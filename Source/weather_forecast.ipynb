{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Függvény a float ellenőrzéshez."
      ],
      "metadata": {
        "id": "eid0LwZsygml"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irha9zbCRCfc"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def is_float(s): #számok kiszűrése\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(is_float(\"alma\"))\n",
        "print(is_float(\"-3.9\"))\n",
        "for i in range(2,9):\n",
        "  print(i,\"páros\" if i%2==0 else \"páratlan\")\n",
        "for i in [\"szilva\", \"5\", \"3.14\", 3.14]:\n",
        "  print(i,\"float\" if is_float(i) else \"nem float\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9aMaI4xpxWJ",
        "outputId": "350ddd7b-f5ec-4b8d-8bc4-90c3192d088b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n",
            "2 páros\n",
            "3 páratlan\n",
            "4 páros\n",
            "5 páratlan\n",
            "6 páros\n",
            "7 páratlan\n",
            "8 páros\n",
            "szilva nem float\n",
            "5 float\n",
            "3.14 float\n",
            "3.14 float\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google drive kezeléséhez import és mount"
      ],
      "metadata": {
        "id": "3MgAAcrAypE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s5CdxnZTOub",
        "outputId": "e7817788-de13-4f11-8f0a-c79fd826f590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adatok beolvasása, plusz paraméterek."
      ],
      "metadata": {
        "id": "Z2TFZMnEyt_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIST=10\n",
        "COLS=3\n",
        "adatok_nyers=[sor.strip().split(sep=\";\") for sor in open(\"/content/drive/My Drive/Classroom/Tibor Tajti/neural net application/BP_d.csv\")]\n"
      ],
      "metadata": {
        "id": "RrlO7boJTSFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adatok_nyers[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILCzwakdUt9n",
        "outputId": "b1a130b1-9cdf-44e5-8e4b-d66c00f324d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['#datum', 'd_ta', 'd_tx', 'd_tn', 'd_rs', 'd_rf', 'd_ss', 'd_ssr'],\n",
              " ['1901-01-01', '-5.7', '-0.4', '-9.2', '1.9', '4', '', ''],\n",
              " ['1901-01-02', '-9.3', '-6.6', '-11.3', '0.0', '', '', ''],\n",
              " ['1901-01-03', '-9.1', '-6.6', '-10.8', '0.8', '4', '', ''],\n",
              " ['1901-01-04', '-11.0', '-9.8', '-12.4', '0.2', '4', '', '']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adatokból kiválasztjuk a felhasználandókat. (avg, max, min hőmérséklet)"
      ],
      "metadata": {
        "id": "QY1e4MSOy4cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print( len(adatok_nyers), adatok_nyers[0])\n",
        "adatok=[[float(adat) if is_float(adat) else adat  for adat in sor[1:COLS+1] ] for sor in adatok_nyers[1:]]\n",
        "print( len(adatok), adatok[0])\n",
        "print( min([min(sor) for sor in adatok]), max([max(sor) for sor in adatok]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBZlAv6hUo90",
        "outputId": "f1b636f1-7f3e-475b-943b-5411277cf399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43831 ['#datum', 'd_ta', 'd_tx', 'd_tn', 'd_rs', 'd_rf', 'd_ss', 'd_ssr']\n",
            "43830 [-5.7, -0.4, -9.2]\n",
            "-23.4 40.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Az adatokból kiválasztunk tanulási és tesztelési mintahalmazt."
      ],
      "metadata": {
        "id": "r5aM_h4RzDda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=adatok[:20000]\n",
        "test=adatok[20000:25000]\n"
      ],
      "metadata": {
        "id": "Eb3Jr2gGU_gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[:5], test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOsMH-VuViyg",
        "outputId": "ad4109a2-e699-487e-bc96-611cce37e648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[-5.7, -0.4, -9.2],\n",
              "  [-9.3, -6.6, -11.3],\n",
              "  [-9.1, -6.6, -10.8],\n",
              "  [-11.0, -9.8, -12.4],\n",
              "  [-11.1, -9.0, -15.5]],\n",
              " [[14.1, 20.2, 10.1],\n",
              "  [15.6, 20.0, 11.2],\n",
              "  [12.4, 16.4, 10.5],\n",
              "  [14.2, 17.5, 10.4],\n",
              "  [13.3, 15.1, 12.3]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Az adatsorokból idősoros mintákat állítunk elő."
      ],
      "metadata": {
        "id": "WlXWEjhlEbv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_x=(np.array([ train[i:i+HIST] for i in range(len(train)-HIST)])-8)/40 # első sortól az ötödikig\n",
        "train_y=(np.array([ train[i+HIST] for i in range(len(train)-HIST)])-8)/40\n",
        "#train_x=(np.array([ train[i:i+HIST] for i in range(0,19990)])+35)/40 # első sortól az ötödikig\n",
        "#train_y=(np.array([ train[i+HIST] for i in range(0,19990)])+35)/40\n",
        "test_x=(np.array([ test[i:i+HIST] for i in range(len(test)-HIST)])-8)/40 # első sortól az ötödikig\n",
        "test_y=(np.array([ test[i+HIST] for i in range(len(test)-HIST)])-8)/40\n",
        "\n",
        "print(train_x.shape, train_y.shape)\n",
        "print(train_x[0])\n",
        "print(train_y[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwTxJio0Vfcg",
        "outputId": "78ff70cc-b31f-4544-a56c-e567b9f3fac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19990, 10, 3) (19990, 3)\n",
            "[[-0.3425 -0.21   -0.43  ]\n",
            " [-0.4325 -0.365  -0.4825]\n",
            " [-0.4275 -0.365  -0.47  ]\n",
            " [-0.475  -0.445  -0.51  ]\n",
            " [-0.4775 -0.425  -0.5875]\n",
            " [-0.4    -0.35   -0.545 ]\n",
            " [-0.3375 -0.275  -0.3725]\n",
            " [-0.45   -0.3475 -0.51  ]\n",
            " [-0.5025 -0.425  -0.5975]\n",
            " [-0.505  -0.445  -0.6225]]\n",
            "[-0.4325 -0.39   -0.5375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Egyszerű futtatás 50 leckével."
      ],
      "metadata": {
        "id": "5cxc27N7HEBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('train with tensorflow')\n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(HIST,COLS)),\n",
        "  tf.keras.layers.Dense(100, activation='tanh'),\n",
        "  tf.keras.layers.Dense(50, activation='tanh'),\n",
        "  tf.keras.layers.Dense(COLS, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "mselst=[]\n",
        "for _ in range(50):\n",
        "  model.fit(train_x, train_y, epochs=1)\n",
        "  y=model.predict(test_x)\n",
        "  print('prediction MSE:', mean_squared_error(test_y, y))\n",
        "  print('dummy MSE:', mean_squared_error(test_y[HIST:], test_y[HIST-1:-1]))\n",
        "  mselst.append(mean_squared_error(test_y, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrvKhxj6TbV5",
        "outputId": "09473787-a4e9-404d-e225-7252ba6865d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train with tensorflow\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0043 - accuracy: 0.9868\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0032148935356100874\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9992\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003314590220797215\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9992\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003144797307870145\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0032004898506326177\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003160851568023268\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0034476772269238505\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0032072491526189233\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0032685670930369284\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003142087559492017\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.00320178784690881\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0032682338635925327\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0032580961533412132\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.00321195464454385\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031297084990327185\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003264890484343303\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003743616833566067\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031005111120140697\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031526309573784005\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031269201772816183\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003214416401065488\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031047392839497596\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003184291862747794\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003081730295058071\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031098226040836598\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031139467309418095\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 1s 5ms/step\n",
            "prediction MSE: 0.003162242848897093\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031771631821039294\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.00310644963137012\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0030608612133021626\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003058637849170348\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031536548315692025\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0030558124346269284\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003202499257509725\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 3ms/step\n",
            "prediction MSE: 0.0031563876231150262\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031028049551859067\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0030762733116885418\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0030478545300118448\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003052357320363699\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0032986037600376086\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.00313162491925288\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003186197702964351\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0030976009343377845\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031674757225195345\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0030678745940094514\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.00306016372580753\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003051479337893004\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031571574235225532\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.00318072615047119\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.0031188149630705965\n",
            "dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 1ms/step\n",
            "prediction MSE: 0.003218361222997732\n",
            "dummy MSE: 0.003883875502008048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ugyanaz még egyszer 10 db tanulóval."
      ],
      "metadata": {
        "id": "9eOi_efUzbf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('train with tensorflow')\n",
        "import tensorflow as tf\n",
        "mselstlst=[]\n",
        "for m in range(10):\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(HIST,COLS)),\n",
        "    tf.keras.layers.Dense(100, activation='tanh'),\n",
        "    tf.keras.layers.Dense(50, activation='tanh'),\n",
        "    tf.keras.layers.Dense(COLS, activation='tanh')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "  mselst=[]\n",
        "  for epoch in range(50):\n",
        "    model.fit(train_x, train_y, epochs=1)\n",
        "    y=model.predict(test_x)\n",
        "    print(m, epoch, 'prediction MSE:', mean_squared_error(test_y, y))\n",
        "    print(m, epoch, 'dummy MSE:', mean_squared_error(test_y[HIST:], test_y[HIST-1:-1]))\n",
        "    mselst.append(mean_squared_error(test_y, y))\n",
        "\n",
        "  mselstlst.append(mselst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_kseSHWqMmj",
        "outputId": "7feb7a3e-eddb-4254-b524-ecaad05d2ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train with tensorflow\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0047 - accuracy: 0.9849\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 0 prediction MSE: 0.0033908436801931446\n",
            "0 0 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0036 - accuracy: 0.9984\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 1 prediction MSE: 0.003596868929844521\n",
            "0 1 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0035 - accuracy: 0.9987\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 2 prediction MSE: 0.0031573953013442953\n",
            "0 2 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9992\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 3 prediction MSE: 0.00350071811277171\n",
            "0 3 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 4 prediction MSE: 0.003291387395544146\n",
            "0 4 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0034 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 5 prediction MSE: 0.003304513754705748\n",
            "0 5 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9992\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 6 prediction MSE: 0.003391066456796849\n",
            "0 6 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 7 prediction MSE: 0.00336794608595411\n",
            "0 7 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 8 prediction MSE: 0.0032407952269073114\n",
            "0 8 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 9 prediction MSE: 0.0032606474338131423\n",
            "0 9 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 10 prediction MSE: 0.003389527589632228\n",
            "0 10 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 11 prediction MSE: 0.0031618323975472844\n",
            "0 11 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 12 prediction MSE: 0.0031188117625277957\n",
            "0 12 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 13 prediction MSE: 0.003329841076239849\n",
            "0 13 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 14 prediction MSE: 0.0033188976871507403\n",
            "0 14 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 15 prediction MSE: 0.003137536491986626\n",
            "0 15 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 16 prediction MSE: 0.0031535537503198977\n",
            "0 16 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 17 prediction MSE: 0.0032258602409110694\n",
            "0 17 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 18 prediction MSE: 0.003424573227079198\n",
            "0 18 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 19 prediction MSE: 0.003211710878382711\n",
            "0 19 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 20 prediction MSE: 0.0034306115453811097\n",
            "0 20 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 21 prediction MSE: 0.0031605139455189207\n",
            "0 21 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 22 prediction MSE: 0.003326678786164663\n",
            "0 22 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 23 prediction MSE: 0.0031300263791032602\n",
            "0 23 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 24 prediction MSE: 0.0031312396875573536\n",
            "0 24 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 25 prediction MSE: 0.0031019234104754413\n",
            "0 25 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 26 prediction MSE: 0.003168426559008742\n",
            "0 26 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 27 prediction MSE: 0.003111965131962196\n",
            "0 27 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 28 prediction MSE: 0.0032061231575385516\n",
            "0 28 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 29 prediction MSE: 0.003162388921389148\n",
            "0 29 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 30 prediction MSE: 0.0031690617830284766\n",
            "0 30 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 31 prediction MSE: 0.0031040892386496543\n",
            "0 31 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 32 prediction MSE: 0.0031307723924712378\n",
            "0 32 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 33 prediction MSE: 0.003103453490881127\n",
            "0 33 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 34 prediction MSE: 0.0032898980517138813\n",
            "0 34 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 35 prediction MSE: 0.003177079837083541\n",
            "0 35 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 36 prediction MSE: 0.0031839391008995858\n",
            "0 36 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 37 prediction MSE: 0.0030823561920753514\n",
            "0 37 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 38 prediction MSE: 0.0031327929720544726\n",
            "0 38 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 39 prediction MSE: 0.003142219615987808\n",
            "0 39 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 40 prediction MSE: 0.0032747930991876965\n",
            "0 40 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 41 prediction MSE: 0.003139141471329891\n",
            "0 41 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 42 prediction MSE: 0.003064427563870592\n",
            "0 42 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 43 prediction MSE: 0.0031320017693738673\n",
            "0 43 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 44 prediction MSE: 0.003119448881675481\n",
            "0 44 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 45 prediction MSE: 0.003132294138483656\n",
            "0 45 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 46 prediction MSE: 0.003092799692072115\n",
            "0 46 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 47 prediction MSE: 0.0030567797076553097\n",
            "0 47 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 48 prediction MSE: 0.0031993833668380526\n",
            "0 48 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "0 49 prediction MSE: 0.0031489883368549416\n",
            "0 49 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0048 - accuracy: 0.9837\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 0 prediction MSE: 0.0034377036411911577\n",
            "1 0 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0036 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 1 prediction MSE: 0.003481268273382262\n",
            "1 1 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 2 prediction MSE: 0.0032933042998277693\n",
            "1 2 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 3 prediction MSE: 0.0032603649744277403\n",
            "1 3 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 4 prediction MSE: 0.0031988989354134398\n",
            "1 4 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 5 prediction MSE: 0.003217292277331678\n",
            "1 5 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 6 prediction MSE: 0.0032428118080688045\n",
            "1 6 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 7 prediction MSE: 0.0032469637649934365\n",
            "1 7 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 8 prediction MSE: 0.00321960011960291\n",
            "1 8 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 9 prediction MSE: 0.003433222081289473\n",
            "1 9 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 10 prediction MSE: 0.003183763804156582\n",
            "1 10 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 11 prediction MSE: 0.0031718906674996234\n",
            "1 11 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 12 prediction MSE: 0.003344543103094321\n",
            "1 12 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 13 prediction MSE: 0.0033047325569055042\n",
            "1 13 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 14 prediction MSE: 0.003390454197570593\n",
            "1 14 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 15 prediction MSE: 0.0032965118042724444\n",
            "1 15 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 16 prediction MSE: 0.003103138484951365\n",
            "1 16 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 17 prediction MSE: 0.003121822361984112\n",
            "1 17 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 18 prediction MSE: 0.003274053294811534\n",
            "1 18 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 19 prediction MSE: 0.003173053387465589\n",
            "1 19 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 20 prediction MSE: 0.0032654810703196158\n",
            "1 20 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 1s 5ms/step\n",
            "1 21 prediction MSE: 0.003195572380793241\n",
            "1 21 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 22 prediction MSE: 0.0030979611612369697\n",
            "1 22 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 23 prediction MSE: 0.0031049917558079745\n",
            "1 23 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 24 prediction MSE: 0.00322820969561388\n",
            "1 24 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 25 prediction MSE: 0.0032543448388459816\n",
            "1 25 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 26 prediction MSE: 0.0031084547680356525\n",
            "1 26 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 27 prediction MSE: 0.0031514573973640335\n",
            "1 27 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 28 prediction MSE: 0.003143085944863917\n",
            "1 28 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 29 prediction MSE: 0.0031383648166269217\n",
            "1 29 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 30 prediction MSE: 0.003084409453283347\n",
            "1 30 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 31 prediction MSE: 0.0031696436403471774\n",
            "1 31 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 32 prediction MSE: 0.003253521284740044\n",
            "1 32 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 33 prediction MSE: 0.003240547689022951\n",
            "1 33 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 34 prediction MSE: 0.003099323466350228\n",
            "1 34 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 35 prediction MSE: 0.0031017304513293997\n",
            "1 35 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 36 prediction MSE: 0.003100367395683642\n",
            "1 36 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 37 prediction MSE: 0.00325385441673866\n",
            "1 37 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 38 prediction MSE: 0.0033608077708698722\n",
            "1 38 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 39 prediction MSE: 0.003162469027029583\n",
            "1 39 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 40 prediction MSE: 0.0031750486048088312\n",
            "1 40 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 41 prediction MSE: 0.0030879474114610807\n",
            "1 41 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 42 prediction MSE: 0.003183854025005738\n",
            "1 42 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 43 prediction MSE: 0.003069010587221846\n",
            "1 43 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 44 prediction MSE: 0.0030798542035883024\n",
            "1 44 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 45 prediction MSE: 0.003098568843353558\n",
            "1 45 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 46 prediction MSE: 0.0032740568573877958\n",
            "1 46 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 47 prediction MSE: 0.0031634405812705686\n",
            "1 47 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 48 prediction MSE: 0.00317776598129015\n",
            "1 48 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "1 49 prediction MSE: 0.003156443184697467\n",
            "1 49 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9749\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 0 prediction MSE: 0.0037555016227068055\n",
            "2 0 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0036 - accuracy: 0.9991\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 1 prediction MSE: 0.003369854770804537\n",
            "2 1 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 2 prediction MSE: 0.003484458593533297\n",
            "2 2 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 3 prediction MSE: 0.003323531364018705\n",
            "2 3 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 4 prediction MSE: 0.0032677331596674634\n",
            "2 4 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 5 prediction MSE: 0.003264967587270486\n",
            "2 5 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 6 prediction MSE: 0.004040720929547535\n",
            "2 6 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 7 prediction MSE: 0.003249625892907504\n",
            "2 7 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 8 prediction MSE: 0.003329917054482457\n",
            "2 8 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 9 prediction MSE: 0.0032253832139107473\n",
            "2 9 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 10 prediction MSE: 0.0031701378887920412\n",
            "2 10 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 11 prediction MSE: 0.0031177887751008375\n",
            "2 11 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 12 prediction MSE: 0.0031303426395877056\n",
            "2 12 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 13 prediction MSE: 0.003228477277280232\n",
            "2 13 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 14 prediction MSE: 0.003165005636431265\n",
            "2 14 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 15 prediction MSE: 0.0032689555261411073\n",
            "2 15 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 16 prediction MSE: 0.003130330059983857\n",
            "2 16 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 17 prediction MSE: 0.003175781536839404\n",
            "2 17 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 18 prediction MSE: 0.0035802168220207993\n",
            "2 18 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 19 prediction MSE: 0.003129736201904553\n",
            "2 19 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 20 prediction MSE: 0.0031717018325158903\n",
            "2 20 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 21 prediction MSE: 0.00309394717591987\n",
            "2 21 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 22 prediction MSE: 0.0034841779306506297\n",
            "2 22 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 23 prediction MSE: 0.0031750110642525674\n",
            "2 23 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 24 prediction MSE: 0.0031954943941771186\n",
            "2 24 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 25 prediction MSE: 0.0031427459749999967\n",
            "2 25 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 26 prediction MSE: 0.003270496312293659\n",
            "2 26 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 27 prediction MSE: 0.003070132173755445\n",
            "2 27 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 28 prediction MSE: 0.003509558491919262\n",
            "2 28 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 29 prediction MSE: 0.003266444825051923\n",
            "2 29 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 30 prediction MSE: 0.0031293943461429374\n",
            "2 30 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 31 prediction MSE: 0.0031356146014668226\n",
            "2 31 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 32 prediction MSE: 0.003102901022491691\n",
            "2 32 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 33 prediction MSE: 0.0031106599981378636\n",
            "2 33 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 3ms/step\n",
            "2 34 prediction MSE: 0.0032474500668734974\n",
            "2 34 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 35 prediction MSE: 0.0033934361790384487\n",
            "2 35 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 36 prediction MSE: 0.0031470268459676126\n",
            "2 36 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 37 prediction MSE: 0.0030757688865699763\n",
            "2 37 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 38 prediction MSE: 0.0031508269637364164\n",
            "2 38 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 39 prediction MSE: 0.0031219051553869575\n",
            "2 39 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 40 prediction MSE: 0.0032827979037121477\n",
            "2 40 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 41 prediction MSE: 0.0032074505641218006\n",
            "2 41 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 42 prediction MSE: 0.003061889719893081\n",
            "2 42 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 43 prediction MSE: 0.0031828198276231956\n",
            "2 43 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 44 prediction MSE: 0.003182765327298408\n",
            "2 44 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 45 prediction MSE: 0.0031914519497896494\n",
            "2 45 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 1s 7ms/step\n",
            "2 46 prediction MSE: 0.003094400001550163\n",
            "2 46 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 47 prediction MSE: 0.003052497100181448\n",
            "2 47 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 48 prediction MSE: 0.0031723182346024615\n",
            "2 48 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "2 49 prediction MSE: 0.003213307813835961\n",
            "2 49 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9865\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 0 prediction MSE: 0.0033982813480019722\n",
            "3 0 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0036 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 1 prediction MSE: 0.004206639353692947\n",
            "3 1 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9991\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 2 prediction MSE: 0.00324774996459593\n",
            "3 2 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9992\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 3 prediction MSE: 0.0032725467616210903\n",
            "3 3 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9994\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 4 prediction MSE: 0.00331472959226359\n",
            "3 4 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9992\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 5 prediction MSE: 0.003330815099505694\n",
            "3 5 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9993\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 6 prediction MSE: 0.003339422562290325\n",
            "3 6 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 7 prediction MSE: 0.0031487142002563\n",
            "3 7 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 8 prediction MSE: 0.0033675557139886355\n",
            "3 8 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 9 prediction MSE: 0.0031166084588321167\n",
            "3 9 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 10 prediction MSE: 0.003459587037002174\n",
            "3 10 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 11 prediction MSE: 0.0032048748648070666\n",
            "3 11 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 12 prediction MSE: 0.0032428806751300357\n",
            "3 12 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 13 prediction MSE: 0.0032282506611011823\n",
            "3 13 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 14 prediction MSE: 0.003420374592727131\n",
            "3 14 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 15 prediction MSE: 0.0033184771080852354\n",
            "3 15 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 16 prediction MSE: 0.0031736373960375448\n",
            "3 16 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 17 prediction MSE: 0.003161029378955113\n",
            "3 17 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 18 prediction MSE: 0.003328227762395204\n",
            "3 18 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 19 prediction MSE: 0.0030850836808647593\n",
            "3 19 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 20 prediction MSE: 0.0031152996502072663\n",
            "3 20 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 21 prediction MSE: 0.003306882814146787\n",
            "3 21 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 22 prediction MSE: 0.003175249847251056\n",
            "3 22 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 23 prediction MSE: 0.003152514845279368\n",
            "3 23 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 24 prediction MSE: 0.003065921157032927\n",
            "3 24 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 25 prediction MSE: 0.00325582378023649\n",
            "3 25 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 26 prediction MSE: 0.0032119551314155003\n",
            "3 26 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 27 prediction MSE: 0.003424881412997798\n",
            "3 27 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 28 prediction MSE: 0.003198264753211704\n",
            "3 28 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 29 prediction MSE: 0.00309870318128421\n",
            "3 29 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 30 prediction MSE: 0.003094150642473495\n",
            "3 30 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 31 prediction MSE: 0.0034289962258512857\n",
            "3 31 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 32 prediction MSE: 0.0030673972312548446\n",
            "3 32 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 33 prediction MSE: 0.00314214533379617\n",
            "3 33 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 34 prediction MSE: 0.0030923926695680948\n",
            "3 34 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 35 prediction MSE: 0.0032501158710931213\n",
            "3 35 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 36 prediction MSE: 0.003265250081048879\n",
            "3 36 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 37 prediction MSE: 0.003112662544153648\n",
            "3 37 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 38 prediction MSE: 0.003250633672076617\n",
            "3 38 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 39 prediction MSE: 0.0030916816626114286\n",
            "3 39 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 40 prediction MSE: 0.0030598046366355383\n",
            "3 40 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 41 prediction MSE: 0.00308314221637121\n",
            "3 41 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 42 prediction MSE: 0.0030892707107134936\n",
            "3 42 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 43 prediction MSE: 0.003104732703017862\n",
            "3 43 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 44 prediction MSE: 0.003123037232582238\n",
            "3 44 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 45 prediction MSE: 0.0030981059431246026\n",
            "3 45 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 46 prediction MSE: 0.003169127440567056\n",
            "3 46 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 47 prediction MSE: 0.0030641177153787943\n",
            "3 47 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 48 prediction MSE: 0.003060635254830318\n",
            "3 48 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "3 49 prediction MSE: 0.0030355927891840225\n",
            "3 49 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9852\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 0 prediction MSE: 0.004540453794060283\n",
            "4 0 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0036 - accuracy: 0.9981\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 1 prediction MSE: 0.0033607946585343146\n",
            "4 1 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 2 prediction MSE: 0.0037574687223430915\n",
            "4 2 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9990\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 3 prediction MSE: 0.00313538305000732\n",
            "4 3 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9992\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 4 prediction MSE: 0.003226944645415291\n",
            "4 4 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 5 prediction MSE: 0.0032889306884623317\n",
            "4 5 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 6 prediction MSE: 0.0032602909310526884\n",
            "4 6 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 7 prediction MSE: 0.0031183162617697906\n",
            "4 7 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 8 prediction MSE: 0.0033974600879059357\n",
            "4 8 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 9 prediction MSE: 0.0038390432695115458\n",
            "4 9 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 10 prediction MSE: 0.003216336212153441\n",
            "4 10 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 11 prediction MSE: 0.003121200745936041\n",
            "4 11 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 12 prediction MSE: 0.0031662877743019353\n",
            "4 12 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 13 prediction MSE: 0.0031542800658656903\n",
            "4 13 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 14 prediction MSE: 0.003695123840024002\n",
            "4 14 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 15 prediction MSE: 0.003138451116619503\n",
            "4 15 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 16 prediction MSE: 0.0030970103364450145\n",
            "4 16 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 17 prediction MSE: 0.003198811383607843\n",
            "4 17 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 18 prediction MSE: 0.003110642374553531\n",
            "4 18 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 19 prediction MSE: 0.0033244010118620433\n",
            "4 19 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 20 prediction MSE: 0.0033080353441217597\n",
            "4 20 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 21 prediction MSE: 0.0031822639802040315\n",
            "4 21 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 22 prediction MSE: 0.0031024358185107776\n",
            "4 22 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 23 prediction MSE: 0.0032266871156739134\n",
            "4 23 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 24 prediction MSE: 0.0031020026955099213\n",
            "4 24 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 25 prediction MSE: 0.0031261172062684132\n",
            "4 25 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 26 prediction MSE: 0.0030975297343272604\n",
            "4 26 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 27 prediction MSE: 0.003075822966784365\n",
            "4 27 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 28 prediction MSE: 0.0031441848244387924\n",
            "4 28 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 29 prediction MSE: 0.0031293051135968014\n",
            "4 29 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 30 prediction MSE: 0.003132930620349171\n",
            "4 30 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 31 prediction MSE: 0.0031035335231538023\n",
            "4 31 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 32 prediction MSE: 0.003124302153474761\n",
            "4 32 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 33 prediction MSE: 0.003137852863668292\n",
            "4 33 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 34 prediction MSE: 0.003149222814865016\n",
            "4 34 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 35 prediction MSE: 0.0032102723586970097\n",
            "4 35 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 36 prediction MSE: 0.0031726615813144027\n",
            "4 36 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 37 prediction MSE: 0.003060658761743263\n",
            "4 37 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 38 prediction MSE: 0.0030841650874801484\n",
            "4 38 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 39 prediction MSE: 0.0031565441244328727\n",
            "4 39 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 40 prediction MSE: 0.0031699016840771575\n",
            "4 40 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 41 prediction MSE: 0.003108034923405495\n",
            "4 41 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 42 prediction MSE: 0.0032327804752190054\n",
            "4 42 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 43 prediction MSE: 0.0032375306835086344\n",
            "4 43 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 44 prediction MSE: 0.003191441080106784\n",
            "4 44 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 45 prediction MSE: 0.0030581134121920373\n",
            "4 45 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 46 prediction MSE: 0.0030912194701192635\n",
            "4 46 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 47 prediction MSE: 0.0030815589889098636\n",
            "4 47 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 48 prediction MSE: 0.003215226399025798\n",
            "4 48 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "4 49 prediction MSE: 0.0030656085971066355\n",
            "4 49 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9926\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 0 prediction MSE: 0.003476807111428099\n",
            "5 0 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0036 - accuracy: 0.9978\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 1 prediction MSE: 0.003228896403056725\n",
            "5 1 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9994\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 2 prediction MSE: 0.0032083592017339638\n",
            "5 2 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 3 prediction MSE: 0.0032975618489613427\n",
            "5 3 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 4 prediction MSE: 0.003210960536137203\n",
            "5 4 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 5 prediction MSE: 0.003275770419910156\n",
            "5 5 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 6 prediction MSE: 0.003315238753017717\n",
            "5 6 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 7 prediction MSE: 0.0031793592300105402\n",
            "5 7 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 8 prediction MSE: 0.0031913229835085536\n",
            "5 8 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 9 prediction MSE: 0.0031810586451839827\n",
            "5 9 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 10 prediction MSE: 0.0031579910404399016\n",
            "5 10 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 11 prediction MSE: 0.0032259997638535935\n",
            "5 11 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 12 prediction MSE: 0.0031222312317149728\n",
            "5 12 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 13 prediction MSE: 0.0032801576892526377\n",
            "5 13 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 14 prediction MSE: 0.0031512865649181436\n",
            "5 14 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 15 prediction MSE: 0.0031586956799125898\n",
            "5 15 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 16 prediction MSE: 0.0031986167089557613\n",
            "5 16 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 17 prediction MSE: 0.003192491817747124\n",
            "5 17 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 18 prediction MSE: 0.0031624725616722442\n",
            "5 18 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 19 prediction MSE: 0.003202475793685107\n",
            "5 19 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 20 prediction MSE: 0.0033024198907709787\n",
            "5 20 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 21 prediction MSE: 0.0031942000839822273\n",
            "5 21 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 22 prediction MSE: 0.003178125876024236\n",
            "5 22 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 23 prediction MSE: 0.003167206110722674\n",
            "5 23 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 24 prediction MSE: 0.0032724855254730387\n",
            "5 24 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 25 prediction MSE: 0.003177318741288857\n",
            "5 25 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 26 prediction MSE: 0.0031534423062221633\n",
            "5 26 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 27 prediction MSE: 0.0031690929676312482\n",
            "5 27 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 28 prediction MSE: 0.003116506630098052\n",
            "5 28 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 29 prediction MSE: 0.003205389307216712\n",
            "5 29 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 30 prediction MSE: 0.0031446299243519243\n",
            "5 30 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 31 prediction MSE: 0.003183643789834987\n",
            "5 31 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 32 prediction MSE: 0.0031894609430866143\n",
            "5 32 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 33 prediction MSE: 0.0030769100713471374\n",
            "5 33 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 34 prediction MSE: 0.0033574211056752357\n",
            "5 34 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 35 prediction MSE: 0.0032249476822302364\n",
            "5 35 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 36 prediction MSE: 0.0032842575650924616\n",
            "5 36 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 37 prediction MSE: 0.0032494012214534175\n",
            "5 37 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 38 prediction MSE: 0.003148465738310302\n",
            "5 38 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 39 prediction MSE: 0.003104596587063507\n",
            "5 39 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 40 prediction MSE: 0.003225957900354896\n",
            "5 40 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 41 prediction MSE: 0.003248281994323816\n",
            "5 41 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 42 prediction MSE: 0.0030836037564551722\n",
            "5 42 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 43 prediction MSE: 0.0031883289728394993\n",
            "5 43 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 44 prediction MSE: 0.0033564135026944325\n",
            "5 44 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 45 prediction MSE: 0.0030961425603687896\n",
            "5 45 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 46 prediction MSE: 0.003107245776084708\n",
            "5 46 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 47 prediction MSE: 0.0031657610916297767\n",
            "5 47 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 48 prediction MSE: 0.0031572491550602906\n",
            "5 48 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "5 49 prediction MSE: 0.003129208858746218\n",
            "5 49 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 3ms/step - loss: 0.0045 - accuracy: 0.9848\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 0 prediction MSE: 0.003372802238226858\n",
            "6 0 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9953\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 1 prediction MSE: 0.003666426849960493\n",
            "6 1 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9979\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 2 prediction MSE: 0.003478551140925321\n",
            "6 2 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9980\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 3 prediction MSE: 0.0032195767898410624\n",
            "6 3 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9987\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 4 prediction MSE: 0.0032382091326069707\n",
            "6 4 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 5 prediction MSE: 0.0032715139819201565\n",
            "6 5 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9992\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 6 prediction MSE: 0.003397201602051311\n",
            "6 6 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9994\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 7 prediction MSE: 0.003297839473444829\n",
            "6 7 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9994\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 8 prediction MSE: 0.0033980651431007093\n",
            "6 8 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 9 prediction MSE: 0.0033140719531997848\n",
            "6 9 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 10 prediction MSE: 0.0035702531746873594\n",
            "6 10 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 11 prediction MSE: 0.0033291938894387837\n",
            "6 11 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 12 prediction MSE: 0.00317496018309305\n",
            "6 12 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 13 prediction MSE: 0.0031659161027986957\n",
            "6 13 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 14 prediction MSE: 0.0032698827016305588\n",
            "6 14 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 15 prediction MSE: 0.003117494531517375\n",
            "6 15 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 16 prediction MSE: 0.0032363292571234298\n",
            "6 16 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 17 prediction MSE: 0.003684508843482285\n",
            "6 17 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 18 prediction MSE: 0.003173612629785258\n",
            "6 18 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 19 prediction MSE: 0.0031324669024415945\n",
            "6 19 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 20 prediction MSE: 0.0032525300319310086\n",
            "6 20 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 21 prediction MSE: 0.003169538785216018\n",
            "6 21 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 22 prediction MSE: 0.003277593263395004\n",
            "6 22 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 23 prediction MSE: 0.0031662415989778276\n",
            "6 23 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 24 prediction MSE: 0.0032876526883160125\n",
            "6 24 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 25 prediction MSE: 0.003086687023203602\n",
            "6 25 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 26 prediction MSE: 0.0031257357229917703\n",
            "6 26 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 27 prediction MSE: 0.0032741747802209815\n",
            "6 27 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 28 prediction MSE: 0.0031542323963522877\n",
            "6 28 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 29 prediction MSE: 0.003124847602359476\n",
            "6 29 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 30 prediction MSE: 0.0031633504756046656\n",
            "6 30 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 31 prediction MSE: 0.003204859551730599\n",
            "6 31 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 32 prediction MSE: 0.003144598631689873\n",
            "6 32 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 33 prediction MSE: 0.0030774388278575903\n",
            "6 33 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 34 prediction MSE: 0.0031532650233379975\n",
            "6 34 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 35 prediction MSE: 0.0032348003024436135\n",
            "6 35 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 36 prediction MSE: 0.003245735793472129\n",
            "6 36 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 37 prediction MSE: 0.0031224573045452887\n",
            "6 37 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 38 prediction MSE: 0.0030946487500979705\n",
            "6 38 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 39 prediction MSE: 0.003142690326032153\n",
            "6 39 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 40 prediction MSE: 0.003204020280686842\n",
            "6 40 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 41 prediction MSE: 0.0031041980715074678\n",
            "6 41 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 42 prediction MSE: 0.003041129825598778\n",
            "6 42 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 43 prediction MSE: 0.003104831443044536\n",
            "6 43 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 44 prediction MSE: 0.003030833339336776\n",
            "6 44 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 45 prediction MSE: 0.0031187382791706872\n",
            "6 45 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 46 prediction MSE: 0.0030707260679144603\n",
            "6 46 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 47 prediction MSE: 0.003168842716170651\n",
            "6 47 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 48 prediction MSE: 0.0032256332820194433\n",
            "6 48 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "6 49 prediction MSE: 0.0030460730999279117\n",
            "6 49 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9831\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 0 prediction MSE: 0.00341590501050164\n",
            "7 0 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0036 - accuracy: 0.9986\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 1 prediction MSE: 0.0032822010937571706\n",
            "7 1 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 2 prediction MSE: 0.0034819202191132405\n",
            "7 2 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 3 prediction MSE: 0.0031928677776567917\n",
            "7 3 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 4 prediction MSE: 0.003873829168926944\n",
            "7 4 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 5 prediction MSE: 0.0031850130875641296\n",
            "7 5 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 6 prediction MSE: 0.003316137968871849\n",
            "7 6 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9994\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 7 prediction MSE: 0.0033210624015959536\n",
            "7 7 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 8 prediction MSE: 0.0033844007770821457\n",
            "7 8 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 9 prediction MSE: 0.003194862838059556\n",
            "7 9 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 10 prediction MSE: 0.0031959865995175338\n",
            "7 10 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 11 prediction MSE: 0.0032203806781760194\n",
            "7 11 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 12 prediction MSE: 0.003250502038391333\n",
            "7 12 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 13 prediction MSE: 0.0032135964663324856\n",
            "7 13 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 14 prediction MSE: 0.003149071804302629\n",
            "7 14 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 15 prediction MSE: 0.0031570322099930027\n",
            "7 15 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 16 prediction MSE: 0.003121453314884517\n",
            "7 16 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 17 prediction MSE: 0.0031521399871833403\n",
            "7 17 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 18 prediction MSE: 0.0032555332190206693\n",
            "7 18 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 19 prediction MSE: 0.003091603491016235\n",
            "7 19 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 20 prediction MSE: 0.003199337273349296\n",
            "7 20 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 21 prediction MSE: 0.003122860072143536\n",
            "7 21 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 22 prediction MSE: 0.003209712011936967\n",
            "7 22 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 23 prediction MSE: 0.0032361778222572846\n",
            "7 23 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 24 prediction MSE: 0.0034209090842374813\n",
            "7 24 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 25 prediction MSE: 0.003203271453064587\n",
            "7 25 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 26 prediction MSE: 0.0033400172921376503\n",
            "7 26 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 27 prediction MSE: 0.0031315441858183325\n",
            "7 27 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 28 prediction MSE: 0.003095138951503828\n",
            "7 28 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 29 prediction MSE: 0.003163103633055669\n",
            "7 29 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 30 prediction MSE: 0.0030967318222823504\n",
            "7 30 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 31 prediction MSE: 0.0031477580211478813\n",
            "7 31 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 32 prediction MSE: 0.0030800209576828767\n",
            "7 32 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 33 prediction MSE: 0.003107989055806377\n",
            "7 33 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 34 prediction MSE: 0.0031813268591574357\n",
            "7 34 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 35 prediction MSE: 0.003119440457403534\n",
            "7 35 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 36 prediction MSE: 0.003091657917626528\n",
            "7 36 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 37 prediction MSE: 0.0031002067361183936\n",
            "7 37 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 38 prediction MSE: 0.003155462341279254\n",
            "7 38 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 39 prediction MSE: 0.0032460290260302796\n",
            "7 39 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 40 prediction MSE: 0.0031206577492930015\n",
            "7 40 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 41 prediction MSE: 0.00306189771089097\n",
            "7 41 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 42 prediction MSE: 0.003071927971676387\n",
            "7 42 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 43 prediction MSE: 0.003116239603544253\n",
            "7 43 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 44 prediction MSE: 0.0032410789777380564\n",
            "7 44 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 45 prediction MSE: 0.0030745537533193763\n",
            "7 45 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 46 prediction MSE: 0.0031486203523768182\n",
            "7 46 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 47 prediction MSE: 0.0031110379777179627\n",
            "7 47 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 48 prediction MSE: 0.0033319809840767945\n",
            "7 48 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "7 49 prediction MSE: 0.003096191849410054\n",
            "7 49 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9842\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 0 prediction MSE: 0.003396836207436681\n",
            "8 0 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0036 - accuracy: 0.9979\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 1 prediction MSE: 0.0032101453991422962\n",
            "8 1 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9983\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 2 prediction MSE: 0.0033806754798584083\n",
            "8 2 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9993\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 3 prediction MSE: 0.003301711848431061\n",
            "8 3 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9993\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 4 prediction MSE: 0.0031738239260627747\n",
            "8 4 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 5 prediction MSE: 0.003305027383311846\n",
            "8 5 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 6 prediction MSE: 0.0032106314563617477\n",
            "8 6 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 7 prediction MSE: 0.0031706337817806467\n",
            "8 7 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 8 prediction MSE: 0.003282461888208368\n",
            "8 8 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 9 prediction MSE: 0.0033204316916405872\n",
            "8 9 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 10 prediction MSE: 0.0032136604657230904\n",
            "8 10 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 11 prediction MSE: 0.0031350947857369978\n",
            "8 11 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 12 prediction MSE: 0.0031524255094347677\n",
            "8 12 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 13 prediction MSE: 0.0031355842429371217\n",
            "8 13 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 14 prediction MSE: 0.0032151363149993625\n",
            "8 14 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 15 prediction MSE: 0.0031542162495671656\n",
            "8 15 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 16 prediction MSE: 0.0035091033522630043\n",
            "8 16 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 17 prediction MSE: 0.0032541035534713243\n",
            "8 17 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 18 prediction MSE: 0.0032088420188682086\n",
            "8 18 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 19 prediction MSE: 0.003227629277963015\n",
            "8 19 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 20 prediction MSE: 0.003295443039936475\n",
            "8 20 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 21 prediction MSE: 0.003139226440328121\n",
            "8 21 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 22 prediction MSE: 0.0031749573915682582\n",
            "8 22 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 23 prediction MSE: 0.003134594795781929\n",
            "8 23 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 24 prediction MSE: 0.0032749149688347406\n",
            "8 24 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 25 prediction MSE: 0.0031377542496561915\n",
            "8 25 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 26 prediction MSE: 0.0031291057155387867\n",
            "8 26 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 27 prediction MSE: 0.003184361900408809\n",
            "8 27 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 28 prediction MSE: 0.0031189001530669736\n",
            "8 28 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 29 prediction MSE: 0.0031919346464515225\n",
            "8 29 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 30 prediction MSE: 0.0033552647408971008\n",
            "8 30 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 31 prediction MSE: 0.003176011517449638\n",
            "8 31 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 32 prediction MSE: 0.0031216532895186008\n",
            "8 32 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 33 prediction MSE: 0.0031065700315742292\n",
            "8 33 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 34 prediction MSE: 0.0032702425371001196\n",
            "8 34 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 35 prediction MSE: 0.003113889547670036\n",
            "8 35 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 36 prediction MSE: 0.0031892625969603765\n",
            "8 36 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 37 prediction MSE: 0.003112367416663876\n",
            "8 37 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 38 prediction MSE: 0.0032133516938816827\n",
            "8 38 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 39 prediction MSE: 0.003261357006117823\n",
            "8 39 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 40 prediction MSE: 0.003164850035929105\n",
            "8 40 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 41 prediction MSE: 0.0031049320133548293\n",
            "8 41 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 42 prediction MSE: 0.0031361038013384013\n",
            "8 42 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 43 prediction MSE: 0.0031729963243373803\n",
            "8 43 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 44 prediction MSE: 0.003090277895344934\n",
            "8 44 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 3ms/step\n",
            "8 45 prediction MSE: 0.003120394288332415\n",
            "8 45 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 46 prediction MSE: 0.003068180006110886\n",
            "8 46 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 47 prediction MSE: 0.003155546054372949\n",
            "8 47 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 48 prediction MSE: 0.0030694011013426927\n",
            "8 48 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "8 49 prediction MSE: 0.0031398553557856605\n",
            "8 49 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9861\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 0 prediction MSE: 0.0033942251333765575\n",
            "9 0 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0036 - accuracy: 0.9961\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 1 prediction MSE: 0.0038008693873222894\n",
            "9 1 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9990\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 2 prediction MSE: 0.003312532954400069\n",
            "9 2 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0035 - accuracy: 0.9996\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 3 prediction MSE: 0.0034764654226441226\n",
            "9 3 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 4 prediction MSE: 0.0035626908536774246\n",
            "9 4 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 5 prediction MSE: 0.003249697705361669\n",
            "9 5 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9997\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 6 prediction MSE: 0.0032291960825599985\n",
            "9 6 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 7 prediction MSE: 0.003214918881091869\n",
            "9 7 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 8 prediction MSE: 0.003323107621193393\n",
            "9 8 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 9 prediction MSE: 0.003246497711868818\n",
            "9 9 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 10 prediction MSE: 0.0032493451526025706\n",
            "9 10 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 11 prediction MSE: 0.0031679001804056275\n",
            "9 11 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 12 prediction MSE: 0.0032214040305089168\n",
            "9 12 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 13 prediction MSE: 0.003441908226032582\n",
            "9 13 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9999\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 14 prediction MSE: 0.003323927129752442\n",
            "9 14 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 15 prediction MSE: 0.0031447778843275783\n",
            "9 15 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 16 prediction MSE: 0.0031852832138660856\n",
            "9 16 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 17 prediction MSE: 0.003206880638348603\n",
            "9 17 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 18 prediction MSE: 0.003284501625275306\n",
            "9 18 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 19 prediction MSE: 0.0031743976207896357\n",
            "9 19 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 20 prediction MSE: 0.0032611676352676607\n",
            "9 20 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 21 prediction MSE: 0.0031859232046109135\n",
            "9 21 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 22 prediction MSE: 0.003307040219064071\n",
            "9 22 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 23 prediction MSE: 0.0031906242496684604\n",
            "9 23 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 24 prediction MSE: 0.003143617614580961\n",
            "9 24 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 25 prediction MSE: 0.0031382537909004564\n",
            "9 25 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 26 prediction MSE: 0.003161314292331513\n",
            "9 26 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 27 prediction MSE: 0.0030748857918210695\n",
            "9 27 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 28 prediction MSE: 0.0031384574179159964\n",
            "9 28 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 29 prediction MSE: 0.003121922592603765\n",
            "9 29 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 30 prediction MSE: 0.003111403201146059\n",
            "9 30 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 31 prediction MSE: 0.003190137374303252\n",
            "9 31 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 32 prediction MSE: 0.003078010805610791\n",
            "9 32 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 1s 3ms/step\n",
            "9 33 prediction MSE: 0.0033737172747224237\n",
            "9 33 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 1s 9ms/step\n",
            "9 34 prediction MSE: 0.0030897746184555853\n",
            "9 34 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 35 prediction MSE: 0.0030929695914990274\n",
            "9 35 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 1s 4ms/step\n",
            "9 36 prediction MSE: 0.0031059090818525057\n",
            "9 36 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 37 prediction MSE: 0.0030941155069327017\n",
            "9 37 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 38 prediction MSE: 0.0032670469056018682\n",
            "9 38 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 39 prediction MSE: 0.003303022308599893\n",
            "9 39 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 40 prediction MSE: 0.003111998219648944\n",
            "9 40 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 41 prediction MSE: 0.003125787106828031\n",
            "9 41 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 42 prediction MSE: 0.0031937914972970396\n",
            "9 42 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 43 prediction MSE: 0.0032420325108353265\n",
            "9 43 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 44 prediction MSE: 0.0032139508917084837\n",
            "9 44 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 45 prediction MSE: 0.003154237025269482\n",
            "9 45 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 46 prediction MSE: 0.003064919172953885\n",
            "9 46 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 47 prediction MSE: 0.0031950451256042077\n",
            "9 47 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 48 prediction MSE: 0.0030782099713218547\n",
            "9 48 dummy MSE: 0.003883875502008048\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "9 49 prediction MSE: 0.0033630528134509525\n",
            "9 49 dummy MSE: 0.003883875502008048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mselst)\n",
        "print(mselstlst)\n",
        "res=np.array(mselstlst)\n",
        "print(res.shape)\n",
        "print(np.mean(res))\n",
        "print(np.mean(res, axis=1))\n",
        "print(np.mean(res, axis=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUaWzKvJ5FSG",
        "outputId": "7454d89f-3063-454d-a31e-71c22fad8bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0033942251333765575, 0.0038008693873222894, 0.003312532954400069, 0.0034764654226441226, 0.0035626908536774246, 0.003249697705361669, 0.0032291960825599985, 0.003214918881091869, 0.003323107621193393, 0.003246497711868818, 0.0032493451526025706, 0.0031679001804056275, 0.0032214040305089168, 0.003441908226032582, 0.003323927129752442, 0.0031447778843275783, 0.0031852832138660856, 0.003206880638348603, 0.003284501625275306, 0.0031743976207896357, 0.0032611676352676607, 0.0031859232046109135, 0.003307040219064071, 0.0031906242496684604, 0.003143617614580961, 0.0031382537909004564, 0.003161314292331513, 0.0030748857918210695, 0.0031384574179159964, 0.003121922592603765, 0.003111403201146059, 0.003190137374303252, 0.003078010805610791, 0.0033737172747224237, 0.0030897746184555853, 0.0030929695914990274, 0.0031059090818525057, 0.0030941155069327017, 0.0032670469056018682, 0.003303022308599893, 0.003111998219648944, 0.003125787106828031, 0.0031937914972970396, 0.0032420325108353265, 0.0032139508917084837, 0.003154237025269482, 0.003064919172953885, 0.0031950451256042077, 0.0030782099713218547, 0.0033630528134509525]\n",
            "[[0.0033908436801931446, 0.003596868929844521, 0.0031573953013442953, 0.00350071811277171, 0.003291387395544146, 0.003304513754705748, 0.003391066456796849, 0.00336794608595411, 0.0032407952269073114, 0.0032606474338131423, 0.003389527589632228, 0.0031618323975472844, 0.0031188117625277957, 0.003329841076239849, 0.0033188976871507403, 0.003137536491986626, 0.0031535537503198977, 0.0032258602409110694, 0.003424573227079198, 0.003211710878382711, 0.0034306115453811097, 0.0031605139455189207, 0.003326678786164663, 0.0031300263791032602, 0.0031312396875573536, 0.0031019234104754413, 0.003168426559008742, 0.003111965131962196, 0.0032061231575385516, 0.003162388921389148, 0.0031690617830284766, 0.0031040892386496543, 0.0031307723924712378, 0.003103453490881127, 0.0032898980517138813, 0.003177079837083541, 0.0031839391008995858, 0.0030823561920753514, 0.0031327929720544726, 0.003142219615987808, 0.0032747930991876965, 0.003139141471329891, 0.003064427563870592, 0.0031320017693738673, 0.003119448881675481, 0.003132294138483656, 0.003092799692072115, 0.0030567797076553097, 0.0031993833668380526, 0.0031489883368549416], [0.0034377036411911577, 0.003481268273382262, 0.0032933042998277693, 0.0032603649744277403, 0.0031988989354134398, 0.003217292277331678, 0.0032428118080688045, 0.0032469637649934365, 0.00321960011960291, 0.003433222081289473, 0.003183763804156582, 0.0031718906674996234, 0.003344543103094321, 0.0033047325569055042, 0.003390454197570593, 0.0032965118042724444, 0.003103138484951365, 0.003121822361984112, 0.003274053294811534, 0.003173053387465589, 0.0032654810703196158, 0.003195572380793241, 0.0030979611612369697, 0.0031049917558079745, 0.00322820969561388, 0.0032543448388459816, 0.0031084547680356525, 0.0031514573973640335, 0.003143085944863917, 0.0031383648166269217, 0.003084409453283347, 0.0031696436403471774, 0.003253521284740044, 0.003240547689022951, 0.003099323466350228, 0.0031017304513293997, 0.003100367395683642, 0.00325385441673866, 0.0033608077708698722, 0.003162469027029583, 0.0031750486048088312, 0.0030879474114610807, 0.003183854025005738, 0.003069010587221846, 0.0030798542035883024, 0.003098568843353558, 0.0032740568573877958, 0.0031634405812705686, 0.00317776598129015, 0.003156443184697467], [0.0037555016227068055, 0.003369854770804537, 0.003484458593533297, 0.003323531364018705, 0.0032677331596674634, 0.003264967587270486, 0.004040720929547535, 0.003249625892907504, 0.003329917054482457, 0.0032253832139107473, 0.0031701378887920412, 0.0031177887751008375, 0.0031303426395877056, 0.003228477277280232, 0.003165005636431265, 0.0032689555261411073, 0.003130330059983857, 0.003175781536839404, 0.0035802168220207993, 0.003129736201904553, 0.0031717018325158903, 0.00309394717591987, 0.0034841779306506297, 0.0031750110642525674, 0.0031954943941771186, 0.0031427459749999967, 0.003270496312293659, 0.003070132173755445, 0.003509558491919262, 0.003266444825051923, 0.0031293943461429374, 0.0031356146014668226, 0.003102901022491691, 0.0031106599981378636, 0.0032474500668734974, 0.0033934361790384487, 0.0031470268459676126, 0.0030757688865699763, 0.0031508269637364164, 0.0031219051553869575, 0.0032827979037121477, 0.0032074505641218006, 0.003061889719893081, 0.0031828198276231956, 0.003182765327298408, 0.0031914519497896494, 0.003094400001550163, 0.003052497100181448, 0.0031723182346024615, 0.003213307813835961], [0.0033982813480019722, 0.004206639353692947, 0.00324774996459593, 0.0032725467616210903, 0.00331472959226359, 0.003330815099505694, 0.003339422562290325, 0.0031487142002563, 0.0033675557139886355, 0.0031166084588321167, 0.003459587037002174, 0.0032048748648070666, 0.0032428806751300357, 0.0032282506611011823, 0.003420374592727131, 0.0033184771080852354, 0.0031736373960375448, 0.003161029378955113, 0.003328227762395204, 0.0030850836808647593, 0.0031152996502072663, 0.003306882814146787, 0.003175249847251056, 0.003152514845279368, 0.003065921157032927, 0.00325582378023649, 0.0032119551314155003, 0.003424881412997798, 0.003198264753211704, 0.00309870318128421, 0.003094150642473495, 0.0034289962258512857, 0.0030673972312548446, 0.00314214533379617, 0.0030923926695680948, 0.0032501158710931213, 0.003265250081048879, 0.003112662544153648, 0.003250633672076617, 0.0030916816626114286, 0.0030598046366355383, 0.00308314221637121, 0.0030892707107134936, 0.003104732703017862, 0.003123037232582238, 0.0030981059431246026, 0.003169127440567056, 0.0030641177153787943, 0.003060635254830318, 0.0030355927891840225], [0.004540453794060283, 0.0033607946585343146, 0.0037574687223430915, 0.00313538305000732, 0.003226944645415291, 0.0032889306884623317, 0.0032602909310526884, 0.0031183162617697906, 0.0033974600879059357, 0.0038390432695115458, 0.003216336212153441, 0.003121200745936041, 0.0031662877743019353, 0.0031542800658656903, 0.003695123840024002, 0.003138451116619503, 0.0030970103364450145, 0.003198811383607843, 0.003110642374553531, 0.0033244010118620433, 0.0033080353441217597, 0.0031822639802040315, 0.0031024358185107776, 0.0032266871156739134, 0.0031020026955099213, 0.0031261172062684132, 0.0030975297343272604, 0.003075822966784365, 0.0031441848244387924, 0.0031293051135968014, 0.003132930620349171, 0.0031035335231538023, 0.003124302153474761, 0.003137852863668292, 0.003149222814865016, 0.0032102723586970097, 0.0031726615813144027, 0.003060658761743263, 0.0030841650874801484, 0.0031565441244328727, 0.0031699016840771575, 0.003108034923405495, 0.0032327804752190054, 0.0032375306835086344, 0.003191441080106784, 0.0030581134121920373, 0.0030912194701192635, 0.0030815589889098636, 0.003215226399025798, 0.0030656085971066355], [0.003476807111428099, 0.003228896403056725, 0.0032083592017339638, 0.0032975618489613427, 0.003210960536137203, 0.003275770419910156, 0.003315238753017717, 0.0031793592300105402, 0.0031913229835085536, 0.0031810586451839827, 0.0031579910404399016, 0.0032259997638535935, 0.0031222312317149728, 0.0032801576892526377, 0.0031512865649181436, 0.0031586956799125898, 0.0031986167089557613, 0.003192491817747124, 0.0031624725616722442, 0.003202475793685107, 0.0033024198907709787, 0.0031942000839822273, 0.003178125876024236, 0.003167206110722674, 0.0032724855254730387, 0.003177318741288857, 0.0031534423062221633, 0.0031690929676312482, 0.003116506630098052, 0.003205389307216712, 0.0031446299243519243, 0.003183643789834987, 0.0031894609430866143, 0.0030769100713471374, 0.0033574211056752357, 0.0032249476822302364, 0.0032842575650924616, 0.0032494012214534175, 0.003148465738310302, 0.003104596587063507, 0.003225957900354896, 0.003248281994323816, 0.0030836037564551722, 0.0031883289728394993, 0.0033564135026944325, 0.0030961425603687896, 0.003107245776084708, 0.0031657610916297767, 0.0031572491550602906, 0.003129208858746218], [0.003372802238226858, 0.003666426849960493, 0.003478551140925321, 0.0032195767898410624, 0.0032382091326069707, 0.0032715139819201565, 0.003397201602051311, 0.003297839473444829, 0.0033980651431007093, 0.0033140719531997848, 0.0035702531746873594, 0.0033291938894387837, 0.00317496018309305, 0.0031659161027986957, 0.0032698827016305588, 0.003117494531517375, 0.0032363292571234298, 0.003684508843482285, 0.003173612629785258, 0.0031324669024415945, 0.0032525300319310086, 0.003169538785216018, 0.003277593263395004, 0.0031662415989778276, 0.0032876526883160125, 0.003086687023203602, 0.0031257357229917703, 0.0032741747802209815, 0.0031542323963522877, 0.003124847602359476, 0.0031633504756046656, 0.003204859551730599, 0.003144598631689873, 0.0030774388278575903, 0.0031532650233379975, 0.0032348003024436135, 0.003245735793472129, 0.0031224573045452887, 0.0030946487500979705, 0.003142690326032153, 0.003204020280686842, 0.0031041980715074678, 0.003041129825598778, 0.003104831443044536, 0.003030833339336776, 0.0031187382791706872, 0.0030707260679144603, 0.003168842716170651, 0.0032256332820194433, 0.0030460730999279117], [0.00341590501050164, 0.0032822010937571706, 0.0034819202191132405, 0.0031928677776567917, 0.003873829168926944, 0.0031850130875641296, 0.003316137968871849, 0.0033210624015959536, 0.0033844007770821457, 0.003194862838059556, 0.0031959865995175338, 0.0032203806781760194, 0.003250502038391333, 0.0032135964663324856, 0.003149071804302629, 0.0031570322099930027, 0.003121453314884517, 0.0031521399871833403, 0.0032555332190206693, 0.003091603491016235, 0.003199337273349296, 0.003122860072143536, 0.003209712011936967, 0.0032361778222572846, 0.0034209090842374813, 0.003203271453064587, 0.0033400172921376503, 0.0031315441858183325, 0.003095138951503828, 0.003163103633055669, 0.0030967318222823504, 0.0031477580211478813, 0.0030800209576828767, 0.003107989055806377, 0.0031813268591574357, 0.003119440457403534, 0.003091657917626528, 0.0031002067361183936, 0.003155462341279254, 0.0032460290260302796, 0.0031206577492930015, 0.00306189771089097, 0.003071927971676387, 0.003116239603544253, 0.0032410789777380564, 0.0030745537533193763, 0.0031486203523768182, 0.0031110379777179627, 0.0033319809840767945, 0.003096191849410054], [0.003396836207436681, 0.0032101453991422962, 0.0033806754798584083, 0.003301711848431061, 0.0031738239260627747, 0.003305027383311846, 0.0032106314563617477, 0.0031706337817806467, 0.003282461888208368, 0.0033204316916405872, 0.0032136604657230904, 0.0031350947857369978, 0.0031524255094347677, 0.0031355842429371217, 0.0032151363149993625, 0.0031542162495671656, 0.0035091033522630043, 0.0032541035534713243, 0.0032088420188682086, 0.003227629277963015, 0.003295443039936475, 0.003139226440328121, 0.0031749573915682582, 0.003134594795781929, 0.0032749149688347406, 0.0031377542496561915, 0.0031291057155387867, 0.003184361900408809, 0.0031189001530669736, 0.0031919346464515225, 0.0033552647408971008, 0.003176011517449638, 0.0031216532895186008, 0.0031065700315742292, 0.0032702425371001196, 0.003113889547670036, 0.0031892625969603765, 0.003112367416663876, 0.0032133516938816827, 0.003261357006117823, 0.003164850035929105, 0.0031049320133548293, 0.0031361038013384013, 0.0031729963243373803, 0.003090277895344934, 0.003120394288332415, 0.003068180006110886, 0.003155546054372949, 0.0030694011013426927, 0.0031398553557856605], [0.0033942251333765575, 0.0038008693873222894, 0.003312532954400069, 0.0034764654226441226, 0.0035626908536774246, 0.003249697705361669, 0.0032291960825599985, 0.003214918881091869, 0.003323107621193393, 0.003246497711868818, 0.0032493451526025706, 0.0031679001804056275, 0.0032214040305089168, 0.003441908226032582, 0.003323927129752442, 0.0031447778843275783, 0.0031852832138660856, 0.003206880638348603, 0.003284501625275306, 0.0031743976207896357, 0.0032611676352676607, 0.0031859232046109135, 0.003307040219064071, 0.0031906242496684604, 0.003143617614580961, 0.0031382537909004564, 0.003161314292331513, 0.0030748857918210695, 0.0031384574179159964, 0.003121922592603765, 0.003111403201146059, 0.003190137374303252, 0.003078010805610791, 0.0033737172747224237, 0.0030897746184555853, 0.0030929695914990274, 0.0031059090818525057, 0.0030941155069327017, 0.0032670469056018682, 0.003303022308599893, 0.003111998219648944, 0.003125787106828031, 0.0031937914972970396, 0.0032420325108353265, 0.0032139508917084837, 0.003154237025269482, 0.003064919172953885, 0.0031950451256042077, 0.0030782099713218547, 0.0033630528134509525]]\n",
            "(10, 50)\n",
            "0.003216852624721964\n",
            "[0.0032156  0.00320752 0.0032409  0.00322108 0.00322851 0.00320152\n",
            " 0.00322254 0.00320557 0.00319764 0.00322766]\n",
            "[0.00355794 0.0035204  0.00338024 0.00329807 0.00333592 0.00326935\n",
            " 0.00337427 0.00323154 0.00331347 0.00331318 0.00328066 0.00318562\n",
            " 0.00319244 0.00324827 0.00330992 0.00318921 0.00319085 0.00323734\n",
            " 0.00328027 0.00317526 0.0032602  0.00317509 0.00323339 0.00316841\n",
            " 0.00321224 0.00316242 0.00317665 0.00316683 0.00318245 0.00316024\n",
            " 0.00314813 0.00318443 0.00312926 0.00314773 0.00319303 0.00319187\n",
            " 0.00317861 0.00312638 0.00318582 0.00317325 0.00317898 0.00312708\n",
            " 0.00311588 0.00315505 0.00316291 0.00311426 0.00311813 0.00312146\n",
            " 0.00316878 0.00313943]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(np.mean(res, axis=0),\"g.\")\n",
        "plt.plot(np.min(res, axis=0),\"r.\")\n",
        "plt.plot(np.max(res, axis=0),\"b.\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "xDh441Omx04y",
        "outputId": "07902aa4-ed1f-4b38-bde3-6802ff223112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(np.mean(res, axis=0),\"g.\")\n",
        "plt.plot(np.min(res, axis=0),\"r.\")\n",
        "plt.plot(np.max(res, axis=0),\"b.\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "Nmvkkt3eP_6P",
        "outputId": "4d7f8f5e-404d-40b0-8592-e1afa80c5731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(res)):\n",
        "  plt.plot(res[i],\"g.\")\n",
        "dummy=mean_squared_error(test_y[HIST:], test_y[HIST-1:-1])\n",
        "plt.plot([dummy for _ in res[0]],\"r.\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RpKWxpoDz9Yu",
        "outputId": "e8c7d25d-1235-4dbb-8101-0e539ad1ae89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x2=train_x.reshape((train_x.shape[0], train_x.shape[1]*train_x.shape[2]))\n",
        "test_x2=test_x.reshape((test_x.shape[0], test_x.shape[1]*test_x.shape[2]))\n",
        "print(train_x2.shape, test_x2.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-YGsdiCuXB8",
        "outputId": "e316a43d-405e-4274-b38f-75258da7e962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19990, 30) (4990, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train with own simple MLP')\n",
        "\n",
        "import math, random, time\n",
        "\n",
        "# available activation functions\n",
        "def activation_tanh(x):     return math.tanh(x)     # (-1..1)\n",
        "def dactivation_tanh(x):    return 1.0 - x**2\n",
        "def activation_sigmoid(x):  return 1.0/(1.0 + math.exp(-x))   # (0..1)\n",
        "def dactivation_sigmoid(x): return x*(1.0-x)\n",
        "\n",
        "#acti, dacti = activation_sigmoid, dactivation_sigmoid\n",
        "acti, dacti = activation_tanh, dactivation_tanh\n",
        "\n",
        "B = 1\n",
        "#nn = [2+B, 4, 3, 3]\n",
        "nn = [len(train_x2[0])+B, 20, 10, len(train_y[0])]\n",
        "wl=[ [ [random.random()*0.4-0.2 for _ in range(nn[l])] for _ in range(nn[l+1])] for l in range(len(nn)-1)] \n",
        "#wl = [ numpy.random.random((nn[l+1], nn[l]))*0.8-0.4 for l in range(len(nn)-1) ]\n",
        "#wl = [numpy.linspace(-1,1,nn[l]*nn[l+1]).reshape((nn[l+1], nn[l])) for l in range(len(nn)-1)]\n",
        "#          3\n",
        "#[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "#                         8\n",
        "#[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
        "epoch = 0\n",
        "sumerr = len(train_x2)\n",
        "# training\n",
        "t00=time.time()\n",
        "while sumerr/len(train_x2)/nn[-1]>=0.0001 and epoch<20:\n",
        "    sumerr = 0.0\n",
        "    epoch += 1\n",
        "    t0=time.time()\n",
        "    #for inp, out in random.sample(samples, len(samples)):\n",
        "    for inp, out in zip(train_x2, train_y):\n",
        "        nl = [ list(inp) + [1.0]*B ]\n",
        "        for l in range(len(nn)-1):\n",
        "            nl.append([acti(sum([nl[l][i] * wl[l][j][i] for i in range(nn[l])])) for j in range(nn[l+1])])\n",
        "            \n",
        "        error = [out[j] - nl[-1][j] for j in range(nn[-1])]\n",
        "        delta = [None for _ in range(len(nn)-1)]\n",
        "        for l in reversed(range(len(nn)-1)):\n",
        "            if l == len(nn)-2:\n",
        "                delta[l] = [error[j] * dacti(nl[-1][j]) for j in range(nn[-1])]\n",
        "            else:\n",
        "                delta[l] = [sum([delta[l+1][j] * wl[l+1][j][i] for j in range(nn[l+2])])*dacti(nl[l+1][i]) for i in range(nn[l+1])]\n",
        "            \n",
        "            for i in range(nn[l]):\n",
        "                for j in range(nn[l+1]):\n",
        "                    wl[l][j][i] += 0.01 * delta[l][j] * nl[l][i]\n",
        "\n",
        "        sumerr += sum( [error[j]**2 for j in range(nn[-1])])\n",
        "    print (epoch,round(sumerr/len(train_x2)/nn[-1],3), round(time.time()-t0,3))\n",
        "print (epoch,round(sumerr/len(train_x2)/nn[-1],3), round(time.time()-t00,3))\n",
        "\n",
        "#testing\n",
        "y2=[]\n",
        "#for inp, out in random.sample(samples, len(samples)):\n",
        "for inp in test_x2:\n",
        "    nl = [ list(inp) + [1.0]*B ]\n",
        "    for l in range(len(nn)-1):\n",
        "        nl.append([acti(sum([nl[l][i] * wl[l][j][i] for i in range(nn[l])])) for j in range(nn[l+1])])\n",
        "        \n",
        "    y2.append(nl[-1])\n",
        "y2=np.array(y2)\n",
        "print('prediction MSE:', mean_squared_error(test_y, y2))\n",
        "print('dummy MSE:', mean_squared_error(test_y[1:], test_y[:-1]))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWdx51roTf_Z",
        "outputId": "c193dafe-2da9-4e7f-e7bc-73f033012fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train with own simple MLP\n",
            "1 0.006 18.687\n",
            "2 0.004 21.996\n",
            "3 0.004 18.712\n",
            "4 0.004 18.753\n",
            "5 0.004 18.655\n",
            "6 0.004 18.641\n",
            "7 0.003 18.693\n",
            "8 0.003 18.762\n",
            "9 0.003 18.754\n",
            "10 0.003 18.789\n",
            "11 0.003 19.172\n",
            "12 0.003 18.743\n",
            "13 0.003 20.749\n",
            "14 0.003 18.519\n",
            "15 0.003 18.608\n",
            "16 0.003 18.583\n",
            "17 0.003 18.582\n",
            "18 0.003 18.68\n",
            "19 0.003 18.652\n",
            "20 0.003 18.682\n",
            "20 0.003 379.436\n",
            "prediction MSE: 0.003498989085390193\n",
            "dummy MSE: 0.0038834861695730767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=[11,12,13,14,15]\n",
        "b=[21,22,23,24,25]\n",
        "[ (a,b) for a,b in zip(a,b) ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66n4eiVvaZfh",
        "outputId": "e9ea12bd-e65f-4e9e-aeb9-8bf6b3d68e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(11, 21), (12, 22), (13, 23), (14, 24), (15, 25)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=['x1','x2','x3','x4','x5']\n",
        "y=['y1','y2','y3','y4','y5']\n",
        "[ (_x,_y) for _x,_y in zip(x,y) ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOHIX2tPXqAN",
        "outputId": "6b1dcbe1-bc35-4ca9-861c-7db42acb1e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('x1', 'y1'), ('x2', 'y2'), ('x3', 'y3'), ('x4', 'y4'), ('x5', 'y5')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train with own simple MLP vectorized')\n",
        "import random, time\n",
        "def activation_tanh(x):     return np.tanh(x)     # (-1..1)\n",
        "def dactivation_tanh(x):    return 1.0 - x**2\n",
        "def activation_sigmoid(x):  return 1.0/(1.0 + np.exp(-x))   # (0..1)\n",
        "def dactivation_sigmoid(x): return x*(1.0-x)\n",
        "\n",
        "acti, dacti = activation_tanh, dactivation_tanh\n",
        "\n",
        "B = 1\n",
        "nn = [len(train_x2[0])+B, 100, 50, len(train_y[0])]\n",
        "wl = [ np.random.random((nn[l+1], nn[l]))*0.2-0.1 for l in range(len(nn)-1)] \n",
        "#wl = [numpy.linspace(-1,1,nn[l]*nn[l+1]).reshape((nn[l+1], nn[l])) for l in range(len(nn)-1)]\n",
        "delta = [np.zeros((nn[l+1])) for l in range(len(nn)-1)]\n",
        "\n",
        "epoch = 0\n",
        "sumerr = len(train_x2)\n",
        "t00=time.time()\n",
        "while sumerr/len(train_x2)/nn[-1]>=0.0001 and epoch<20:\n",
        "    sumerr = 0.0\n",
        "    epoch += 1\n",
        "    t0=time.time()\n",
        "    #for inp, out in random.sample(samples, len(samples)):\n",
        "    #for inp, out in zip(train_x2, train_y):\n",
        "    for inp, out in random.sample([(a,b) for a,b in zip(train_x2, train_y)],len(train_x2)):\n",
        "        nl = [ np.array(list(inp) + [1.0]*B) ]\n",
        "        for l in range(len(nn)-1):\n",
        "            nl.append(acti(np.dot(wl[l],nl[l])))\n",
        "        error = out - nl[-1]\n",
        "        #delta = [None for _ in range(len(nn)-1)]\n",
        "        for l in reversed(range(len(nn)-1)):\n",
        "            if l == len(nn)-2:\n",
        "                #delta[l] = error*dacti(nl[-1])\n",
        "                delta[l][:] = error*dacti(nl[-1])\n",
        "            else:\n",
        "                #delta[l] = numpy.dot(delta[l+1],wl[l+1])*dacti(nl[l+1])\n",
        "                np.dot(delta[l+1],wl[l+1], out=delta[l])\n",
        "                delta[l] *= dacti(nl[l+1])\n",
        "            \n",
        "            wl[l] += 0.01 * delta[l].reshape((nn[l+1],1))*nl[l].reshape((1,nn[l]))\n",
        "\n",
        "        sumerr += sum(error**2)\n",
        "    print (epoch,round(sumerr/len(train_x2)/nn[-1],3), round(time.time()-t0,3))\n",
        "print (epoch,round(sumerr/len(train_x2)/nn[-1],3), round(time.time()-t00,3))\n",
        "\n",
        "sumerr = 0.0\n",
        "y2=[]\n",
        "for inp in test_x2:\n",
        "    nl = [ np.array(list(inp) + [1.0]*B) ]\n",
        "    for l in range(len(nn)-1):\n",
        "        nl.append(acti(np.dot(wl[l],nl[l])))\n",
        "    y2.append(nl[-1])\n",
        "y2=np.array(y2)\n",
        "print('prediction MSE:', mean_squared_error(test_y, y2))\n",
        "print('dummy MSE:', mean_squared_error(test_y[1:], test_y[:-1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sN8rV6vTiGQ",
        "outputId": "90a88063-d1b3-4ab8-c878-3e4b3c4f1f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train with own simple MLP vectorized\n",
            "1 0.006 1.907\n",
            "2 0.004 1.84\n",
            "3 0.004 2.275\n",
            "4 0.004 1.83\n",
            "5 0.004 1.826\n",
            "6 0.003 1.871\n",
            "7 0.003 1.905\n",
            "8 0.003 1.836\n",
            "9 0.003 1.834\n",
            "10 0.003 1.796\n",
            "11 0.003 1.822\n",
            "12 0.003 1.902\n",
            "13 0.003 1.846\n",
            "14 0.003 1.835\n",
            "15 0.003 1.838\n",
            "16 0.003 1.816\n",
            "17 0.003 1.883\n",
            "18 0.003 1.822\n",
            "19 0.003 1.836\n",
            "20 0.003 1.831\n",
            "20 0.003 37.365\n",
            "prediction MSE: 0.0033660413475829543\n",
            "dummy MSE: 0.0038834861695730763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train with own simple MLP vectorized + momentum')\n",
        "import random, time\n",
        "\n",
        "def activation_tanh(x):     return np.tanh(x)     # (-1..1)\n",
        "def dactivation_tanh(x):    return 1.0 - x**2\n",
        "def activation_sigmoid(x):  return 1.0/(1.0 + np.exp(-x))   # (0..1)\n",
        "def dactivation_sigmoid(x): return x*(1.0-x)\n",
        "\n",
        "acti, dacti = activation_tanh, dactivation_tanh\n",
        "\n",
        "B=1\n",
        "nn = [len(train_x2[0])+B, 100, 50, len(train_y[0])]\n",
        "wl = [ np.random.random((nn[l+1], nn[l]))*0.2-0.1 for l in range(len(nn)-1)] \n",
        "#wl = [numpy.linspace(-1,1,nn[l]*nn[l+1]).reshape((nn[l+1], nn[l])) for l in range(len(nn)-1)]\n",
        "delta = [np.zeros((nn[l+1])) for l in range(len(nn)-1)]\n",
        "cl = [np.zeros_like(_w) for _w in wl]\n",
        "epoch = 0\n",
        "sumerr = len(train_x2)\n",
        "t00=time.time()\n",
        "while sumerr/len(train_x2)>=0.0001 and epoch<20:\n",
        "    sumerr = 0.0\n",
        "    epoch += 1\n",
        "    t0=time.time()\n",
        "    #for inp, out in random.sample(samples, len(samples)):\n",
        "    #for inp, out in zip(train_x2, train_y):\n",
        "    for inp, out in random.sample([(a,b) for a,b in zip(train_x2, train_y)],len(train_x2)):\n",
        "        nl = [ np.array(list(inp) + [1.0]*B) ]\n",
        "        for l in range(len(nn)-1):\n",
        "            nl.append(acti(np.dot(wl[l],nl[l])))\n",
        "        error = out - nl[-1]\n",
        "        #delta = [None for _ in range(len(nn)-1)]\n",
        "        for l in reversed(range(len(nn)-1)):\n",
        "            if l == len(nn)-2:\n",
        "                #delta[l] = error*dacti(nl[-1])\n",
        "                delta[l][:] = error*dacti(nl[-1])\n",
        "            else:\n",
        "                #delta[l] = numpy.dot(delta[l+1],wl[l+1])*dacti(nl[l+1])\n",
        "                np.dot(delta[l+1],wl[l+1], out=delta[l])\n",
        "                delta[l] *= dacti(nl[l+1])\n",
        "            \n",
        "            wl[l] += 0.2*cl[l]\n",
        "            cl[l][:]=0.01 * delta[l].reshape((nn[l+1],1))*nl[l].reshape((1,nn[l]))\n",
        "            wl[l] += 0.8*cl[l]\n",
        "\n",
        "        sumerr += sum( [error[j]**2 for j in range(nn[-1])])\n",
        "    print (epoch,round(sumerr/len(train_x2)/nn[-1],3), round(time.time()-t0,3))\n",
        "print (epoch,round(sumerr/len(train_x2)/nn[-1],3), round(time.time()-t00,3))\n",
        "\n",
        "sumerr = 0.0\n",
        "y2=[]\n",
        "#for inp, out in random.sample(samples, len(samples)):\n",
        "for inp in test_x2:\n",
        "    nl = [ np.array(list(inp) + [1.0]*B) ]\n",
        "    for l in range(len(nn)-1):\n",
        "        nl.append(acti(np.dot(wl[l],nl[l])))\n",
        "    y2.append(nl[-1])\n",
        "y2=np.array(y2)\n",
        "print('prediction MSE:', mean_squared_error(test_y, y2))\n",
        "print('stupid MSE:', mean_squared_error(test_y[1:], test_y[:-1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqMd5PhPxBwQ",
        "outputId": "75bc6e5f-305a-4a81-cbb7-ee5859fba259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train with own simple MLP vectorized + momentum\n",
            "1 0.006 2.712\n",
            "2 0.004 2.42\n",
            "3 0.004 2.464\n",
            "4 0.004 2.407\n",
            "5 0.004 2.501\n",
            "6 0.003 2.385\n",
            "7 0.003 2.411\n",
            "8 0.003 2.373\n",
            "9 0.003 2.406\n",
            "10 0.003 2.449\n",
            "11 0.003 2.411\n",
            "12 0.003 2.407\n",
            "13 0.003 2.424\n",
            "14 0.003 2.438\n",
            "15 0.003 2.457\n",
            "16 0.003 2.391\n",
            "17 0.003 2.396\n",
            "18 0.003 2.492\n",
            "19 0.003 2.373\n",
            "20 0.003 2.401\n",
            "20 0.003 48.738\n",
            "prediction MSE: 0.003114472911873856\n",
            "stupid MSE: 0.0038834861695730763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in zip(test_y, y):\n",
        "  for _a, _b in zip(a*70-35, b*70-35):\n",
        "    print(round(_a,2), round(_b,2), end=\"; \")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AjW5-cC2OxX",
        "outputId": "5e5ccc41-30e2-4983-9696-a87dc313c94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.3 12.88; 14.3 17.97; 6.6 7.68; \n",
            "10.1 10.14; 15.0 14.13; 7.0 5.54; \n",
            "9.2 10.86; 9.8 15.05; 8.0 6.51; \n",
            "10.6 9.46; 14.8 11.92; 9.1 6.36; \n",
            "8.4 10.92; 10.2 14.56; 7.5 7.33; \n",
            "8.5 8.8; 13.0 11.29; 2.7 5.56; \n",
            "9.4 9.33; 14.2 13.03; 5.5 4.64; \n",
            "11.8 9.9; 15.5 13.89; 7.0 5.38; \n",
            "10.9 11.82; 13.1 15.79; 9.2 7.42; \n",
            "10.4 10.33; 11.7 13.07; 6.5 6.89; \n",
            "6.8 10.11; 11.6 12.53; 5.5 6.73; \n",
            "9.7 6.61; 12.0 9.01; 5.7 2.98; \n",
            "9.4 10.1; 16.2 12.88; 6.0 6.53; \n",
            "9.7 9.61; 15.2 13.6; 6.5 4.97; \n",
            "4.9 9.89; 8.7 13.51; 3.6 5.88; \n",
            "4.2 4.86; 7.8 7.29; -0.6 1.26; \n",
            "2.3 5.15; 5.3 8.17; -0.2 0.94; \n",
            "4.8 2.99; 8.1 5.42; 1.7 -0.94; \n",
            "5.1 5.49; 6.5 8.19; 2.3 1.79; \n",
            "6.9 5.21; 8.0 7.09; 5.1 2.06; \n",
            "7.5 6.79; 8.3 8.69; 5.8 4.08; \n",
            "9.9 7.14; 10.6 8.8; 8.0 4.38; \n",
            "10.4 9.18; 11.1 11.34; 9.4 6.49; \n",
            "11.2 9.15; 13.2 10.86; 9.5 6.83; \n",
            "10.7 9.76; 13.5 11.67; 9.0 7.44; \n",
            "10.8 9.26; 13.8 11.12; 9.4 6.81; \n",
            "9.6 9.63; 12.4 11.75; 5.7 7.12; \n",
            "9.5 8.85; 12.1 10.82; 7.6 5.86; \n",
            "9.2 8.91; 10.1 10.82; 8.0 6.21; \n",
            "8.6 8.66; 9.5 9.82; 7.8 6.43; \n",
            "7.1 8.13; 8.7 9.13; 6.0 6.0; \n",
            "5.2 7.03; 6.2 7.97; 4.2 4.68; \n",
            "3.1 5.36; 6.8 5.97; 1.2 3.07; \n",
            "1.9 3.64; 4.1 5.03; -0.8 0.55; \n",
            "2.2 2.76; 2.7 4.09; 0.8 -0.47; \n",
            "2.8 2.92; 3.6 3.63; 1.5 0.47; \n",
            "1.6 3.14; 3.2 3.83; 1.0 0.67; \n",
            "3.1 1.79; 5.6 2.31; 0.7 -0.62; \n",
            "4.0 3.42; 5.2 4.8; 1.4 0.66; \n",
            "5.7 3.99; 8.0 5.14; 4.6 1.53; \n",
            "3.8 5.21; 6.2 6.63; 3.2 2.89; \n",
            "1.5 3.07; 4.3 4.05; 0.0 0.8; \n",
            "-1.4 1.05; 1.0 2.41; -2.8 -1.42; \n",
            "2.8 -1.64; 4.5 -0.55; -2.2 -4.08; \n",
            "5.2 3.21; 6.7 4.99; 3.2 0.28; \n",
            "4.2 4.59; 7.7 5.85; 3.1 2.26; \n",
            "1.8 3.4; 3.5 4.98; 1.0 0.89; \n",
            "0.8 1.35; 2.1 2.18; -2.2 -0.79; \n",
            "3.4 1.09; 4.2 2.35; 1.6 -1.7; \n",
            "3.1 3.37; 4.5 4.61; 2.2 0.92; \n",
            "7.7 2.52; 9.5 3.33; 3.5 0.38; \n",
            "5.7 6.87; 8.2 8.74; 4.7 4.3; \n",
            "7.4 4.39; 9.5 5.59; 4.0 2.38; \n",
            "9.5 6.7; 12.7 8.54; 7.3 3.97; \n",
            "7.0 8.53; 11.8 10.92; 3.8 5.71; \n",
            "3.8 6.18; 5.5 8.65; 1.2 2.72; \n",
            "6.0 3.14; 7.8 4.33; 1.4 0.6; \n",
            "4.9 5.78; 9.0 7.63; 2.9 2.78; \n",
            "0.0 4.48; 3.1 6.32; -1.3 1.15; \n",
            "-1.3 0.07; 0.0 1.34; -4.9 -3.04; \n",
            "-1.0 -0.45; 0.5 1.08; -4.6 -3.7; \n",
            "1.2 0.26; 1.7 1.73; -0.3 -3.16; \n",
            "7.9 2.08; 9.9 3.19; 1.5 -1.04; \n",
            "7.4 8.06; 10.9 10.81; 5.3 4.32; \n",
            "6.0 6.41; 9.8 8.76; 3.5 3.28; \n",
            "2.9 5.4; 7.2 7.58; 1.5 2.25; \n",
            "2.5 2.35; 4.0 4.48; 0.7 -1.09; \n",
            "1.3 2.4; 2.8 4.07; 0.6 -0.37; \n",
            "3.0 0.65; 6.3 1.72; 0.0 -1.71; \n",
            "-0.8 2.59; 2.4 4.42; -1.5 -0.13; \n",
            "1.5 -1.43; 2.4 -0.16; -1.1 -3.95; \n",
            "1.5 2.23; 2.1 3.74; 0.6 -0.16; \n",
            "1.9 1.57; 4.4 2.47; 0.7 -0.84; \n",
            "0.7 2.0; 2.3 3.5; -0.9 -0.77; \n",
            "0.4 0.5; 1.8 1.71; -1.5 -1.96; \n",
            "6.2 0.39; 8.8 1.66; 1.0 -1.82; \n",
            "5.7 5.99; 8.8 8.21; 3.8 2.96; \n",
            "4.1 4.68; 6.6 6.44; 2.8 1.99; \n",
            "3.4 3.16; 4.9 4.62; 1.3 0.75; \n",
            "0.4 2.76; 3.9 3.9; -1.4 0.55; \n",
            "1.9 -0.03; 3.5 1.29; -0.4 -3.02; \n",
            "0.6 1.96; 2.5 3.34; -2.6 -0.71; \n",
            "1.6 0.41; 2.1 1.73; 0.9 -2.33; \n",
            "1.4 1.58; 3.5 2.23; 0.3 -0.36; \n",
            "-0.2 1.35; 2.9 2.34; -1.6 -1.1; \n",
            "-1.5 -0.16; -0.7 1.35; -2.3 -3.23; \n",
            "-0.6 -1.13; -0.2 -0.28; -1.7 -3.34; \n",
            "1.0 -0.29; 2.1 0.5; -1.4 -2.38; \n",
            "1.2 1.16; 2.5 2.09; 0.5 -1.18; \n",
            "0.9 0.78; 1.8 1.66; -0.9 -1.22; \n",
            "3.5 0.61; 6.8 1.26; 0.6 -1.23; \n",
            "3.4 3.06; 8.1 4.78; 1.4 0.45; \n",
            "4.6 2.69; 5.6 4.61; 0.0 -0.2; \n",
            "6.7 4.13; 9.8 5.81; 3.7 1.44; \n",
            "5.1 5.61; 8.3 7.73; 0.2 2.93; \n",
            "5.5 4.27; 10.5 6.14; -0.5 0.96; \n",
            "4.9 5.07; 9.5 8.01; 2.1 0.97; \n",
            "4.1 4.36; 7.2 6.97; 1.4 0.81; \n",
            "3.0 3.73; 4.8 5.64; 1.1 0.42; \n",
            "5.3 2.9; 11.2 4.38; -0.7 -0.15; \n",
            "7.2 5.55; 10.7 9.33; 3.1 0.72; \n",
            "5.8 6.99; 11.0 10.15; 3.0 3.22; \n",
            "2.1 5.58; 5.4 8.98; 0.7 1.54; \n",
            "-0.5 2.05; 2.0 4.22; -1.6 -1.38; \n",
            "-1.3 -0.05; 0.4 1.89; -4.0 -3.34; \n",
            "-2.3 -0.74; 1.7 1.46; -3.6 -4.3; \n",
            "-5.1 -1.98; -1.2 0.42; -6.9 -5.32; \n",
            "-7.7 -4.66; -4.5 -2.46; -10.8 -8.18; \n",
            "-11.3 -6.48; -8.6 -3.95; -12.3 -10.63; \n",
            "-11.2 -10.39; -8.9 -8.27; -15.8 -14.8; \n",
            "-11.0 -9.18; -8.8 -6.57; -13.7 -14.55; \n",
            "-11.4 -9.51; -7.5 -7.29; -14.1 -13.91; \n",
            "-13.0 -9.98; -9.0 -7.3; -16.0 -14.64; \n",
            "-11.8 -11.72; -7.0 -9.37; -16.8 -16.83; \n",
            "-6.6 -9.45; -3.5 -5.49; -11.3 -15.39; \n",
            "-8.7 -4.08; -3.2 -0.07; -10.6 -8.57; \n",
            "-7.8 -7.89; -5.1 -4.3; -12.0 -12.38; \n",
            "-15.7 -6.06; -6.8 -2.68; -18.5 -10.27; \n",
            "-10.4 -16.22; -7.1 -12.04; -18.8 -22.89; \n",
            "-4.0 -7.23; -2.5 -2.26; -8.2 -13.2; \n",
            "-8.9 -2.28; -2.6 1.11; -11.0 -5.79; \n",
            "-11.5 -8.93; -8.2 -5.41; -12.8 -13.8; \n",
            "-8.7 -10.83; -7.4 -8.65; -12.6 -15.35; \n",
            "-10.0 -6.75; -5.7 -3.36; -12.4 -11.07; \n",
            "-11.5 -9.08; -4.5 -5.67; -16.6 -14.14; \n",
            "-12.6 -10.64; -6.7 -5.98; -16.7 -16.24; \n",
            "-6.3 -11.64; -3.2 -7.26; -15.4 -17.15; \n",
            "-0.3 -3.37; 0.4 2.03; -3.3 -8.62; \n",
            "-1.2 0.72; 0.9 3.58; -2.5 -2.6; \n",
            "-3.0 -1.27; -1.7 0.8; -3.6 -4.37; \n",
            "-4.0 -3.16; -2.8 -1.3; -5.3 -5.81; \n",
            "-2.8 -3.82; -0.1 -2.25; -4.8 -6.3; \n",
            "-2.7 -2.86; 2.2 -0.76; -5.7 -6.04; \n",
            "-5.7 -3.09; -1.5 -0.24; -7.5 -6.47; \n",
            "-4.3 -6.37; 2.1 -3.75; -11.1 -9.67; \n",
            "-5.0 -3.65; 2.3 0.83; -11.2 -8.36; \n",
            "-1.3 -4.73; 3.2 0.01; -8.1 -10.26; \n",
            "3.6 -0.16; 6.4 3.93; -0.8 -4.95; \n",
            "4.4 3.54; 9.1 6.75; 2.3 -0.04; \n",
            "5.7 3.5; 9.8 6.53; 1.4 0.06; \n",
            "5.2 4.83; 9.3 8.29; 3.1 1.06; \n",
            "6.0 4.02; 9.5 7.39; 2.6 0.69; \n",
            "4.8 4.9; 9.3 8.18; 3.7 1.37; \n",
            "2.8 3.48; 5.6 6.41; 0.4 0.25; \n",
            "2.2 1.88; 6.1 4.44; 0.5 -1.24; \n",
            "-2.3 1.38; 0.9 4.14; -3.3 -1.6; \n",
            "-2.0 -2.62; 2.1 -0.68; -4.6 -5.57; \n",
            "-2.1 -1.37; 0.4 1.48; -4.3 -5.1; \n",
            "-4.3 -1.38; -0.5 0.85; -6.9 -4.52; \n",
            "-1.6 -3.7; 2.2 -0.99; -7.8 -7.66; \n",
            "-0.4 -0.24; 1.4 3.11; -3.3 -4.59; \n",
            "0.6 0.19; 2.4 2.51; -1.8 -3.24; \n",
            "2.6 0.94; 5.2 2.97; -0.5 -2.14; \n",
            "3.7 2.52; 5.7 4.76; 1.2 -0.7; \n",
            "3.5 3.13; 5.8 5.05; 1.4 0.34; \n",
            "2.4 2.66; 4.3 4.56; 0.2 -0.03; \n",
            "0.8 1.69; 3.4 3.3; -0.3 -0.87; \n",
            "1.5 0.2; 5.2 1.61; -2.7 -2.47; \n",
            "2.4 1.32; 4.2 3.7; -1.0 -2.07; \n",
            "4.2 2.02; 6.7 3.82; 1.6 -0.84; \n",
            "5.5 3.73; 10.7 5.5; 1.9 0.97; \n",
            "3.6 4.94; 7.0 7.73; 0.3 1.38; \n",
            "4.0 3.25; 5.7 5.49; 1.3 -0.15; \n",
            "2.7 3.78; 4.4 5.74; 2.3 0.86; \n",
            "4.8 2.19; 7.2 3.34; 0.9 -0.2; \n",
            "5.3 4.64; 11.8 6.63; 0.5 1.39; \n",
            "7.5 4.84; 14.4 8.31; -0.2 0.68; \n",
            "8.6 7.32; 16.8 11.72; 1.1 2.43; \n",
            "11.5 8.54; 18.3 13.7; 2.2 2.95; \n",
            "11.3 11.65; 16.0 17.31; 6.0 5.61; \n",
            "9.8 10.76; 15.0 15.46; 7.3 5.67; \n",
            "10.7 9.18; 16.3 13.32; 3.7 4.79; \n",
            "11.3 10.58; 16.7 15.28; 6.3 5.22; \n",
            "5.2 11.15; 10.5 15.97; 3.6 6.13; \n",
            "5.8 5.05; 11.2 8.57; 0.3 0.48; \n",
            "2.3 6.58; 6.9 10.81; 0.5 1.37; \n",
            "2.9 3.0; 7.5 6.47; -2.5 -1.74; \n",
            "5.2 4.11; 8.0 8.29; 0.0 -1.14; \n",
            "11.1 5.96; 16.6 9.5; 5.7 1.37; \n",
            "13.3 11.36; 20.8 16.43; 7.7 6.26; \n",
            "12.5 12.94; 19.6 18.8; 8.6 7.7; \n",
            "14.1 12.17; 19.4 17.86; 7.6 7.08; \n",
            "15.1 13.48; 20.4 18.77; 9.5 8.27; \n",
            "16.1 14.21; 20.1 19.54; 13.2 9.24; \n",
            "17.0 14.81; 23.4 19.51; 11.2 10.46; \n",
            "18.5 15.65; 24.8 20.92; 12.6 10.81; \n",
            "11.8 17.02; 18.0 22.54; 8.6 12.21; \n",
            "8.1 11.75; 12.7 16.39; 3.6 6.92; \n",
            "6.9 9.03; 10.3 12.89; 3.2 3.98; \n",
            "9.5 8.2; 13.5 11.67; 2.7 3.25; \n",
            "8.0 10.72; 13.5 14.89; 3.5 5.17; \n",
            "9.2 8.95; 11.8 13.09; 7.3 3.67; \n",
            "11.9 9.88; 16.0 13.23; 5.6 5.79; \n",
            "13.6 12.54; 19.0 17.01; 5.1 7.43; \n",
            "13.8 14.2; 17.9 19.75; 9.3 8.09; \n",
            "12.8 13.74; 14.8 18.53; 10.5 8.61; \n",
            "14.0 12.08; 18.8 15.41; 11.5 8.29; \n",
            "14.6 13.4; 19.0 17.47; 9.1 9.25; \n",
            "13.2 14.13; 18.0 18.48; 11.6 9.54; \n",
            "8.9 12.62; 12.4 16.58; 7.4 8.72; \n",
            "11.4 8.95; 16.7 11.67; 6.6 5.31; \n",
            "15.6 12.04; 20.9 16.19; 9.6 7.41; \n",
            "15.6 15.64; 20.0 20.76; 11.6 10.69; \n",
            "14.3 15.12; 20.3 19.93; 7.8 10.63; \n",
            "15.1 14.43; 21.6 19.25; 8.1 9.35; \n",
            "18.6 15.59; 24.5 21.17; 10.2 9.97; \n",
            "19.4 18.32; 23.8 24.13; 15.6 12.57; \n",
            "18.5 18.48; 23.2 23.89; 15.6 13.56; \n",
            "15.8 17.55; 26.0 22.36; 9.2 13.05; \n",
            "12.9 16.23; 17.6 22.33; 11.5 10.19; \n",
            "14.0 13.66; 18.9 18.39; 9.0 8.98; \n",
            "13.2 14.8; 14.6 19.77; 12.2 9.35; \n",
            "15.5 13.49; 19.4 16.96; 11.8 9.62; \n",
            "15.8 15.54; 20.7 19.98; 12.3 11.03; \n",
            "14.9 15.66; 19.4 20.61; 10.1 11.23; \n",
            "16.8 15.34; 22.3 20.08; 8.7 10.55; \n",
            "16.0 17.1; 22.4 22.47; 13.0 11.37; \n",
            "15.5 16.27; 21.5 21.52; 12.5 11.31; \n",
            "10.1 15.63; 13.5 20.54; 9.4 10.58; \n",
            "14.0 10.49; 18.2 13.53; 7.0 6.76; \n",
            "15.2 14.56; 17.7 19.01; 12.0 9.57; \n",
            "15.9 15.24; 19.2 19.49; 11.9 11.08; \n",
            "18.2 15.83; 24.2 20.21; 11.1 11.43; \n",
            "15.3 17.81; 20.2 23.19; 12.6 12.55; \n",
            "15.1 15.29; 18.0 19.98; 13.1 10.83; \n",
            "17.6 14.91; 22.5 18.82; 13.2 10.77; \n",
            "18.5 17.32; 23.4 22.21; 13.1 12.63; \n",
            "19.8 18.02; 25.7 22.9; 11.6 13.11; \n",
            "20.5 18.95; 26.3 24.34; 14.2 13.77; \n",
            "21.4 19.64; 27.3 25.22; 13.1 14.46; \n",
            "21.0 20.58; 25.8 26.18; 13.5 14.99; \n",
            "19.0 20.24; 26.0 25.69; 14.5 14.71; \n",
            "19.3 19.0; 25.7 24.56; 15.0 13.38; \n",
            "21.1 19.25; 26.6 24.68; 15.2 13.91; \n",
            "22.8 20.64; 28.2 26.17; 15.9 15.24; \n",
            "24.1 21.69; 29.7 27.31; 16.4 16.14; \n",
            "23.0 22.45; 29.3 28.05; 18.0 16.96; \n",
            "22.0 21.94; 28.0 27.66; 17.1 16.46; \n",
            "13.3 21.39; 20.7 26.99; 10.4 15.95; \n",
            "15.4 14.98; 20.2 20.08; 10.8 9.1; \n",
            "19.2 16.69; 22.9 21.57; 12.4 11.22; \n",
            "21.6 19.39; 28.3 24.62; 15.2 13.77; \n",
            "21.8 21.09; 26.2 26.89; 17.6 15.43; \n",
            "22.7 20.92; 28.8 26.41; 16.2 15.96; \n",
            "17.0 21.58; 27.0 27.34; 15.0 16.19; \n",
            "14.9 18.29; 19.5 24.52; 12.3 12.35; \n",
            "17.8 16.16; 22.0 21.13; 9.8 10.94; \n",
            "20.7 18.07; 24.0 23.12; 14.8 12.38; \n",
            "19.8 19.83; 25.3 24.99; 16.6 14.78; \n",
            "20.1 19.22; 23.7 24.55; 17.2 14.45; \n",
            "13.0 19.4; 19.5 24.43; 11.4 15.04; \n",
            "13.3 14.32; 15.7 19.0; 10.5 9.19; \n",
            "14.8 14.41; 18.5 18.13; 13.2 10.02; \n",
            "15.5 15.44; 18.8 19.62; 13.3 11.0; \n",
            "17.1 15.68; 21.5 19.67; 12.0 11.47; \n",
            "15.8 16.94; 19.2 21.55; 13.2 12.59; \n",
            "17.3 15.76; 22.8 20.08; 12.7 11.77; \n",
            "17.7 17.43; 22.6 22.42; 14.0 12.74; \n",
            "16.8 17.74; 22.4 22.76; 13.0 13.03; \n",
            "18.6 16.88; 22.8 21.63; 12.5 12.2; \n",
            "23.2 17.89; 28.6 22.64; 15.5 13.28; \n",
            "22.9 21.43; 29.5 26.91; 17.0 16.48; \n",
            "21.2 21.43; 25.8 27.08; 16.8 16.34; \n",
            "18.7 20.15; 21.7 25.32; 16.3 15.45; \n",
            "21.5 18.17; 27.5 22.63; 15.4 13.84; \n",
            "24.1 20.69; 30.2 26.02; 17.0 15.59; \n",
            "20.5 22.52; 25.6 27.99; 17.6 17.2; \n",
            "23.6 19.96; 29.5 25.1; 15.0 15.1; \n",
            "21.3 22.09; 27.0 27.48; 16.9 16.69; \n",
            "22.3 20.95; 28.5 26.53; 13.7 15.68; \n",
            "22.7 21.88; 29.2 27.44; 16.6 15.89; \n",
            "22.7 22.01; 27.7 27.66; 18.7 16.35; \n",
            "23.3 21.81; 28.4 27.1; 16.4 16.72; \n",
            "22.5 22.12; 29.8 27.5; 17.3 16.79; \n",
            "21.4 22.02; 26.9 27.78; 17.5 16.41; \n",
            "20.8 21.2; 26.0 26.62; 18.7 15.78; \n",
            "17.4 20.58; 21.2 25.87; 16.7 15.75; \n",
            "20.4 18.07; 25.5 22.67; 14.1 13.4; \n",
            "22.2 20.3; 26.5 25.46; 14.8 15.08; \n",
            "20.3 21.44; 25.1 26.8; 17.8 16.14; \n",
            "21.0 20.08; 26.0 25.29; 17.5 15.22; \n",
            "20.8 20.49; 25.5 25.58; 17.0 15.8; \n",
            "19.5 20.37; 24.7 25.51; 17.3 15.56; \n",
            "16.8 19.41; 20.3 24.38; 15.2 14.75; \n",
            "18.2 17.22; 23.0 21.46; 13.4 12.99; \n",
            "19.4 18.58; 24.3 23.3; 14.0 13.72; \n",
            "24.5 19.47; 29.7 24.63; 17.7 14.51; \n",
            "25.6 22.53; 30.8 27.92; 17.8 17.67; \n",
            "26.0 23.18; 32.5 28.56; 20.5 18.16; \n",
            "24.8 23.52; 30.6 28.96; 21.1 18.6; \n",
            "22.1 22.86; 27.5 28.18; 18.8 18.14; \n",
            "21.1 21.31; 25.9 26.48; 17.6 16.44; \n",
            "18.3 20.68; 23.5 25.6; 14.3 15.81; \n",
            "17.1 18.75; 20.7 23.6; 16.2 13.74; \n",
            "17.7 17.65; 22.5 21.9; 14.2 13.38; \n",
            "19.1 18.46; 25.5 23.37; 12.7 13.57; \n",
            "23.2 19.72; 28.4 25.21; 14.4 14.18; \n",
            "26.1 22.28; 33.5 27.87; 17.0 16.73; \n",
            "19.3 23.91; 26.1 29.66; 17.0 18.24; \n",
            "20.6 19.69; 27.3 25.26; 13.2 14.31; \n",
            "22.6 20.69; 29.0 26.33; 14.7 14.76; \n",
            "25.2 21.88; 31.6 27.63; 17.6 16.05; \n",
            "19.4 23.34; 25.2 28.92; 17.5 17.7; \n",
            "18.0 19.4; 23.3 24.76; 13.2 14.28; \n",
            "22.8 18.56; 29.0 23.76; 13.0 13.17; \n",
            "17.0 22.15; 23.5 27.98; 15.0 15.95; \n",
            "20.3 18.19; 25.2 23.96; 13.0 12.48; \n",
            "22.6 20.26; 30.0 25.58; 16.8 14.37; \n",
            "25.0 21.83; 31.8 27.78; 18.1 16.18; \n",
            "22.3 23.19; 30.2 29.0; 19.4 17.69; \n",
            "22.8 21.65; 29.5 27.64; 17.0 16.27; \n",
            "22.7 22.05; 30.5 27.74; 19.0 16.44; \n",
            "19.7 21.95; 25.6 27.82; 16.9 16.55; \n",
            "16.8 19.85; 20.1 25.39; 16.0 14.76; \n",
            "16.8 17.19; 20.6 21.67; 13.3 12.69; \n",
            "20.4 17.35; 26.1 21.93; 12.7 12.78; \n",
            "17.7 20.36; 22.0 25.94; 16.8 14.77; \n",
            "24.3 18.11; 32.5 23.11; 15.3 13.53; \n",
            "24.9 22.8; 32.1 28.6; 20.2 17.12; \n",
            "25.1 23.01; 30.5 28.8; 19.2 17.95; \n",
            "17.4 23.04; 25.4 28.52; 14.9 17.93; \n",
            "18.3 18.07; 24.9 23.66; 12.8 12.58; \n",
            "19.6 19.1; 27.4 24.58; 12.2 13.51; \n",
            "22.6 20.13; 31.7 26.08; 14.5 13.94; \n",
            "23.7 22.06; 32.1 28.21; 16.7 16.03; \n",
            "20.5 22.61; 27.7 28.68; 18.3 16.64; \n",
            "19.1 20.41; 26.0 26.53; 15.3 15.18; \n",
            "20.6 19.78; 28.5 25.81; 12.6 13.88; \n",
            "21.1 21.1; 26.0 27.41; 16.1 14.58; \n",
            "18.2 20.85; 24.0 26.56; 16.8 15.23; \n",
            "20.4 18.3; 26.9 23.75; 14.7 13.26; \n",
            "21.0 20.14; 29.2 25.83; 14.3 14.68; \n",
            "20.0 20.92; 25.5 27.16; 16.6 14.86; \n",
            "15.6 19.86; 20.1 25.59; 13.3 14.54; \n",
            "11.9 16.4; 16.0 21.21; 9.6 11.32; \n",
            "12.7 13.43; 18.5 17.49; 9.3 8.51; \n",
            "13.1 14.29; 20.2 19.14; 6.2 9.04; \n",
            "16.6 14.69; 23.7 20.24; 8.5 8.52; \n",
            "15.0 17.56; 19.5 23.53; 13.7 11.34; \n",
            "13.9 15.49; 19.2 20.6; 9.0 10.78; \n",
            "11.2 14.71; 18.5 19.75; 6.6 9.33; \n",
            "12.6 12.71; 20.8 18.23; 4.8 6.56; \n",
            "12.6 14.21; 21.2 20.35; 6.8 7.55; \n",
            "14.4 13.74; 23.8 19.8; 6.9 7.45; \n",
            "15.3 15.52; 25.1 22.17; 8.2 8.79; \n",
            "16.0 16.08; 23.5 23.05; 10.0 9.27; \n",
            "14.7 16.41; 21.3 23.11; 10.7 10.22; \n",
            "16.3 15.26; 22.7 21.59; 9.0 9.22; \n",
            "18.4 16.75; 24.3 23.0; 13.5 10.6; \n",
            "15.0 17.97; 19.7 24.13; 13.2 12.34; \n",
            "17.0 14.71; 24.9 19.86; 10.8 9.96; \n",
            "17.7 16.88; 26.3 22.93; 11.9 11.0; \n",
            "17.7 17.85; 26.8 24.3; 12.0 11.78; \n",
            "18.1 17.9; 27.0 24.45; 11.8 11.63; \n",
            "18.5 18.35; 25.5 24.87; 12.8 12.06; \n",
            "15.0 18.63; 18.8 24.86; 13.7 12.64; \n",
            "13.9 15.2; 18.9 20.14; 11.8 10.59; \n",
            "7.5 14.49; 13.2 19.51; 5.9 9.72; \n",
            "8.0 8.84; 13.2 12.82; 5.5 3.91; \n",
            "8.2 9.62; 14.2 13.84; 4.1 5.0; \n",
            "8.5 9.68; 13.4 14.39; 3.6 4.31; \n",
            "9.3 9.88; 15.3 14.35; 5.7 4.55; \n",
            "6.0 10.36; 13.0 15.25; 1.5 5.1; \n",
            "7.6 7.16; 15.1 12.01; 2.1 1.47; \n",
            "10.5 8.96; 15.8 14.31; 5.5 3.04; \n",
            "13.3 11.27; 17.0 16.55; 8.2 5.99; \n",
            "9.2 12.94; 15.8 17.63; 7.1 8.27; \n",
            "7.5 8.95; 15.8 13.46; 2.2 4.34; \n",
            "7.6 8.04; 15.6 13.31; 2.3 2.43; \n",
            "9.0 8.3; 15.8 13.82; 2.3 2.58; \n",
            "11.8 9.74; 15.9 15.38; 7.4 3.71; \n",
            "13.0 11.6; 19.3 16.3; 8.8 6.78; \n",
            "12.8 12.54; 20.0 17.95; 7.5 7.6; \n",
            "11.5 12.71; 18.8 18.59; 7.0 7.28; \n",
            "12.6 11.91; 20.5 17.73; 6.4 6.44; \n",
            "8.5 13.1; 14.3 19.19; 5.8 7.04; \n",
            "8.0 8.79; 9.7 13.36; 4.8 3.73; \n",
            "8.5 8.21; 11.4 11.6; 6.8 4.05; \n",
            "11.5 8.43; 12.7 11.79; 8.3 4.7; \n",
            "7.3 11.31; 11.7 14.57; 5.7 7.7; \n",
            "5.7 7.38; 6.2 10.49; 3.8 3.42; \n",
            "6.8 6.33; 10.5 8.19; 3.3 3.34; \n",
            "5.1 7.37; 9.3 10.23; 3.0 3.25; \n",
            "1.9 5.64; 7.0 8.35; -2.4 1.52; \n",
            "1.0 2.48; 2.3 5.52; -0.4 -2.15; \n",
            "2.9 1.59; 5.0 3.1; 1.5 -1.18; \n",
            "1.0 3.53; 4.9 5.11; -0.7 0.58; \n",
            "4.9 1.36; 7.4 3.31; -1.2 -2.35; \n",
            "4.7 5.64; 7.5 8.43; 3.4 1.83; \n",
            "4.6 4.18; 7.7 6.3; 2.1 1.38; \n",
            "1.2 4.58; 3.3 6.66; 0.3 1.45; \n",
            "-1.4 0.93; 1.9 2.41; -2.8 -2.08; \n",
            "-0.1 -1.27; 1.6 0.72; -3.4 -4.37; \n",
            "-1.1 0.15; 0.7 1.98; -2.0 -2.77; \n",
            "3.4 -1.05; 7.0 0.04; -1.8 -3.55; \n",
            "5.5 3.76; 7.2 6.41; 2.6 0.16; \n",
            "6.7 4.99; 8.5 6.92; 5.1 2.39; \n",
            "7.0 5.86; 7.8 7.79; 5.7 3.29; \n",
            "5.1 5.97; 7.4 7.34; 4.3 3.81; \n",
            "5.5 4.02; 6.7 5.3; 3.3 1.72; \n",
            "6.3 4.58; 8.4 5.85; 5.0 2.32; \n",
            "0.7 5.11; 5.8 6.44; -1.2 3.08; \n",
            "-2.4 -0.27; 0.9 1.22; -4.5 -3.39; \n",
            "-5.1 -2.08; -1.1 -0.47; -7.7 -5.08; \n",
            "-0.8 -4.53; 1.6 -2.31; -7.7 -8.22; \n",
            "-0.2 0.83; 0.5 3.48; -1.5 -3.43; \n",
            "-1.0 0.21; 2.3 1.21; -2.8 -2.5; \n",
            "-3.3 -0.64; -0.2 1.09; -5.7 -4.0; \n",
            "3.6 -2.62; 6.6 -0.91; -3.8 -6.2; \n",
            "6.1 4.69; 9.0 8.06; 1.8 0.41; \n",
            "4.8 5.49; 7.1 8.36; 4.0 1.86; \n",
            "4.2 3.66; 7.4 5.5; 3.1 1.07; \n",
            "2.6 3.05; 4.4 4.92; 2.0 0.37; \n",
            "3.6 1.73; 4.8 3.07; 1.9 -0.46; \n",
            "2.3 2.82; 5.0 4.26; 1.8 0.46; \n",
            "5.7 1.38; 8.3 2.63; 0.4 -0.83; \n",
            "5.6 5.31; 8.6 7.54; 1.9 2.28; \n",
            "9.5 4.77; 10.4 7.02; 8.5 1.84; \n",
            "7.1 8.41; 9.3 10.35; 6.1 6.28; \n",
            "2.6 5.86; 6.1 7.14; 1.3 3.45; \n",
            "2.5 2.08; 5.4 3.47; 0.5 -0.76; \n",
            "-0.4 2.36; 3.2 4.05; -2.7 -0.35; \n",
            "0.2 -0.52; 2.6 1.08; -3.0 -3.6; \n",
            "3.1 0.81; 6.2 2.54; 0.2 -2.34; \n",
            "0.9 3.31; 1.4 5.45; 0.1 0.22; \n",
            "3.0 0.84; 4.5 1.55; 0.2 -1.46; \n",
            "6.3 3.35; 9.2 5.04; 2.7 0.49; \n",
            "6.1 6.15; 8.3 8.48; 2.9 2.95; \n",
            "3.3 5.48; 6.4 7.38; 2.8 2.51; \n",
            "3.5 2.4; 4.6 4.01; 2.6 -0.15; \n",
            "1.2 3.03; 3.5 4.04; -0.4 0.96; \n",
            "-0.4 0.69; 1.3 1.8; -0.9 -1.98; \n",
            "-0.4 -0.59; 0.0 0.41; -1.3 -2.89; \n",
            "0.0 -0.41; 0.2 0.11; -0.9 -2.18; \n",
            "0.0 0.24; 0.4 0.5; -0.3 -1.55; \n",
            "-0.8 0.24; 0.0 0.57; -1.4 -1.68; \n",
            "0.4 -0.66; 1.1 -0.26; -0.8 -2.69; \n",
            "-1.1 0.58; 0.4 1.16; -1.3 -1.33; \n",
            "-1.3 -1.31; 0.2 -0.89; -2.3 -3.21; \n",
            "0.0 -1.23; 1.3 -0.69; -2.6 -3.24; \n",
            "-4.9 -0.01; 0.3 0.89; -6.8 -2.14; \n",
            "-5.7 -5.45; -4.2 -3.88; -7.3 -8.75; \n",
            "-3.4 -5.06; -2.0 -4.28; -5.7 -7.55; \n",
            "-1.7 -2.68; -0.8 -1.54; -3.3 -5.2; \n",
            "-0.4 -1.32; 0.2 -0.57; -1.6 -3.59; \n",
            "-0.2 -0.41; 1.0 0.22; -1.3 -2.32; \n",
            "-0.5 -0.49; 1.8 0.32; -2.5 -2.38; \n",
            "0.3 -0.6; 1.7 0.7; -3.5 -2.96; \n",
            "0.0 0.34; 1.1 1.83; -1.2 -2.32; \n",
            "1.2 -0.48; 2.2 0.41; -0.7 -2.59; \n",
            "5.6 0.66; 7.0 1.58; 1.8 -1.32; \n",
            "4.6 4.72; 5.7 6.07; 2.7 2.44; \n",
            "3.6 3.26; 8.0 4.0; 1.1 1.33; \n",
            "-2.0 2.66; 1.7 4.4; -2.7 -0.19; \n",
            "2.1 -2.67; 4.2 -1.73; -1.7 -5.43; \n",
            "1.1 2.58; 3.0 4.58; -0.5 -0.45; \n",
            "-0.4 0.51; 1.3 1.58; -0.8 -1.97; \n",
            "-0.6 -0.73; 0.2 0.11; -2.5 -2.96; \n",
            "-0.4 -0.46; 0.2 0.29; -1.1 -2.61; \n",
            "-2.5 -0.06; 0.0 0.69; -3.0 -2.14; \n",
            "-4.5 -2.41; -2.3 -1.48; -5.3 -5.06; \n",
            "-7.2 -4.11; -2.6 -3.1; -11.1 -6.83; \n",
            "-7.6 -6.66; -3.8 -4.2; -10.2 -10.67; \n",
            "-6.5 -6.65; -4.3 -4.2; -10.7 -10.49; \n",
            "-5.5 -5.19; -4.8 -2.99; -6.3 -8.93; \n",
            "-8.0 -4.59; -5.5 -3.49; -8.6 -7.32; \n",
            "-7.0 -7.44; -5.6 -6.43; -9.2 -10.59; \n",
            "-1.0 -5.77; 0.5 -4.32; -5.8 -9.06; \n",
            "0.5 0.24; 3.0 2.56; -1.0 -2.66; \n",
            "-2.3 0.05; 0.1 1.95; -6.0 -2.4; \n",
            "-2.7 -2.43; -1.2 -0.65; -5.1 -5.39; \n",
            "1.3 -2.59; 3.5 -0.77; -2.7 -5.44; \n",
            "0.5 1.36; 4.7 3.43; -1.2 -1.54; \n",
            "-1.1 -0.68; 2.4 1.19; -3.7 -3.7; \n",
            "-1.5 -1.66; -0.5 0.13; -3.2 -4.46; \n",
            "-0.9 -1.69; 0.5 -0.56; -3.2 -3.93; \n",
            "0.8 -0.67; 1.2 0.65; 0.0 -3.33; \n",
            "1.6 0.65; 2.0 1.67; 0.6 -1.63; \n",
            "2.5 1.12; 3.0 1.87; 1.7 -0.55; \n",
            "2.4 1.71; 3.3 2.35; 2.0 0.18; \n",
            "1.9 1.71; 2.7 2.17; 0.7 0.13; \n",
            "4.1 1.32; 8.5 1.99; 0.5 -0.66; \n",
            "3.4 3.48; 7.9 5.72; 0.3 0.57; \n",
            "8.7 2.43; 13.4 4.47; 2.2 -0.5; \n",
            "7.8 7.94; 13.0 11.17; 2.9 4.38; \n",
            "6.7 6.7; 9.3 9.84; 4.1 2.96; \n",
            "5.6 5.86; 9.0 7.91; 1.1 2.94; \n",
            "6.2 5.07; 9.0 7.41; 3.8 1.45; \n",
            "7.4 5.76; 8.8 7.99; 5.9 2.57; \n",
            "7.3 6.71; 10.0 8.38; 3.2 4.08; \n",
            "7.4 6.74; 9.5 9.04; 5.2 3.37; \n",
            "5.3 6.95; 8.5 8.99; 2.8 3.96; \n",
            "9.4 5.16; 12.6 7.37; 3.7 1.68; \n",
            "5.5 9.41; 11.3 12.65; 4.4 5.37; \n",
            "5.3 5.11; 9.0 7.9; 0.6 1.23; \n",
            "5.3 5.53; 9.1 8.12; 2.7 1.65; \n",
            "3.0 5.24; 6.2 7.78; 1.7 1.7; \n",
            "1.1 3.13; 5.3 5.14; -2.3 -0.24; \n",
            "2.9 1.6; 5.2 4.04; 0.2 -2.34; \n",
            "5.0 3.43; 7.5 5.75; 1.4 0.2; \n",
            "3.3 5.18; 8.5 7.59; 1.6 1.77; \n",
            "1.3 3.17; 6.3 5.94; -2.3 -0.48; \n",
            "1.0 1.63; 5.7 4.7; -2.8 -2.64; \n",
            "0.9 1.44; 5.2 4.75; -1.0 -2.65; \n",
            "-0.4 1.13; 3.4 4.02; -4.6 -2.58; \n",
            "-0.2 -0.1; 5.0 2.84; -4.3 -4.28; \n",
            "0.1 0.16; 3.8 3.59; -4.2 -4.02; \n",
            "2.8 0.48; 6.1 3.66; -1.5 -3.47; \n",
            "4.1 3.16; 7.0 6.25; -0.7 -0.71; \n",
            "4.5 4.17; 7.9 7.17; 2.5 0.16; \n",
            "4.5 3.99; 8.3 6.77; -1.4 0.52; \n",
            "1.8 4.25; 5.5 7.44; 0.3 0.09; \n",
            "2.1 1.25; 9.0 3.84; -3.1 -2.34; \n",
            "4.6 2.25; 12.7 6.1; -2.6 -2.59; \n",
            "6.5 4.68; 13.4 9.59; -1.9 -1.02; \n",
            "9.3 6.6; 16.6 11.66; 1.6 0.89; \n",
            "13.6 9.04; 20.8 14.69; 3.2 3.23; \n",
            "12.4 13.35; 16.5 19.63; 11.0 7.09; \n",
            "12.0 11.44; 15.0 16.45; 10.3 6.97; \n",
            "5.6 10.89; 11.5 14.78; 3.9 7.21; \n",
            "12.1 4.74; 17.3 8.24; 4.5 0.31; \n",
            "13.0 12.12; 15.7 17.02; 10.0 6.92; \n",
            "14.2 11.86; 22.1 16.09; 8.0 7.7; \n",
            "15.0 13.51; 22.0 18.99; 7.8 8.14; \n",
            "13.1 14.62; 19.3 20.4; 10.7 8.97; \n",
            "14.0 12.88; 19.7 18.16; 8.2 8.17; \n",
            "13.7 14.1; 19.5 19.36; 11.5 8.67; \n",
            "10.6 13.97; 16.7 19.04; 8.0 9.2; \n",
            "6.5 10.94; 12.3 15.19; 3.0 6.22; \n",
            "6.4 7.01; 11.5 11.13; 0.6 2.49; \n",
            "7.3 7.76; 12.5 12.04; 0.0 2.48; \n",
            "6.3 8.76; 9.8 13.45; 3.6 2.83; \n",
            "5.3 7.16; 8.3 10.75; 4.7 2.56; \n",
            "9.3 5.85; 13.2 8.69; 1.6 1.88; \n",
            "13.2 10.13; 18.2 14.25; 7.2 5.02; \n",
            "13.2 13.27; 19.5 18.58; 6.3 7.99; \n",
            "14.3 13.15; 20.0 18.55; 10.2 7.48; \n",
            "14.2 13.7; 23.3 18.73; 7.8 8.83; \n",
            "16.4 14.12; 21.7 20.16; 7.6 8.18; \n",
            "14.5 15.71; 22.1 21.28; 6.2 10.01; \n",
            "12.2 14.43; 21.3 20.3; 6.3 8.11; \n",
            "8.8 12.76; 11.8 18.75; 6.3 6.32; \n",
            "5.9 9.31; 8.3 12.85; 5.0 4.91; \n",
            "10.7 6.5; 14.7 9.49; 2.5 2.3; \n",
            "9.7 11.78; 15.4 16.26; 8.1 6.16; \n",
            "6.1 10.3; 8.3 14.95; 4.8 5.27; \n",
            "6.7 6.93; 11.2 9.76; 3.4 2.99; \n",
            "6.5 7.64; 9.7 11.36; 3.9 3.06; \n",
            "6.3 7.42; 10.2 10.47; 2.0 3.06; \n",
            "8.4 6.79; 13.3 10.37; 0.9 2.05; \n",
            "9.6 8.79; 15.3 12.98; 2.9 3.78; \n",
            "10.0 9.87; 15.0 14.24; 5.8 4.68; \n",
            "9.9 9.93; 14.0 13.99; 2.4 5.49; \n",
            "12.7 10.08; 17.2 14.32; 9.2 4.71; \n",
            "10.3 12.34; 13.1 16.68; 9.1 7.79; \n",
            "11.5 9.71; 14.8 12.68; 9.0 6.16; \n",
            "13.3 10.94; 18.3 14.36; 8.7 7.19; \n",
            "11.6 12.93; 15.0 17.32; 10.3 8.53; \n",
            "13.5 10.94; 19.7 14.35; 9.2 7.41; \n",
            "14.7 13.18; 19.3 17.79; 9.1 8.71; \n",
            "16.2 14.37; 22.8 19.15; 9.8 9.61; \n",
            "17.3 15.71; 25.1 20.97; 10.0 10.7; \n",
            "19.2 16.98; 26.9 22.97; 11.5 11.39; \n",
            "19.9 18.73; 26.3 24.76; 13.1 12.98; \n",
            "13.1 19.1; 19.7 25.02; 11.0 13.6; \n",
            "11.1 13.5; 12.9 18.57; 8.2 8.44; \n",
            "10.3 11.66; 11.8 14.98; 8.9 7.35; \n",
            "12.8 10.92; 18.2 13.97; 7.8 7.04; \n",
            "8.3 13.63; 12.6 18.23; 5.8 8.44; \n",
            "7.8 9.24; 11.3 12.73; 4.5 4.65; \n",
            "5.0 9.02; 7.6 12.35; 1.6 4.65; \n",
            "7.7 6.51; 11.0 9.18; 4.5 1.9; \n",
            "8.9 9.0; 14.4 12.35; 4.3 4.36; \n",
            "9.6 9.68; 12.6 13.78; 4.7 4.55; \n",
            "14.6 9.8; 20.7 13.13; 7.6 5.66; \n",
            "14.0 14.43; 21.5 19.58; 8.7 9.42; \n",
            "15.6 14.03; 22.4 19.73; 9.3 8.73; \n",
            "17.5 15.37; 24.6 20.94; 11.4 9.87; \n",
            "18.2 16.8; 24.7 22.77; 10.7 11.39; \n",
            "19.3 17.24; 25.1 22.94; 12.5 11.79; \n",
            "18.0 18.14; 23.5 23.88; 12.8 12.77; \n",
            "20.6 17.27; 25.5 22.83; 13.0 12.06; \n",
            "18.3 19.26; 24.2 24.76; 16.8 13.87; \n",
            "15.8 17.75; 19.3 23.27; 15.2 13.0; \n",
            "14.1 15.64; 18.0 19.88; 12.7 11.41; \n",
            "13.9 14.4; 16.1 18.4; 10.7 10.15; \n",
            "17.6 14.51; 22.2 18.3; 13.8 10.16; \n",
            "19.3 17.51; 25.4 22.37; 15.0 12.84; \n",
            "16.8 18.89; 21.8 24.33; 14.3 14.11; \n",
            "11.3 16.79; 15.4 21.58; 9.8 12.33; \n",
            "10.4 12.06; 13.4 15.45; 5.9 8.07; \n",
            "10.4 11.55; 12.9 14.93; 7.8 7.03; \n",
            "12.4 11.42; 16.1 14.47; 8.7 7.28; \n",
            "13.3 13.02; 18.6 16.67; 6.8 8.79; \n",
            "13.5 13.72; 16.6 18.03; 6.9 8.91; \n",
            "16.7 13.92; 22.4 18.12; 9.0 9.16; \n",
            "20.0 16.86; 26.0 22.37; 12.3 11.21; \n",
            "21.8 19.41; 27.8 25.22; 13.3 13.7; \n",
            "19.8 20.5; 23.5 26.19; 17.0 14.76; \n",
            "17.5 18.31; 22.5 23.22; 15.4 13.93; \n",
            "17.3 16.79; 21.5 21.41; 12.7 12.42; \n",
            "20.4 17.13; 25.9 21.81; 12.3 12.28; \n",
            "21.7 19.79; 28.0 25.22; 15.3 14.19; \n",
            "21.8 20.48; 29.5 26.07; 17.0 15.1; \n",
            "23.1 20.78; 29.4 26.59; 16.5 15.56; \n",
            "27.0 21.8; 33.2 27.55; 17.3 16.35; \n",
            "27.6 24.12; 33.5 29.71; 20.7 18.6; \n",
            "26.0 24.44; 31.2 29.88; 22.7 19.2; \n",
            "22.7 23.52; 27.8 28.78; 17.2 18.75; \n",
            "22.1 21.66; 27.7 26.86; 15.8 16.43; \n",
            "22.3 21.51; 28.8 26.86; 13.6 16.02; \n",
            "24.1 21.97; 29.5 27.5; 14.4 15.81; \n",
            "21.4 23.01; 28.9 28.45; 17.0 16.88; \n",
            "20.3 21.54; 25.2 27.28; 16.2 15.55; \n",
            "24.1 20.57; 29.0 25.93; 17.7 15.07; \n",
            "22.0 22.98; 24.5 28.43; 18.7 17.46; \n",
            "22.9 21.51; 31.2 26.63; 14.7 16.42; \n",
            "23.5 22.45; 29.0 28.12; 16.7 16.39; \n",
            "25.6 22.61; 31.3 28.18; 18.5 17.0; \n",
            "20.1 23.59; 26.9 29.07; 17.4 18.08; \n",
            "17.1 20.2; 21.5 25.7; 14.6 14.78; \n",
            "17.9 17.99; 22.7 22.68; 12.7 12.91; \n",
            "19.5 18.68; 24.7 23.7; 12.3 13.16; \n",
            "23.9 20.05; 29.8 25.53; 15.6 14.31; \n",
            "25.6 22.76; 32.0 28.34; 18.8 17.0; \n",
            "26.4 23.47; 33.0 29.15; 20.0 18.23; \n",
            "25.7 23.85; 33.5 29.45; 20.3 18.51; \n",
            "24.5 23.76; 31.1 29.48; 19.9 18.38; \n",
            "26.3 23.07; 32.3 28.6; 18.5 17.72; \n",
            "28.7 23.96; 35.7 29.29; 21.1 18.48; \n",
            "29.9 25.18; 37.0 30.49; 21.8 19.91; \n",
            "29.8 25.71; 35.0 30.92; 23.2 20.52; \n",
            "30.5 25.62; 37.2 30.72; 22.4 20.67; \n",
            "27.7 26.23; 31.6 31.27; 24.9 21.0; \n",
            "25.9 24.85; 30.2 29.82; 21.3 20.1; \n",
            "19.8 24.06; 26.3 28.93; 17.3 18.98; \n",
            "20.1 20.73; 24.3 25.85; 17.7 15.17; \n",
            "22.3 20.79; 27.0 25.51; 18.1 15.79; \n",
            "23.1 22.12; 29.2 27.23; 18.0 16.91; \n",
            "21.8 22.73; 26.5 28.09; 19.3 17.39; \n",
            "15.9 21.68; 20.6 26.86; 14.9 16.73; \n",
            "19.0 17.41; 25.0 22.01; 14.2 12.7; \n",
            "19.8 19.99; 25.5 25.34; 16.0 14.54; \n",
            "22.3 20.39; 28.0 25.83; 14.7 15.24; \n",
            "19.0 21.56; 24.5 26.91; 15.9 16.24; \n",
            "19.5 19.06; 25.7 24.28; 15.0 14.19; \n",
            "16.5 19.68; 18.7 25.15; 15.5 14.59; \n",
            "15.5 17.01; 16.5 21.27; 14.4 12.77; \n",
            "17.3 15.91; 21.3 19.42; 14.5 12.07; \n",
            "18.4 17.36; 22.5 21.56; 15.2 13.12; \n",
            "20.2 18.21; 25.0 22.81; 16.4 14.05; \n",
            "19.7 19.5; 26.5 24.54; 17.1 14.99; \n",
            "15.7 19.32; 19.0 24.69; 13.7 14.82; \n",
            "18.7 16.04; 24.0 19.96; 11.7 11.86; \n",
            "19.7 18.72; 24.5 23.8; 15.5 13.62; \n",
            "19.7 19.34; 25.4 24.44; 16.1 14.62; \n",
            "20.5 19.23; 26.0 24.25; 16.0 14.75; \n",
            "21.5 19.79; 27.0 25.01; 15.1 15.24; \n",
            "20.2 20.65; 25.0 26.08; 16.8 15.62; \n",
            "18.1 19.7; 23.4 24.9; 13.0 14.97; \n",
            "18.8 18.51; 25.0 23.66; 13.2 13.24; \n",
            "20.5 19.08; 27.2 24.4; 13.5 13.56; \n",
            "22.5 20.32; 28.3 25.99; 14.4 14.79; \n",
            "23.0 21.51; 28.3 27.17; 18.8 15.84; \n",
            "22.6 21.75; 26.2 27.27; 18.4 16.71; \n",
            "21.1 21.32; 26.5 26.51; 18.3 16.49; \n",
            "24.3 20.53; 31.5 25.82; 14.9 15.68; \n",
            "26.2 23.0; 33.2 28.64; 19.1 17.17; \n",
            "25.7 23.86; 32.3 29.41; 20.3 18.47; \n",
            "25.5 23.47; 31.3 28.95; 20.3 18.26; \n",
            "22.0 23.31; 28.5 28.7; 17.6 18.21; \n",
            "20.1 21.57; 27.5 27.06; 16.5 16.19; \n",
            "17.1 20.62; 22.4 26.28; 14.3 15.0; \n",
            "18.7 18.4; 25.4 23.48; 12.3 13.13; \n",
            "20.9 19.75; 25.5 25.34; 15.3 13.75; \n",
            "20.5 20.84; 24.3 26.32; 16.4 15.49; \n",
            "18.2 20.24; 20.7 25.57; 15.6 15.1; \n",
            "16.4 18.46; 19.8 23.08; 14.5 13.76; \n",
            "15.8 17.17; 22.6 21.64; 10.5 12.53; \n",
            "19.8 17.09; 25.5 22.25; 10.2 11.42; \n",
            "19.5 19.99; 24.8 25.54; 15.3 13.98; \n",
            "17.0 19.26; 19.6 24.58; 15.3 13.99; \n",
            "18.0 16.86; 23.3 20.96; 11.6 12.72; \n",
            "16.0 18.24; 22.0 23.36; 13.8 12.85; \n",
            "14.9 16.91; 18.8 22.13; 13.2 11.85; \n",
            "15.2 15.56; 20.1 19.79; 10.2 11.23; \n",
            "16.6 15.91; 22.3 20.52; 9.0 10.94; \n",
            "16.6 17.3; 22.5 22.58; 11.5 11.63; \n",
            "19.6 16.93; 25.5 22.38; 13.2 11.58; \n",
            "17.8 19.32; 22.1 25.04; 14.1 13.89; \n",
            "16.8 17.81; 18.4 22.89; 15.0 12.79; \n",
            "18.4 16.46; 23.5 20.4; 14.7 12.62; \n",
            "18.5 17.99; 23.8 22.97; 13.5 13.32; \n",
            "19.2 18.4; 26.0 23.52; 13.0 13.39; \n",
            "19.6 19.03; 27.5 24.54; 13.3 13.62; \n",
            "20.6 19.34; 28.6 25.2; 14.5 13.79; \n",
            "19.4 20.24; 24.6 26.2; 15.2 14.53; \n",
            "19.9 19.24; 25.1 24.77; 15.0 14.02; \n",
            "16.9 19.55; 23.7 24.98; 13.5 14.37; \n",
            "14.0 17.56; 18.0 23.01; 12.6 12.29; \n",
            "12.8 15.02; 15.2 19.46; 10.6 10.56; \n",
            "12.0 13.75; 16.8 17.47; 8.7 9.46; \n",
            "12.4 13.26; 17.6 17.5; 8.4 8.4; \n",
            "12.5 13.68; 18.1 18.22; 8.4 8.54; \n",
            "12.9 13.6; 16.7 18.49; 10.4 8.42; \n",
            "14.4 13.62; 19.4 17.87; 8.5 9.13; \n",
            "16.3 15.06; 23.7 19.97; 11.8 9.87; \n",
            "16.5 16.64; 24.4 22.4; 11.4 11.32; \n",
            "17.1 16.81; 24.5 22.72; 10.8 11.32; \n",
            "18.4 17.16; 23.2 23.04; 12.6 11.62; \n",
            "20.3 17.91; 23.0 23.38; 15.2 12.86; \n",
            "11.8 18.84; 21.4 23.92; 9.8 14.23; \n",
            "10.2 12.52; 14.5 17.86; 8.3 7.07; \n",
            "10.4 11.16; 15.5 15.11; 8.0 6.76; \n",
            "13.1 11.36; 16.5 15.54; 8.5 6.84; \n",
            "16.0 13.78; 20.0 18.16; 9.9 8.98; \n",
            "10.5 16.1; 16.8 21.07; 9.6 10.97; \n",
            "7.4 11.06; 9.7 15.58; 7.0 6.45; \n",
            "8.3 8.37; 13.8 10.98; 6.2 4.94; \n",
            "7.0 9.43; 14.3 13.38; 1.6 4.89; \n",
            "8.5 8.35; 13.7 12.76; 4.9 2.72; \n",
            "6.2 9.01; 13.0 13.18; 2.2 4.5; \n",
            "8.6 6.8; 16.5 11.06; 0.5 2.01; \n",
            "9.5 9.83; 18.5 15.44; 3.5 3.75; \n",
            "10.8 10.68; 19.2 17.06; 4.2 4.35; \n",
            "11.6 11.54; 19.6 17.95; 6.0 5.2; \n",
            "10.9 11.99; 18.9 18.04; 5.3 6.09; \n",
            "11.5 11.42; 18.2 17.66; 6.6 5.33; \n",
            "9.9 11.64; 14.0 17.49; 4.8 6.06; \n",
            "12.9 9.95; 20.1 14.93; 6.5 4.7; \n",
            "13.8 13.02; 19.0 18.99; 8.1 7.08; \n",
            "12.9 13.52; 18.3 19.02; 11.1 8.18; \n",
            "10.4 12.39; 18.2 17.49; 6.0 7.66; \n",
            "11.3 10.75; 19.7 16.11; 5.2 5.15; \n",
            "12.6 12.11; 19.7 18.17; 6.3 5.86; \n",
            "14.0 13.28; 23.5 19.24; 5.7 7.16; \n",
            "12.4 14.66; 17.8 21.5; 8.8 7.76; \n",
            "11.2 12.71; 13.4 17.95; 10.2 7.47; \n",
            "10.1 11.11; 11.0 15.06; 8.3 7.21; \n",
            "11.2 10.11; 12.8 13.15; 10.0 6.5; \n",
            "9.8 11.21; 13.2 14.4; 6.1 7.63; \n",
            "9.6 9.99; 14.4 13.25; 7.5 5.83; \n",
            "9.7 9.74; 15.2 13.34; 4.1 5.83; \n",
            "11.1 10.28; 12.0 14.34; 10.0 5.28; \n",
            "10.8 10.9; 13.5 13.64; 9.5 7.63; \n",
            "10.4 10.49; 16.2 13.25; 6.6 7.07; \n",
            "9.8 10.5; 16.0 14.24; 5.7 6.22; \n",
            "10.0 10.3; 16.6 14.24; 5.9 6.03; \n",
            "9.6 10.44; 15.7 14.96; 5.4 5.81; \n",
            "11.2 10.11; 12.8 14.25; 6.6 5.57; \n",
            "12.7 11.22; 14.5 14.64; 8.9 7.12; \n",
            "11.2 12.1; 14.7 15.53; 10.2 8.48; \n",
            "12.1 10.7; 17.1 13.96; 9.6 7.28; \n",
            "13.2 12.09; 17.8 15.96; 9.2 8.23; \n",
            "11.2 13.0; 15.0 17.22; 8.5 8.85; \n",
            "11.7 10.97; 13.6 14.41; 9.2 7.05; \n",
            "10.5 11.38; 12.7 14.28; 9.8 7.87; \n",
            "11.0 10.18; 14.1 12.69; 5.1 7.08; \n",
            "10.7 11.1; 12.6 14.26; 10.2 7.01; \n",
            "8.8 10.41; 10.8 12.74; 8.0 7.62; \n",
            "6.3 8.76; 9.8 10.39; 4.4 5.99; \n",
            "4.6 6.75; 7.4 8.67; 3.4 3.32; \n",
            "3.7 5.4; 7.6 7.16; 0.1 2.17; \n",
            "3.9 4.44; 4.3 6.81; 2.2 0.52; \n",
            "3.8 4.61; 4.5 5.7; 3.4 2.01; \n",
            "3.2 4.17; 3.9 5.02; 2.6 1.68; \n",
            "2.8 3.55; 3.8 4.09; 2.4 1.32; \n",
            "3.2 2.95; 4.5 3.66; 2.3 0.7; \n",
            "1.3 3.28; 4.7 4.14; -1.4 1.08; \n",
            "0.8 1.44; 4.2 2.87; -3.5 -1.54; \n",
            "2.5 1.21; 3.6 3.26; -0.4 -2.31; \n",
            "4.3 2.74; 6.5 4.1; 2.0 0.12; \n",
            "5.6 3.9; 7.4 5.38; 3.2 1.24; \n",
            "7.4 5.03; 8.6 6.29; 5.3 2.49; \n",
            "5.8 6.51; 8.0 7.87; 4.2 4.29; \n",
            "7.7 4.81; 9.5 6.05; 5.4 2.48; \n",
            "4.3 6.98; 9.5 8.65; 1.4 4.51; \n",
            "-4.4 3.56; 1.4 5.71; -5.6 0.06; \n",
            "-4.2 -5.02; -0.7 -2.93; -6.0 -8.73; \n",
            "-1.8 -3.45; 1.6 -1.19; -5.8 -6.59; \n",
            "-1.3 -0.89; 1.5 1.53; -4.4 -4.69; \n",
            "-2.3 -0.66; -0.9 1.56; -3.0 -4.2; \n",
            "2.1 -1.92; 3.2 -0.47; -2.8 -4.53; \n",
            "2.5 3.05; 6.6 5.16; 0.1 -0.08; \n",
            "-0.5 2.45; 3.1 5.05; -2.8 -1.12; \n",
            "2.1 -0.62; 6.0 1.75; -2.9 -4.21; \n",
            "7.8 2.02; 11.6 5.18; 4.4 -1.62; \n",
            "4.0 6.84; 7.7 10.02; 2.5 3.63; \n",
            "2.5 2.5; 4.3 4.59; 1.1 -0.52; \n",
            "5.6 1.71; 7.5 3.45; 1.8 -0.64; \n",
            "10.0 5.0; 12.9 7.11; 5.8 2.22; \n",
            "11.6 8.88; 14.3 11.82; 10.4 5.75; \n",
            "5.7 9.94; 10.6 12.8; 4.6 7.32; \n",
            "2.3 4.18; 5.4 6.27; 2.0 1.31; \n",
            "1.8 1.9; 3.1 3.4; 0.3 -0.48; \n",
            "2.5 1.95; 4.7 3.49; 0.9 -0.82; \n",
            "1.4 2.49; 2.9 4.19; 0.2 -0.33; \n",
            "1.1 1.24; 2.5 2.24; -1.5 -0.92; \n",
            "-0.5 1.31; 1.8 2.53; -1.1 -1.07; \n",
            "-2.9 -0.07; -1.1 1.02; -3.4 -2.64; \n",
            "-4.0 -2.16; -2.7 -1.16; -4.3 -5.23; \n",
            "-3.2 -3.21; -2.7 -2.39; -4.4 -5.87; \n",
            "-0.4 -2.47; 0.8 -1.59; -3.3 -4.7; \n",
            "0.0 0.09; 3.1 1.31; -1.3 -2.33; \n",
            "-2.0 -0.19; -1.0 1.2; -2.5 -2.64; \n",
            "-2.1 -2.07; -1.6 -1.4; -3.1 -4.02; \n",
            "0.2 -1.8; 4.0 -1.2; -2.0 -3.76; \n",
            "-1.4 0.08; 0.1 1.9; -3.0 -2.74; \n",
            "1.5 -1.9; 5.1 -1.02; -3.9 -4.04; \n",
            "-1.0 1.37; 2.2 3.87; -1.6 -1.68; \n",
            "-2.2 -1.81; -1.1 -0.69; -2.7 -4.08; \n",
            "-1.4 -2.08; 2.3 -1.36; -3.1 -4.34; \n",
            "-5.3 -1.52; -2.4 0.43; -7.0 -4.5; \n",
            "-4.4 -5.44; -3.6 -3.99; -7.9 -8.37; \n",
            "-2.1 -3.64; -0.5 -2.23; -3.8 -6.38; \n",
            "5.4 -1.57; 7.0 -0.13; -2.7 -4.03; \n",
            "0.2 5.68; 6.2 8.33; -1.6 2.12; \n",
            "0.7 -1.04; 2.6 1.32; -3.4 -4.66; \n",
            "4.5 1.0; 7.6 3.24; 0.8 -2.18; \n",
            "1.2 4.04; 4.0 6.38; 0.0 0.77; \n",
            "4.0 0.5; 5.1 1.96; 0.8 -2.6; \n",
            "6.0 3.43; 7.2 5.29; 3.2 0.69; \n",
            "8.2 4.76; 10.7 6.22; 4.0 2.63; \n",
            "4.1 7.03; 8.2 9.33; 3.1 4.01; \n",
            "2.5 3.05; 5.1 4.84; 0.5 0.19; \n",
            "2.7 2.18; 3.5 3.94; 1.5 -0.79; \n",
            "2.4 2.44; 5.1 3.53; 1.2 0.19; \n",
            "2.9 2.1; 5.1 3.51; 0.8 -0.69; \n",
            "4.0 2.63; 8.8 4.07; -0.3 -0.03; \n",
            "-0.3 3.86; 5.4 6.52; -1.1 0.48; \n",
            "-2.9 -0.6; 1.3 1.63; -4.6 -3.99; \n",
            "-3.0 -2.22; -0.5 0.08; -5.7 -5.82; \n",
            "-4.8 -2.2; -0.7 0.12; -8.0 -5.76; \n",
            "-6.5 -4.21; -4.4 -1.42; -7.6 -8.19; \n",
            "-4.6 -6.05; 0.9 -4.34; -8.3 -9.09; \n",
            "-4.1 -3.58; 1.0 -0.17; -8.0 -7.7; \n",
            "-4.4 -3.19; 2.2 0.29; -8.4 -7.55; \n",
            "-3.7 -3.55; 1.5 0.74; -9.5 -8.55; \n",
            "-5.8 -2.77; -2.0 1.8; -9.2 -7.8; \n",
            "-5.3 -5.05; -0.9 -1.34; -10.1 -9.49; \n",
            "-3.6 -4.28; -1.4 -0.15; -7.3 -9.11; \n",
            "-1.6 -2.75; 1.1 0.22; -5.2 -6.47; \n",
            "0.8 -1.21; 4.4 1.74; -4.7 -4.78; \n",
            "1.5 1.08; 3.8 4.38; 0.4 -2.97; \n",
            "3.7 1.11; 5.1 3.54; -1.2 -1.8; \n",
            "3.9 3.46; 7.5 6.15; 2.5 0.04; \n",
            "0.2 2.8; 2.6 5.45; -0.2 -0.28; \n",
            "-0.1 -0.84; 0.7 0.72; -1.7 -3.44; \n",
            "1.8 -0.5; 4.4 0.86; -0.5 -2.83; \n",
            "1.9 1.36; 4.5 3.2; -0.3 -1.19; \n",
            "5.0 1.27; 7.2 2.88; 0.4 -1.52; \n",
            "10.0 4.59; 15.5 6.77; 7.0 1.79; \n",
            "9.7 8.84; 17.2 12.62; 5.3 5.49; \n",
            "7.7 8.66; 12.2 12.89; 3.3 4.69; \n",
            "11.5 6.91; 17.5 10.36; 6.9 3.02; \n",
            "11.6 10.7; 13.9 15.23; 8.5 6.51; \n",
            "5.1 10.15; 11.9 13.19; 3.4 6.93; \n",
            "1.5 4.08; 3.5 7.21; 0.8 0.2; \n",
            "1.2 1.2; 4.2 3.03; 0.0 -1.34; \n",
            "0.4 1.5; 3.0 3.55; -2.8 -1.26; \n",
            "2.7 1.29; 5.3 3.65; -0.5 -2.61; \n",
            "1.4 3.54; 5.5 6.3; 0.0 -0.09; \n",
            "0.4 1.59; 4.5 4.11; -4.0 -1.83; \n",
            "4.6 1.39; 8.7 4.4; -1.2 -2.91; \n",
            "3.0 5.36; 4.7 9.06; 1.0 0.8; \n",
            "9.3 2.83; 13.3 4.77; 2.4 -0.45; \n",
            "4.4 8.88; 9.8 12.58; 1.5 4.71; \n",
            "-0.1 3.41; 1.5 6.15; -1.6 -0.53; \n",
            "0.3 -0.19; 5.2 1.4; -3.1 -3.12; \n",
            "-1.8 0.49; 1.0 3.33; -4.6 -3.52; \n",
            "1.6 -1.34; 2.8 0.72; -2.5 -5.26; \n",
            "-0.7 2.26; 2.9 4.52; -3.9 -1.14; \n",
            "1.0 -0.75; 7.6 1.66; -6.0 -4.37; \n",
            "2.5 1.9; 7.9 5.85; -2.2 -3.39; \n",
            "4.1 3.09; 6.8 6.92; -0.7 -1.68; \n",
            "0.8 4.33; 3.6 7.62; -0.1 0.1; \n",
            "1.4 0.29; 4.5 2.22; -1.0 -3.06; \n",
            "0.9 1.57; 4.7 3.94; -4.0 -1.98; \n",
            "2.2 0.81; 5.5 3.84; -1.4 -3.29; \n",
            "-0.4 2.23; 3.6 5.1; -2.0 -1.25; \n",
            "-0.1 -0.73; 4.0 1.45; -3.8 -4.2; \n",
            "0.5 0.45; 4.5 3.4; -2.3 -3.57; \n",
            "-1.4 0.69; 1.5 3.85; -4.3 -3.23; \n",
            "-0.8 -1.2; 2.3 1.42; -3.0 -4.85; \n",
            "0.2 -0.52; 5.0 1.87; -3.5 -3.83; \n",
            "1.9 0.5; 7.3 3.59; -2.8 -3.43; \n",
            "2.0 2.04; 8.3 5.67; -3.2 -2.19; \n",
            "5.1 1.88; 8.9 5.99; -1.8 -2.68; \n",
            "-1.3 5.11; 6.5 8.92; -2.6 0.67; \n",
            "-3.5 -2.2; -2.1 1.46; -4.4 -6.86; \n",
            "-1.1 -3.05; 1.0 -0.73; -4.0 -6.31; \n",
            "-0.6 -0.65; 2.1 2.0; -2.8 -3.94; \n",
            "0.5 -0.56; 3.2 1.8; -2.6 -3.82; \n",
            "3.1 0.61; 5.0 3.17; -1.7 -2.62; \n",
            "5.9 3.2; 7.6 6.0; 3.0 -0.05; \n",
            "6.5 5.47; 8.7 7.97; 5.4 2.47; \n",
            "9.6 5.38; 16.0 7.51; 2.8 2.69; \n",
            "10.6 8.63; 15.9 12.79; 3.1 4.13; \n",
            "6.2 9.34; 10.8 13.46; 4.0 4.85; \n",
            "3.3 4.87; 8.5 7.48; -0.7 1.41; \n",
            "4.2 2.85; 9.5 5.63; -0.7 -1.37; \n",
            "8.2 4.32; 13.6 7.66; 0.7 -0.3; \n",
            "12.2 8.26; 19.3 12.56; 5.8 3.15; \n",
            "13.1 11.8; 18.4 17.26; 10.0 6.65; \n",
            "10.7 12.52; 13.6 17.48; 9.0 8.11; \n",
            "5.7 10.15; 10.2 13.85; 4.9 6.39; \n",
            "4.0 5.53; 5.5 8.8; 1.5 1.59; \n",
            "4.6 4.18; 8.6 6.68; 0.6 0.61; \n",
            "4.7 4.82; 10.0 7.92; 1.7 0.76; \n",
            "4.9 4.75; 10.5 8.04; 0.7 0.74; \n",
            "7.0 5.14; 12.5 8.73; 0.7 0.86; \n",
            "9.9 7.55; 15.2 11.92; 1.6 2.52; \n",
            "10.2 10.45; 14.2 15.59; 5.0 4.7; \n",
            "11.4 10.22; 13.5 14.59; 9.2 5.27; \n",
            "11.2 10.77; 14.7 14.15; 7.8 7.13; \n",
            "7.0 10.34; 11.9 13.72; 5.9 6.49; \n",
            "7.4 6.4; 9.4 9.19; 4.5 2.76; \n",
            "8.8 7.24; 13.5 9.76; 3.2 3.82; \n",
            "12.6 8.79; 16.9 12.43; 6.6 4.22; \n",
            "13.0 12.38; 18.0 16.67; 10.8 7.7; \n",
            "9.4 12.23; 12.3 16.56; 8.2 8.23; \n",
            "9.8 8.88; 14.3 11.53; 6.2 5.61; \n",
            "11.4 9.96; 15.2 13.5; 7.6 5.85; \n",
            "9.9 11.5; 15.1 15.29; 4.3 7.39; \n",
            "11.3 10.07; 17.2 13.97; 5.0 5.27; \n",
            "12.2 11.48; 21.2 15.96; 5.1 6.51; \n",
            "10.6 12.68; 14.3 18.44; 7.5 6.84; \n",
            "13.0 10.69; 18.0 14.7; 7.2 6.24; \n",
            "13.4 13.28; 18.7 18.24; 8.1 8.05; \n",
            "15.6 13.53; 20.7 18.46; 5.8 8.3; \n",
            "16.3 15.64; 20.5 21.04; 13.3 9.81; \n",
            "17.2 15.65; 24.2 20.89; 9.7 10.94; \n",
            "12.0 16.86; 18.2 22.52; 9.2 11.15; \n",
            "14.2 12.2; 19.1 16.93; 5.4 6.93; \n",
            "15.9 14.7; 21.6 19.86; 9.5 8.77; \n",
            "16.1 15.86; 20.0 21.38; 14.5 9.95; \n",
            "19.5 15.96; 24.7 20.68; 12.2 11.52; \n",
            "20.3 18.62; 26.5 24.15; 15.1 13.19; \n",
            "22.7 19.26; 31.0 25.05; 14.4 14.24; \n",
            "25.5 21.41; 31.6 27.61; 17.0 15.46; \n",
            "26.4 22.96; 33.2 28.76; 17.5 17.52; \n",
            "22.2 23.55; 27.4 29.24; 18.2 17.75; \n",
            "23.2 20.64; 30.2 26.05; 15.6 15.59; \n",
            "25.8 21.81; 32.6 27.42; 18.7 16.18; \n",
            "19.9 23.64; 26.8 29.26; 17.3 18.02; \n",
            "15.6 20.08; 19.3 25.65; 13.5 14.71; \n",
            "16.2 16.56; 22.0 20.94; 9.0 11.53; \n",
            "18.4 17.78; 23.3 23.15; 13.1 11.58; \n",
            "20.4 19.33; 26.4 24.93; 11.8 13.35; \n",
            "23.5 20.65; 28.6 26.48; 14.9 14.45; \n",
            "22.6 22.23; 27.6 27.91; 18.3 16.37; \n",
            "20.6 21.5; 28.3 27.1; 15.6 16.35; \n",
            "22.2 20.54; 28.7 26.48; 17.0 14.69; \n",
            "23.0 21.68; 29.0 27.36; 15.5 16.05; \n",
            "24.4 21.95; 31.4 27.54; 16.1 16.14; \n",
            "26.3 22.68; 33.3 28.33; 17.3 17.03; \n",
            "24.3 23.94; 32.3 29.6; 21.2 18.14; \n",
            "19.9 22.87; 26.0 28.73; 16.0 17.56; \n",
            "21.5 20.17; 25.7 25.7; 15.8 14.65; \n",
            "20.5 21.19; 25.8 26.53; 17.0 15.65; \n",
            "20.3 20.58; 26.3 25.96; 14.2 15.28; \n",
            "22.4 20.5; 28.2 26.01; 14.4 14.71; \n",
            "24.4 21.93; 30.2 27.55; 15.0 16.07; \n",
            "18.6 23.01; 24.6 28.73; 17.4 17.06; \n",
            "16.3 19.09; 21.8 24.53; 14.3 13.82; \n",
            "16.6 17.56; 21.5 22.59; 13.2 12.15; \n",
            "16.1 17.66; 21.5 22.62; 11.0 12.33; \n",
            "19.9 17.27; 25.8 22.4; 9.4 11.75; \n",
            "22.2 20.14; 27.6 25.86; 15.0 13.86; \n",
            "21.0 21.4; 24.8 27.19; 15.2 15.78; \n",
            "15.6 20.29; 20.6 25.74; 15.3 14.94; \n",
            "14.3 16.17; 15.3 20.89; 14.0 11.42; \n",
            "13.3 14.82; 14.3 18.03; 12.1 10.9; \n",
            "16.5 13.75; 20.3 16.56; 13.2 10.04; \n",
            "17.5 16.72; 23.5 20.87; 11.9 12.4; \n",
            "18.2 17.64; 23.4 22.65; 11.5 12.6; \n",
            "19.5 18.02; 24.5 23.18; 11.8 13.01; \n",
            "21.4 19.18; 27.2 24.65; 12.7 13.7; \n",
            "20.4 20.64; 25.3 26.24; 15.4 14.97; \n",
            "21.2 19.84; 25.6 25.05; 15.8 14.68; \n",
            "19.1 20.16; 22.0 25.22; 17.7 15.24; \n",
            "17.0 18.32; 20.9 22.66; 15.9 14.35; \n",
            "17.2 17.03; 21.5 21.23; 13.9 12.93; \n",
            "20.5 17.47; 25.3 22.0; 14.2 12.86; \n",
            "16.1 20.03; 20.3 25.19; 15.2 14.91; \n",
            "20.6 16.42; 26.7 20.82; 10.7 12.07; \n",
            "15.3 20.25; 21.2 25.66; 12.5 14.61; \n",
            "12.7 16.28; 13.4 21.38; 9.6 10.98; \n",
            "16.6 13.66; 19.9 16.65; 12.8 9.58; \n",
            "19.1 16.81; 24.0 21.12; 14.7 12.26; \n",
            "20.1 19.01; 26.7 24.01; 18.3 14.29; \n",
            "21.7 19.37; 26.5 24.74; 15.6 14.94; \n",
            "21.4 20.45; 28.8 25.79; 18.0 15.81; \n",
            "20.4 20.55; 26.2 26.24; 14.1 15.49; \n",
            "17.7 20.01; 20.3 25.47; 15.8 14.84; \n",
            "20.0 17.37; 24.2 21.83; 16.5 13.03; \n",
            "20.2 19.11; 25.3 23.73; 16.6 14.86; \n",
            "20.1 19.38; 25.0 24.41; 15.6 15.08; \n",
            "19.7 19.6; 25.5 24.58; 14.3 15.03; \n",
            "21.6 19.58; 27.7 24.96; 14.5 14.39; \n",
            "23.1 21.07; 29.0 26.56; 16.2 15.69; \n",
            "24.8 22.13; 31.2 27.74; 18.5 16.58; \n",
            "25.9 22.94; 32.3 28.47; 19.4 17.7; \n",
            "25.9 23.5; 33.1 28.93; 17.6 18.36; \n",
            "26.9 23.77; 33.8 29.35; 18.8 18.31; \n",
            "28.1 24.41; 35.3 29.91; 20.2 18.86; \n",
            "23.2 25.04; 31.1 30.44; 20.0 19.53; \n",
            "20.9 22.51; 26.2 28.18; 16.8 16.97; \n",
            "21.7 20.93; 27.3 26.22; 15.0 15.48; \n",
            "22.6 21.6; 29.2 27.1; 15.0 15.73; \n",
            "21.7 22.45; 27.1 28.15; 17.6 16.33; \n",
            "22.1 21.67; 29.6 27.23; 16.7 16.05; \n",
            "16.9 21.97; 20.5 27.78; 16.0 16.15; \n",
            "17.5 17.97; 21.0 22.84; 13.5 12.92; \n",
            "18.1 18.38; 22.9 23.21; 14.2 13.14; \n",
            "17.6 18.83; 23.4 24.04; 12.2 13.47; \n",
            "20.7 18.53; 27.0 23.77; 12.5 12.92; \n",
            "23.0 20.53; 28.8 26.24; 17.6 14.75; \n",
            "23.7 21.77; 31.6 27.49; 18.7 16.61; \n",
            "24.4 22.34; 29.4 28.17; 20.1 16.96; \n",
            "24.6 22.59; 30.7 28.04; 18.3 17.76; \n",
            "26.3 22.75; 32.6 28.22; 20.5 17.46; \n",
            "27.6 23.68; 34.9 29.11; 20.4 18.77; \n",
            "21.3 24.6; 27.3 30.01; 18.5 19.4; \n",
            "17.3 20.81; 22.4 26.17; 14.9 15.7; \n",
            "18.9 17.96; 24.9 22.7; 12.6 13.08; \n",
            "20.0 19.65; 27.1 25.04; 11.7 13.82; \n",
            "22.6 20.84; 29.4 26.64; 14.3 14.47; \n",
            "16.2 22.24; 22.2 28.09; 15.1 16.06; \n",
            "20.8 17.41; 25.9 22.77; 14.7 12.12; \n",
            "22.7 20.81; 28.4 26.37; 17.8 15.2; \n",
            "22.0 22.05; 27.0 27.92; 18.9 16.58; \n",
            "24.5 21.23; 30.5 26.66; 16.3 16.15; \n",
            "18.9 22.67; 25.4 28.15; 16.8 17.25; \n",
            "20.8 19.09; 25.6 24.66; 17.3 14.0; \n",
            "21.2 20.28; 26.5 25.43; 18.7 15.36; \n",
            "24.8 20.51; 30.1 25.86; 17.3 15.78; \n",
            "23.4 22.87; 29.9 28.09; 19.8 17.7; \n",
            "24.7 21.96; 31.5 27.5; 17.5 17.2; \n",
            "26.3 23.08; 32.8 28.62; 19.8 17.85; \n",
            "22.8 24.08; 32.6 29.57; 19.1 18.8; \n",
            "21.6 22.46; 27.1 28.4; 15.6 16.93; \n",
            "22.9 21.28; 27.8 26.61; 19.1 15.77; \n",
            "21.2 21.96; 27.1 27.29; 17.4 16.96; \n",
            "19.4 21.11; 25.4 26.57; 16.1 15.88; \n",
            "21.7 19.93; 28.0 25.28; 16.5 14.78; \n",
            "17.8 21.59; 22.4 27.23; 15.4 16.1; \n",
            "18.3 18.53; 23.9 23.67; 13.5 13.54; \n",
            "18.9 19.06; 24.6 24.33; 12.8 13.59; \n",
            "20.1 19.58; 26.5 25.17; 12.1 13.78; \n",
            "20.2 20.26; 25.4 25.95; 16.4 14.29; \n",
            "19.9 20.07; 24.3 25.61; 16.6 14.87; \n",
            "18.8 19.66; 22.4 24.81; 17.0 14.81; \n",
            "20.0 18.61; 25.0 23.31; 15.6 14.14; \n",
            "17.3 19.75; 23.0 24.98; 13.1 14.84; \n",
            "15.5 17.81; 21.7 22.87; 11.3 12.6; \n",
            "17.4 16.55; 24.7 21.55; 9.4 11.32; \n",
            "20.1 18.27; 28.4 24.02; 11.6 12.12; \n",
            "20.4 20.27; 28.5 26.44; 13.3 14.03; \n",
            "20.4 20.42; 30.4 26.66; 13.0 14.25; \n",
            "18.8 20.67; 23.1 27.18; 15.5 14.22; \n",
            "18.8 19.02; 22.5 24.63; 15.1 13.71; \n",
            "17.4 18.78; 23.5 24.14; 13.6 13.66; \n",
            "15.5 17.88; 21.9 23.43; 13.0 12.42; \n",
            "16.8 16.38; 23.0 21.7; 10.3 11.09; \n",
            "15.3 17.34; 23.1 22.92; 8.8 11.6; \n",
            "18.3 16.43; 25.8 22.48; 9.1 10.11; \n",
            "18.0 18.93; 26.0 25.16; 11.0 12.19; \n",
            "19.7 18.62; 26.7 25.08; 12.3 12.1; \n",
            "19.1 19.76; 23.5 25.97; 13.7 13.42; \n",
            "17.1 19.0; 21.7 24.67; 15.8 13.44; \n",
            "15.9 17.2; 21.2 22.39; 11.9 12.4; \n",
            "19.5 16.46; 27.3 21.61; 13.2 11.08; \n",
            "17.2 19.52; 23.0 25.59; 15.0 13.66; \n",
            "15.0 17.38; 20.3 22.86; 13.2 12.26; \n",
            "15.7 15.33; 20.3 20.15; 11.4 10.61; \n",
            "17.4 16.23; 24.5 21.16; 12.7 11.17; \n",
            "13.8 17.84; 19.4 23.72; 13.3 12.34; \n",
            "13.6 14.52; 18.3 19.31; 12.0 10.04; \n",
            "10.7 14.25; 16.5 18.69; 7.5 10.04; \n",
            "10.9 11.87; 18.8 16.13; 6.0 7.16; \n",
            "13.6 12.43; 19.4 17.9; 4.4 6.85; \n",
            "17.2 14.77; 24.2 20.43; 11.0 8.55; \n",
            "16.0 17.41; 17.8 23.54; 15.0 11.69; \n",
            "15.4 15.44; 20.1 19.73; 14.6 11.63; \n",
            "15.8 14.99; 20.8 19.63; 10.4 10.98; \n",
            "15.9 15.85; 21.3 20.84; 11.0 10.87; \n",
            "16.9 15.97; 21.6 21.18; 11.3 10.9; \n",
            "16.9 16.56; 22.6 21.45; 14.3 11.62; \n",
            "16.6 16.44; 18.6 21.49; 15.0 11.8; \n",
            "15.0 15.76; 20.3 19.57; 13.5 12.1; \n",
            "15.6 14.79; 21.5 19.27; 11.6 10.7; \n",
            "15.6 16.0; 23.5 20.81; 10.6 11.3; \n",
            "15.4 16.49; 23.3 22.08; 10.0 11.11; \n",
            "13.7 16.26; 17.1 21.96; 11.7 10.73; \n",
            "12.7 14.1; 16.1 18.39; 10.5 9.82; \n",
            "11.7 13.12; 14.5 16.96; 10.0 9.02; \n",
            "8.8 12.24; 12.4 15.79; 8.1 8.34; \n",
            "6.4 9.57; 10.0 12.55; 5.0 5.91; \n",
            "6.9 7.42; 10.0 10.01; 5.3 3.83; \n",
            "6.5 7.99; 11.1 10.64; 2.9 4.47; \n",
            "4.9 7.59; 9.8 10.86; 3.4 3.11; \n",
            "5.9 5.71; 9.0 8.85; 1.2 1.67; \n",
            "6.9 6.76; 10.5 9.81; 5.7 2.66; \n",
            "7.3 7.17; 11.2 9.99; 1.0 3.77; \n",
            "8.7 7.85; 13.0 11.16; 6.0 3.41; \n",
            "11.0 8.56; 14.7 12.03; 7.6 4.72; \n",
            "10.3 10.56; 14.2 14.09; 9.1 6.99; \n",
            "7.5 9.43; 13.0 12.63; 4.9 6.11; \n",
            "6.5 7.27; 12.7 10.46; 2.1 3.5; \n",
            "5.9 6.47; 13.2 10.38; 1.7 1.89; \n",
            "7.2 6.21; 12.8 10.41; 2.4 1.6; \n",
            "8.0 7.54; 10.6 11.84; 5.6 2.71; \n",
            "8.9 7.86; 10.6 10.84; 4.0 4.49; \n",
            "8.1 8.67; 9.7 11.73; 8.0 4.87; \n",
            "8.6 7.67; 9.2 10.0; 7.5 4.87; \n",
            "8.5 8.31; 10.2 10.29; 7.3 5.6; \n",
            "8.2 7.96; 12.0 9.95; 6.4 5.21; \n",
            "5.6 7.8; 11.3 10.24; 1.4 4.66; \n",
            "7.1 5.48; 9.2 8.49; 2.8 1.23; \n",
            "8.8 7.27; 9.8 9.8; 7.6 3.84; \n",
            "9.3 8.32; 10.1 10.25; 8.0 5.55; \n",
            "9.2 8.59; 10.2 9.93; 9.0 6.25; \n",
            "10.2 8.36; 11.4 9.62; 7.0 6.25; \n",
            "12.0 9.56; 14.1 11.36; 10.0 7.03; \n",
            "10.3 11.11; 12.5 13.42; 8.8 8.52; \n",
            "11.4 9.62; 13.0 11.46; 10.5 6.88; \n",
            "11.4 10.39; 13.5 12.2; 10.0 8.02; \n",
            "10.0 10.29; 11.8 12.15; 9.1 7.92; \n",
            "9.6 9.19; 12.9 10.64; 8.0 6.88; \n",
            "8.3 9.3; 12.6 11.2; 6.8 6.7; \n",
            "5.9 8.26; 7.0 10.45; 3.6 5.29; \n",
            "5.6 6.17; 9.4 7.17; 3.9 3.7; \n",
            "4.2 5.9; 6.3 7.89; 1.3 2.79; \n",
            "3.3 4.77; 4.5 6.09; 2.0 1.69; \n",
            "1.8 3.75; 4.8 4.8; -0.7 1.11; \n",
            "1.1 2.47; 2.0 3.96; 0.6 -0.78; \n",
            "-0.3 1.73; 1.0 2.37; -0.8 -0.76; \n",
            "1.2 0.4; 1.5 1.09; -0.5 -2.22; \n",
            "2.4 1.89; 5.3 2.88; 1.0 -0.62; \n",
            "2.4 2.46; 3.2 3.87; 0.4 -0.12; \n",
            "3.0 2.38; 4.4 3.35; 1.4 -0.0; \n",
            "2.1 2.76; 3.2 3.92; 0.6 0.66; \n",
            "2.1 1.72; 3.8 2.42; 1.5 -0.44; \n",
            "-0.8 1.69; 2.5 2.41; -2.2 -0.36; \n",
            "-3.2 -1.39; -0.1 -0.27; -5.4 -3.93; \n",
            "-4.3 -3.15; -0.5 -1.87; -7.0 -5.95; \n",
            "-2.5 -3.88; -0.4 -2.13; -7.5 -7.1; \n",
            "1.2 -1.43; 3.1 0.61; -1.3 -5.04; \n",
            "-0.4 1.55; 2.8 3.32; -1.8 -1.2; \n",
            "-4.3 -0.66; -1.0 0.84; -6.2 -3.59; \n",
            "-2.8 -4.09; -2.3 -2.44; -4.8 -7.51; \n",
            "2.8 -1.85; 4.4 -0.4; -2.4 -4.49; \n",
            "2.8 3.19; 5.0 5.46; 0.2 -0.05; \n",
            "4.1 2.01; 5.7 3.7; 3.0 -0.71; \n",
            "3.3 3.12; 4.2 4.6; 1.0 1.07; \n",
            "7.6 2.36; 10.3 3.38; 3.0 0.32; \n",
            "4.7 6.79; 10.5 9.22; 3.1 3.68; \n",
            "4.0 3.37; 5.8 5.74; 2.2 -0.02; \n",
            "8.3 3.11; 10.0 4.61; 3.8 0.83; \n",
            "7.5 7.23; 10.1 9.33; 5.6 4.52; \n",
            "5.4 6.25; 6.8 8.01; 4.2 3.62; \n",
            "6.9 4.51; 8.0 5.57; 4.6 2.18; \n",
            "7.6 6.25; 9.1 7.75; 3.8 3.93; \n",
            "7.5 7.07; 9.2 8.59; 6.9 4.32; \n",
            "7.6 6.75; 8.5 8.04; 5.7 4.36; \n",
            "9.8 6.95; 12.1 8.13; 7.1 4.53; \n",
            "6.4 8.94; 10.3 10.92; 4.6 6.21; \n",
            "4.6 5.88; 5.1 7.58; 4.2 2.92; \n",
            "2.3 4.36; 4.9 5.01; 1.3 2.24; \n",
            "3.6 2.29; 6.4 3.2; 0.7 -0.19; \n",
            "4.4 3.98; 6.7 5.54; 1.1 0.92; \n",
            "6.2 4.54; 9.3 6.09; 2.2 1.61; \n",
            "5.7 6.12; 9.7 8.41; 2.0 2.83; \n",
            "4.5 5.69; 6.5 7.95; 0.0 2.23; \n",
            "0.9 4.8; 6.5 6.73; -1.2 1.14; \n",
            "3.3 0.94; 4.6 3.41; 1.2 -3.19; \n",
            "1.5 3.64; 3.7 5.29; 0.2 0.76; \n",
            "0.9 1.31; 2.6 2.49; -1.0 -1.59; \n",
            "1.6 1.17; 3.7 2.63; 0.0 -1.63; \n",
            "4.4 1.77; 5.7 3.3; 1.4 -0.93; \n",
            "4.1 4.55; 5.6 6.39; 3.1 1.76; \n",
            "-0.5 3.71; 3.4 5.15; -1.8 1.25; \n",
            "-2.2 -0.89; 0.8 0.69; -3.6 -3.94; \n",
            "-3.6 -1.94; 0.2 -0.36; -6.2 -4.93; \n",
            "-3.8 -3.25; -1.8 -0.94; -7.8 -6.69; \n",
            "-2.0 -3.0; 0.8 -1.17; -5.6 -6.45; \n",
            "-1.6 -1.35; 0.6 0.71; -4.8 -4.6; \n",
            "-0.7 -1.11; 1.7 0.65; -1.6 -4.35; \n",
            "-3.3 -0.33; -1.6 1.29; -4.5 -3.12; \n",
            "-4.2 -3.03; -0.6 -1.83; -5.6 -6.0; \n",
            "-2.6 -3.71; 0.4 -1.67; -5.3 -7.15; \n",
            "-3.3 -2.12; -1.2 0.25; -6.2 -5.2; \n",
            "-2.7 -3.06; -1.6 -1.01; -6.6 -6.12; \n",
            "3.0 -2.14; 4.7 -0.31; -2.3 -4.93; \n",
            "1.2 3.22; 3.5 5.47; -1.7 0.09; \n",
            "2.4 0.52; 4.0 2.04; -1.0 -2.4; \n",
            "3.0 2.2; 8.6 3.97; 2.0 -0.7; \n",
            "1.2 2.02; 3.7 4.24; -0.4 -1.02; \n",
            "-0.9 0.62; 1.0 2.05; -3.1 -2.2; \n",
            "-0.1 -1.25; 0.7 0.47; -2.5 -4.06; \n",
            "1.6 -0.07; 3.5 1.3; -0.3 -2.48; \n",
            "-0.1 1.3; 2.4 2.63; -1.2 -1.18; \n",
            "0.3 -0.53; 1.5 0.79; -0.6 -3.02; \n",
            "0.3 0.24; 1.0 1.31; -0.8 -1.81; \n",
            "1.6 0.26; 3.6 0.9; 0.0 -1.74; \n",
            "0.1 1.56; 3.4 2.96; -1.3 -1.1; \n",
            "-1.5 -0.36; 0.5 1.34; -3.1 -2.98; \n",
            "-2.1 -1.65; 1.6 -0.41; -5.5 -3.91; \n",
            "-3.1 -1.96; 1.6 -0.01; -5.6 -5.06; \n",
            "-2.5 -2.96; -1.5 -0.74; -4.8 -6.56; \n",
            "-1.7 -1.98; -0.7 -0.6; -3.4 -4.6; \n",
            "-1.9 -1.46; -1.0 -0.22; -2.9 -3.84; \n",
            "-2.0 -1.66; -0.6 -0.99; -2.4 -3.9; \n",
            "-3.5 -1.86; -2.1 -1.01; -4.6 -4.17; \n",
            "-4.3 -3.32; -2.2 -2.3; -5.2 -5.66; \n",
            "-4.5 -4.03; -4.1 -2.78; -5.4 -6.5; \n",
            "-5.2 -4.04; -2.5 -3.57; -6.0 -6.16; \n",
            "-4.1 -5.06; 1.0 -3.71; -9.0 -7.81; \n",
            "-5.1 -3.6; -3.4 -0.61; -8.4 -7.34; \n",
            "-1.7 -4.61; 1.0 -3.03; -5.4 -7.56; \n",
            "1.4 -0.94; 7.0 1.3; -1.8 -4.02; \n",
            "3.6 1.19; 8.6 3.98; 0.0 -2.35; \n",
            "5.9 3.0; 9.6 6.05; 1.5 -0.37; \n",
            "4.2 4.82; 9.8 8.0; -0.2 1.66; \n",
            "2.2 3.04; 9.5 6.33; 0.7 -0.72; \n",
            "-0.7 1.16; 2.4 4.66; -3.0 -2.82; \n",
            "0.7 -1.26; 3.3 1.47; -1.7 -4.48; \n",
            "6.7 0.26; 10.5 3.02; 1.0 -2.65; \n",
            "6.5 6.13; 10.4 9.44; 4.1 2.53; \n",
            "8.1 5.31; 11.8 8.42; 5.3 2.04; \n",
            "6.8 7.26; 13.2 10.69; 1.7 4.08; \n",
            "10.2 6.29; 15.6 10.46; 2.5 1.77; \n",
            "8.1 9.99; 16.7 14.62; 2.6 4.98; \n",
            "7.9 7.69; 15.1 12.98; 2.1 1.95; \n",
            "7.8 7.6; 14.5 12.3; 1.7 2.39; \n",
            "9.0 7.61; 12.9 12.24; 3.4 2.34; \n",
            "8.3 8.92; 12.5 13.23; 6.6 4.14; \n",
            "8.8 8.02; 11.1 11.81; 5.5 3.85; \n",
            "11.1 8.76; 13.8 12.13; 6.9 4.78; \n",
            "8.5 10.82; 12.0 14.6; 7.7 6.73; \n",
            "8.3 8.06; 14.0 11.24; 6.0 4.49; \n",
            "3.4 8.27; 7.5 12.0; 0.3 4.04; \n",
            "3.8 3.7; 6.4 6.62; 0.6 -0.52; \n",
            "1.1 4.48; 4.5 7.29; -0.4 0.72; \n",
            "4.8 1.4; 6.4 3.56; 1.4 -2.17; \n",
            "6.1 5.44; 10.0 7.7; 2.9 2.07; \n",
            "4.1 6.15; 5.9 8.96; 2.4 2.55; \n",
            "4.5 4.11; 7.4 5.8; 3.8 1.22; \n",
            "6.4 4.51; 12.2 6.38; 0.5 1.61; \n",
            "7.2 6.74; 11.6 10.56; 0.8 2.08; \n",
            "8.3 7.14; 12.8 10.74; 3.7 2.62; \n",
            "6.8 7.72; 14.2 11.29; 0.5 3.71; \n",
            "7.8 6.5; 16.3 10.56; 0.4 1.4; \n",
            "9.8 8.15; 19.4 13.37; 2.0 2.29; \n",
            "11.3 10.36; 21.0 16.71; 2.5 3.83; \n",
            "13.2 11.74; 21.1 18.3; 3.8 4.91; \n",
            "14.0 13.57; 21.2 20.14; 7.5 6.75; \n",
            "12.8 13.97; 20.6 20.52; 6.1 7.72; \n",
            "13.4 12.92; 20.0 19.39; 7.8 6.44; \n",
            "13.4 13.56; 19.2 19.82; 6.8 7.41; \n",
            "12.4 13.45; 16.8 19.3; 9.1 7.36; \n",
            "10.2 12.12; 12.3 17.11; 7.7 6.97; \n",
            "12.1 10.22; 15.6 13.92; 8.2 5.74; \n",
            "12.5 12.12; 16.8 16.48; 7.8 7.29; \n",
            "11.1 12.65; 14.1 17.19; 7.1 7.66; \n",
            "12.3 11.25; 17.3 15.06; 6.4 6.59; \n",
            "12.6 12.66; 17.7 17.07; 6.7 7.52; \n",
            "16.4 13.01; 23.0 17.7; 7.5 7.59; \n",
            "11.1 16.46; 18.4 22.1; 8.5 10.46; \n",
            "11.5 11.56; 19.0 16.53; 8.1 6.17; \n",
            "10.9 12.24; 15.6 17.16; 4.7 7.07; \n",
            "15.5 11.73; 20.0 16.34; 7.8 6.3; \n",
            "12.8 15.75; 17.6 21.2; 7.5 10.12; \n",
            "8.5 13.03; 12.2 17.87; 6.0 7.65; \n",
            "11.9 8.96; 16.5 12.43; 4.9 4.61; \n",
            "12.4 12.69; 16.8 17.36; 9.4 7.18; \n",
            "12.9 12.68; 19.8 17.34; 5.9 7.84; \n",
            "14.1 13.41; 21.7 18.54; 5.8 7.39; \n",
            "15.9 14.62; 21.7 20.59; 7.2 8.23; \n",
            "15.6 16.07; 19.5 21.85; 13.0 9.92; \n",
            "13.1 15.28; 15.8 20.43; 12.2 10.41; \n",
            "10.0 12.98; 13.3 16.7; 8.4 8.91; \n",
            "5.1 10.07; 9.0 13.11; 3.8 6.02; \n",
            "6.3 5.74; 11.0 8.3; 0.1 2.04; \n",
            "7.2 7.62; 11.6 11.39; 0.5 2.45; \n",
            "8.8 8.6; 14.1 12.44; 3.0 3.24; \n",
            "8.3 9.71; 13.4 14.15; 3.8 4.23; \n",
            "8.5 8.9; 13.6 12.98; 6.7 3.83; \n",
            "11.4 9.02; 17.0 13.03; 3.4 4.41; \n",
            "13.7 12.14; 18.0 17.19; 6.6 6.4; \n",
            "15.2 13.71; 19.4 18.79; 7.6 8.4; \n",
            "15.1 14.65; 19.1 19.6; 9.9 9.34; \n",
            "15.6 14.15; 19.2 18.81; 11.6 9.42; \n",
            "11.7 14.62; 16.4 19.02; 9.8 10.2; \n",
            "10.8 11.19; 16.3 14.96; 8.8 6.86; \n",
            "11.0 10.87; 15.7 14.6; 6.4 6.61; \n",
            "11.1 11.43; 16.0 15.44; 6.1 6.53; \n",
            "13.2 11.68; 19.5 15.93; 4.3 6.79; \n",
            "15.4 13.9; 22.3 19.28; 7.2 7.85; \n",
            "17.2 15.82; 24.0 21.81; 8.7 9.76; \n",
            "17.7 17.3; 24.5 23.44; 9.9 11.15; \n",
            "18.8 17.66; 25.1 23.82; 10.8 11.49; \n",
            "19.2 18.49; 24.9 24.42; 11.3 12.4; \n",
            "17.7 18.66; 25.0 24.56; 13.7 12.57; \n",
            "15.2 17.6; 19.6 23.52; 12.6 11.84; \n",
            "14.4 15.33; 19.0 20.18; 11.8 10.25; \n",
            "15.0 14.67; 19.6 19.32; 8.6 9.81; \n",
            "14.5 15.55; 17.3 20.58; 12.3 9.91; \n",
            "19.7 14.79; 24.5 19.14; 12.3 10.21; \n",
            "17.0 19.08; 23.0 24.5; 15.6 13.72; \n",
            "19.7 16.95; 26.2 22.34; 13.4 12.18; \n",
            "20.0 19.24; 27.0 24.8; 16.0 13.96; \n",
            "19.0 19.42; 26.0 25.28; 14.3 14.28; \n",
            "21.4 18.91; 27.9 24.5; 13.5 13.61; \n",
            "16.4 20.61; 20.9 26.34; 15.3 14.97; \n",
            "16.1 16.48; 20.6 21.3; 13.1 12.11; \n",
            "14.6 16.28; 20.2 20.85; 9.2 11.67; \n",
            "16.4 15.58; 22.5 20.55; 8.5 10.38; \n",
            "18.8 17.36; 23.6 22.91; 10.2 11.25; \n",
            "16.7 18.83; 20.5 24.4; 14.1 13.01; \n",
            "15.6 16.89; 20.5 21.84; 9.8 11.92; \n",
            "13.5 16.36; 15.0 21.25; 10.6 10.69; \n",
            "15.4 14.13; 17.4 17.89; 13.5 9.58; \n",
            "15.7 15.53; 18.6 19.32; 14.1 11.29; \n",
            "15.7 15.65; 17.6 19.5; 13.6 11.65; \n",
            "16.8 15.51; 21.8 18.89; 14.4 11.8; \n",
            "16.3 16.39; 19.8 20.9; 13.2 12.27; \n",
            "15.4 16.06; 18.9 20.17; 12.4 12.12; \n",
            "17.8 15.49; 23.3 19.4; 9.3 11.27; \n",
            "19.7 17.77; 25.4 22.73; 13.4 12.6; \n",
            "22.2 18.99; 27.0 24.19; 15.4 14.04; \n",
            "22.0 20.69; 28.0 25.96; 15.0 15.93; \n",
            "20.5 20.76; 27.5 26.23; 15.6 15.61; \n",
            "16.6 20.02; 20.8 25.55; 14.4 14.83; \n",
            "12.1 16.93; 14.6 21.61; 11.4 12.24; \n",
            "15.1 12.96; 16.3 16.16; 12.0 8.9; \n",
            "16.9 15.6; 21.4 19.1; 14.2 11.42; \n",
            "18.0 17.0; 20.6 21.55; 14.7 12.65; \n",
            "18.3 17.59; 24.0 21.96; 13.3 13.46; \n",
            "17.0 18.19; 23.3 23.39; 14.9 13.3; \n",
            "18.2 17.33; 23.0 22.49; 10.1 12.68; \n",
            "21.3 18.4; 27.2 23.54; 12.9 12.89; \n",
            "22.9 20.53; 29.1 26.11; 17.5 14.9; \n",
            "22.1 21.37; 28.1 26.83; 16.8 16.43; \n",
            "22.8 20.68; 27.2 26.1; 17.0 15.87; \n",
            "23.1 21.37; 29.5 26.69; 15.4 16.52; \n",
            "21.8 21.88; 26.0 27.52; 18.0 16.3; \n",
            "19.3 20.88; 25.0 26.03; 15.6 16.04; \n",
            "20.0 19.43; 25.0 24.63; 13.3 14.05; \n",
            "20.9 19.88; 26.6 25.05; 15.2 14.41; \n",
            "22.2 20.6; 26.5 26.07; 15.9 15.15; \n",
            "21.8 21.39; 27.6 26.74; 17.0 16.01; \n",
            "20.3 21.29; 28.3 26.74; 16.3 15.95; \n",
            "15.3 20.61; 18.0 26.42; 14.4 14.98; \n",
            "17.0 16.25; 21.2 20.43; 13.5 11.81; \n",
            "18.5 17.68; 23.3 22.41; 14.4 12.7; \n",
            "19.7 18.91; 24.4 24.0; 16.1 13.89; \n",
            "20.3 19.44; 23.6 24.51; 15.8 14.74; \n",
            "21.2 19.56; 25.3 24.52; 15.3 15.03; \n",
            "21.9 20.31; 27.4 25.45; 18.0 15.49; \n",
            "20.5 20.95; 25.8 26.28; 16.5 16.16; \n",
            "23.2 20.05; 29.3 25.23; 15.4 15.19; \n",
            "24.9 21.82; 31.0 27.1; 17.5 16.48; \n",
            "26.6 22.87; 32.7 28.32; 18.5 17.76; \n",
            "27.4 23.84; 34.5 29.22; 19.1 18.65; \n",
            "28.0 24.53; 35.5 29.96; 19.1 19.13; \n",
            "26.2 25.0; 32.4 30.42; 22.3 19.44; \n",
            "24.8 23.95; 29.2 29.34; 21.3 18.92; \n",
            "24.4 23.14; 29.6 28.28; 19.4 18.21; \n",
            "22.0 23.07; 26.8 28.24; 18.3 17.82; \n",
            "18.9 21.69; 22.5 26.82; 16.9 16.54; \n",
            "18.6 19.46; 21.2 24.12; 16.4 14.56; \n",
            "20.8 19.22; 24.6 23.6; 17.9 14.56; \n",
            "21.2 20.75; 24.9 25.62; 19.0 15.98; \n",
            "21.2 20.75; 25.2 25.56; 17.6 16.33; \n",
            "22.2 20.71; 27.4 25.53; 17.4 16.12; \n",
            "21.6 21.52; 26.7 26.63; 17.9 16.72; \n",
            "23.5 21.12; 29.0 26.23; 18.6 16.45; \n",
            "21.3 22.22; 27.2 27.38; 19.2 17.46; \n",
            "21.3 20.73; 27.2 25.8; 18.3 16.25; \n",
            "23.9 20.69; 28.8 25.72; 17.5 16.27; \n",
            "24.5 22.42; 30.8 27.62; 18.1 17.68; \n",
            "26.5 23.02; 32.0 28.45; 19.0 17.92; \n",
            "25.4 24.02; 31.2 29.28; 19.5 19.0; \n",
            "21.6 23.44; 28.1 28.8; 18.5 18.39; \n",
            "17.9 21.31; 22.9 26.67; 15.9 16.18; \n",
            "19.7 18.7; 25.0 23.55; 14.7 13.79; \n",
            "19.7 20.15; 24.4 25.28; 16.0 14.78; \n",
            "19.8 20.05; 24.6 25.18; 16.1 14.92; \n",
            "19.1 19.94; 23.5 25.06; 15.5 14.98; \n",
            "19.9 19.4; 24.2 24.48; 14.0 14.49; \n",
            "20.7 20.03; 26.1 25.29; 15.9 14.77; \n",
            "21.5 20.56; 28.0 26.0; 14.7 15.32; \n",
            "22.4 21.16; 28.8 26.72; 15.0 15.59; \n",
            "23.5 21.59; 29.9 27.13; 16.6 15.98; \n",
            "22.3 22.22; 27.6 27.85; 18.6 16.81; \n",
            "21.3 21.33; 26.2 26.74; 19.0 16.31; \n",
            "20.3 20.71; 24.1 25.87; 18.0 15.97; \n",
            "21.3 19.92; 26.0 24.81; 18.0 15.35; \n",
            "21.2 20.63; 25.9 25.68; 16.6 16.04; \n",
            "18.2 20.69; 21.5 25.82; 16.3 15.8; \n",
            "17.9 18.36; 20.5 22.83; 14.8 13.98; \n",
            "20.7 18.06; 26.0 22.23; 17.0 13.69; \n",
            "22.2 20.28; 27.1 25.38; 17.8 15.59; \n",
            "21.4 21.29; 27.1 26.4; 17.1 16.62; \n",
            "21.7 20.73; 28.2 25.9; 16.0 15.97; \n",
            "21.9 21.12; 28.7 26.48; 15.7 16.08; \n",
            "23.1 21.47; 30.1 27.08; 15.6 16.11; \n",
            "23.5 22.31; 30.6 27.95; 17.0 16.71; \n",
            "23.4 22.45; 31.0 28.1; 17.3 16.93; \n",
            "24.2 22.34; 29.0 28.03; 19.3 16.93; \n",
            "21.4 22.64; 27.0 28.09; 18.8 17.67; \n",
            "18.7 21.03; 24.6 26.49; 13.4 15.97; \n",
            "19.4 19.42; 25.2 24.78; 14.2 13.77; \n",
            "17.1 19.95; 21.4 25.46; 11.6 14.3; \n",
            "15.7 18.09; 21.3 23.19; 11.0 12.38; \n",
            "15.4 16.96; 21.0 22.07; 12.0 11.24; \n",
            "14.3 16.78; 21.0 21.94; 8.3 11.24; \n",
            "15.7 15.98; 23.1 21.47; 8.3 9.79; \n",
            "16.7 17.28; 23.8 23.3; 9.8 10.73; \n",
            "15.9 17.94; 21.4 24.13; 11.0 11.47; \n",
            "16.6 16.72; 22.3 22.25; 9.5 10.99; \n",
            "16.3 17.33; 22.0 23.15; 12.5 11.19; \n",
            "16.0 16.76; 23.3 22.38; 9.8 11.25; \n",
            "18.2 16.69; 23.6 22.53; 10.0 10.7; \n",
            "16.5 18.29; 23.2 24.12; 12.8 12.2; \n",
            "17.8 16.84; 24.7 22.58; 10.5 11.21; \n",
            "17.6 17.9; 24.8 23.82; 11.4 11.83; \n",
            "19.5 17.97; 27.1 24.08; 11.7 11.83; \n",
            "17.0 19.5; 23.1 25.78; 12.9 13.12; \n",
            "15.9 17.26; 23.7 22.99; 9.4 11.7; \n",
            "19.2 16.88; 26.3 22.93; 9.8 10.44; \n",
            "15.4 19.48; 21.1 25.76; 12.4 12.85; \n",
            "12.7 16.07; 19.7 21.73; 7.4 10.43; \n",
            "12.3 14.01; 20.5 19.51; 4.9 7.71; \n",
            "14.4 14.17; 21.7 20.3; 6.2 7.24; \n",
            "14.9 15.92; 23.8 22.32; 8.3 8.82; \n",
            "20.3 16.13; 27.5 22.92; 9.0 9.17; \n",
            "19.2 20.16; 24.4 26.73; 17.6 13.14; \n",
            "16.4 18.61; 21.8 24.75; 14.7 13.34; \n",
            "14.9 16.33; 18.5 21.88; 12.0 11.33; \n",
            "15.0 15.1; 17.2 19.97; 11.5 10.13; \n",
            "12.0 15.11; 15.8 19.41; 10.2 10.55; \n",
            "12.1 12.15; 16.7 15.93; 10.4 7.79; \n",
            "8.9 12.54; 15.1 16.37; 5.4 8.39; \n",
            "8.7 9.98; 13.9 14.06; 4.8 4.88; \n",
            "8.5 9.99; 17.8 14.02; 1.3 5.27; \n",
            "10.5 10.33; 19.3 16.05; 3.7 3.57; \n",
            "12.1 12.33; 20.7 18.43; 4.7 5.78; \n",
            "12.1 13.51; 17.5 19.95; 7.1 6.95; \n",
            "8.4 12.7; 13.3 18.25; 4.2 7.21; \n",
            "7.1 9.07; 13.4 13.48; 5.0 3.89; \n",
            "8.5 7.81; 17.1 12.61; 2.0 2.66; \n",
            "11.9 9.71; 17.4 15.6; 5.6 3.4; \n",
            "12.3 12.23; 21.0 17.86; 7.7 6.53; \n",
            "11.5 12.39; 18.0 18.58; 4.8 6.64; \n",
            "10.1 11.67; 16.9 17.44; 4.9 5.68; \n",
            "10.2 10.68; 15.6 16.46; 8.5 4.74; \n",
            "9.0 10.45; 15.0 15.66; 3.6 5.5; \n",
            "6.4 9.43; 13.6 14.16; 2.4 4.06; \n",
            "6.4 6.91; 14.2 11.78; 0.3 1.4; \n",
            "6.3 7.34; 14.9 12.79; 0.7 1.45; \n",
            "7.3 7.23; 16.6 13.13; 0.7 0.92; \n",
            "8.4 8.74; 18.4 15.32; 0.5 1.79; \n",
            "9.5 9.54; 19.5 16.63; 2.8 2.17; \n",
            "8.8 10.44; 19.5 17.63; 1.9 3.48; \n",
            "12.0 9.89; 17.8 17.56; 4.8 2.31; \n",
            "13.2 12.5; 17.8 19.0; 9.8 6.25; \n",
            "10.4 12.71; 13.8 18.58; 9.1 7.48; \n",
            "11.0 9.67; 13.8 14.07; 7.0 5.46; \n",
            "12.5 10.52; 18.4 14.75; 4.2 6.18; \n",
            "10.4 12.33; 15.0 17.84; 6.8 6.47; \n",
            "13.1 10.2; 20.2 14.62; 5.3 5.33; \n",
            "17.4 13.15; 22.0 18.65; 11.0 7.02; \n",
            "16.0 16.46; 19.9 21.92; 14.6 11.14; \n",
            "8.4 14.93; 14.6 19.62; 7.2 10.7; \n",
            "8.6 8.48; 11.6 12.17; 4.5 3.89; \n",
            "9.2 9.51; 12.2 12.84; 6.8 5.25; \n",
            "8.6 9.78; 11.3 13.14; 4.0 5.62; \n",
            "10.7 9.17; 13.5 12.21; 7.4 4.96; \n",
            "9.1 10.76; 12.8 13.98; 7.1 6.78; \n",
            "6.7 9.23; 8.2 12.29; 5.0 5.55; \n",
            "6.9 7.16; 7.6 9.18; 5.7 3.77; \n",
            "6.6 7.4; 7.8 9.11; 5.7 4.27; \n",
            "6.1 6.73; 7.8 8.09; 5.3 3.87; \n",
            "5.9 6.06; 7.1 7.35; 4.7 3.55; \n",
            "5.3 5.81; 6.3 6.99; 4.4 3.41; \n",
            "4.8 5.24; 7.0 6.02; 2.2 3.16; \n",
            "4.6 4.96; 6.5 6.27; 2.7 2.07; \n",
            "7.6 4.7; 10.9 5.95; 3.7 1.95; \n",
            "7.9 7.47; 12.0 9.7; 3.0 4.33; \n",
            "6.8 7.57; 8.5 10.12; 4.8 3.96; \n",
            "5.6 6.36; 7.8 7.8; 5.3 3.71; \n",
            "6.5 5.1; 9.7 6.27; 2.6 2.68; \n",
            "8.0 6.43; 9.7 8.51; 5.0 3.09; \n",
            "6.9 7.63; 10.6 9.59; 5.4 4.65; \n",
            "8.3 6.24; 9.8 8.28; 4.6 3.38; \n",
            "6.2 7.86; 8.2 9.72; 5.0 5.02; \n",
            "3.2 5.81; 6.2 7.31; 3.0 3.06; \n",
            "1.3 3.06; 3.2 4.47; 0.1 0.26; \n",
            "-0.9 1.46; 2.5 2.53; -3.5 -1.13; \n",
            "-0.4 -0.4; 2.5 1.27; -3.6 -3.77; \n",
            "1.4 0.5; 5.6 2.4; -2.0 -2.81; \n",
            "3.2 1.95; 8.2 4.41; -0.9 -1.7; \n",
            "4.8 3.62; 6.1 6.65; 1.0 -0.45; \n",
            "4.6 4.94; 6.7 7.11; 3.5 1.82; \n",
            "5.9 4.1; 8.5 5.87; 3.3 1.33; \n",
            "6.2 5.43; 8.1 7.58; 4.4 2.44; \n",
            "7.9 5.31; 9.3 7.17; 4.8 2.73; \n",
            "7.1 6.8; 11.0 8.72; 5.0 4.3; \n",
            "8.3 5.77; 11.0 7.91; 5.2 2.97; \n",
            "5.3 7.4; 8.2 9.61; 4.6 4.48; \n",
            "5.1 4.35; 5.6 6.05; 4.5 1.69; \n",
            "2.8 4.63; 6.1 5.58; 1.8 2.69; \n",
            "2.5 2.38; 4.0 3.58; -0.2 -0.34; \n",
            "4.2 2.81; 5.0 4.08; 2.4 0.15; \n",
            "4.5 4.2; 5.8 5.36; 2.8 1.95; \n",
            "4.3 4.36; 5.4 5.35; 3.6 2.04; \n",
            "4.4 4.12; 4.8 4.86; 3.3 1.9; \n",
            "8.2 4.18; 9.7 4.92; 4.5 2.13; \n",
            "1.8 7.65; 8.3 9.38; 1.2 5.04; \n",
            "0.9 0.84; 1.8 2.53; 0.2 -2.39; \n",
            "1.0 1.1; 1.6 1.87; 0.2 -0.94; \n",
            "1.8 0.93; 2.6 1.55; 1.0 -0.89; \n",
            "-0.2 1.75; 2.2 2.27; -0.5 -0.32; \n",
            "2.5 -0.54; 4.8 0.06; -1.2 -2.73; \n",
            "2.0 2.68; 4.5 4.41; -0.6 0.16; \n",
            "2.7 1.9; 4.9 3.25; -0.2 -0.62; \n",
            "1.6 2.85; 3.0 4.4; 0.4 -0.06; \n",
            "0.9 1.29; 4.6 2.25; -0.3 -1.22; \n",
            "3.3 0.49; 4.7 2.28; 0.0 -2.23; \n",
            "4.8 3.11; 7.6 4.46; 2.4 0.66; \n",
            "5.9 4.11; 9.6 5.85; 0.6 1.54; \n",
            "6.8 5.36; 10.0 7.79; 5.3 1.93; \n",
            "5.8 5.89; 8.4 8.11; 5.0 3.23; \n",
            "4.8 4.83; 7.4 6.54; 3.2 2.38; \n",
            "5.9 4.01; 7.9 5.69; 2.7 1.41; \n",
            "5.7 5.33; 9.5 7.12; 4.6 2.61; \n",
            "2.4 4.8; 5.1 6.84; -0.4 2.07; \n",
            "2.3 2.07; 3.1 3.68; 1.4 -0.7; \n",
            "2.7 2.33; 5.3 3.43; 1.7 0.08; \n",
            "2.0 2.73; 4.4 4.11; 0.4 0.17; \n",
            "2.5 1.92; 5.3 3.4; 1.1 -0.96; \n",
            "1.9 2.53; 2.8 4.22; -0.3 -0.06; \n",
            "2.0 1.95; 4.3 3.08; 1.1 -0.41; \n",
            "1.7 2.01; 4.5 3.27; -0.4 -0.39; \n",
            "-0.1 1.69; 2.0 3.35; -1.0 -1.29; \n",
            "-6.6 -0.28; -0.8 0.95; -8.2 -2.61; \n",
            "-8.1 -7.0; -6.0 -4.94; -11.1 -10.71; \n",
            "-5.4 -6.94; -4.0 -5.32; -9.1 -10.57; \n",
            "-5.4 -3.91; -3.3 -1.92; -6.1 -7.29; \n",
            "-8.5 -4.77; -5.5 -3.35; -9.8 -7.84; \n",
            "-8.7 -7.96; -6.9 -6.66; -14.0 -11.41; \n",
            "-3.6 -7.0; -2.2 -4.72; -7.2 -11.42; \n",
            "-5.3 -1.72; -2.9 0.65; -6.4 -5.15; \n",
            "-3.8 -4.94; -2.8 -3.41; -6.4 -8.22; \n",
            "-2.2 -2.79; 2.7 -1.15; -5.0 -5.71; \n",
            "-7.4 -2.1; -3.0 0.78; -11.5 -5.43; \n",
            "1.5 -7.38; 3.0 -4.92; -6.1 -11.79; \n",
            "-1.6 2.8; 2.0 6.05; -3.0 -0.83; \n",
            "-4.2 -2.58; -2.3 -0.82; -6.5 -5.6; \n",
            "-2.4 -3.93; -1.4 -2.5; -5.2 -7.23; \n",
            "0.5 -2.07; 1.2 -0.48; -1.6 -4.81; \n",
            "1.3 0.65; 3.8 1.97; -1.1 -1.94; \n",
            "2.9 0.78; 6.5 2.36; -0.9 -1.93; \n",
            "1.7 2.44; 4.3 4.93; -0.6 -0.76; \n",
            "4.7 1.0; 9.0 2.9; 0.4 -1.7; \n",
            "5.5 4.19; 7.8 7.19; 4.1 0.71; \n",
            "-0.5 4.35; 6.6 6.25; -2.6 1.7; \n",
            "-7.2 -1.77; -2.5 1.0; -9.2 -5.61; \n",
            "-8.8 -7.7; -4.4 -5.49; -12.2 -11.29; \n",
            "-8.2 -8.05; -4.2 -4.87; -11.7 -12.3; \n",
            "-7.6 -7.06; -4.5 -3.95; -12.3 -11.57; \n",
            "-7.7 -6.23; -5.0 -2.98; -11.7 -10.65; \n",
            "-8.6 -6.48; -4.1 -3.42; -12.6 -10.84; \n",
            "-7.7 -6.92; -3.8 -3.27; -12.1 -12.25; \n",
            "-6.5 -5.72; -1.0 -1.83; -11.5 -11.2; \n",
            "-3.4 -4.77; 1.7 -0.27; -8.7 -10.34; \n",
            "-1.4 -2.17; 1.6 2.47; -7.5 -6.97; \n",
            "1.4 -0.51; 5.4 3.18; -3.7 -4.79; \n",
            "4.2 1.61; 6.7 5.44; 1.0 -2.7; \n",
            "6.9 3.58; 10.5 6.52; 1.0 0.34; \n",
            "2.4 5.71; 7.4 9.21; 1.4 1.77; \n",
            "2.0 0.64; 8.0 3.36; 0.5 -2.73; \n",
            "1.2 1.01; 3.3 4.3; -1.1 -2.66; \n",
            "0.2 0.51; 1.0 2.76; 0.0 -2.5; \n",
            "2.3 -0.27; 4.0 1.49; -0.4 -2.62; \n",
            "2.5 1.94; 4.0 3.93; 1.3 -0.72; \n",
            "5.3 1.94; 8.5 3.41; 2.4 -0.25; \n",
            "6.1 4.87; 10.0 7.46; 3.2 2.01; \n",
            "3.0 5.43; 6.0 8.02; 0.2 2.42; \n",
            "6.2 2.48; 8.4 4.38; 3.7 -0.7; \n",
            "5.7 5.71; 8.0 8.04; 4.4 2.86; \n",
            "5.1 4.66; 8.6 6.28; 1.5 2.23; \n",
            "5.0 4.35; 9.5 6.42; 3.8 1.21; \n",
            "2.9 4.24; 6.0 6.42; 0.2 1.58; \n",
            "5.9 2.54; 9.0 4.34; 2.8 -0.41; \n",
            "6.9 5.86; 15.0 8.34; 3.0 2.69; \n",
            "6.6 6.8; 8.2 11.13; 3.8 2.23; \n",
            "6.3 6.05; 7.4 8.29; 6.0 3.15; \n",
            "7.5 5.56; 12.5 7.27; 2.8 3.46; \n",
            "8.1 7.24; 11.6 10.52; 6.3 3.28; \n",
            "6.0 7.57; 10.4 10.27; 3.9 4.47; \n",
            "1.6 5.36; 4.6 8.26; -0.8 1.97; \n",
            "-0.8 1.39; 2.0 3.29; -3.2 -1.58; \n",
            "-0.7 -0.16; 1.8 1.73; -4.5 -3.6; \n",
            "2.0 0.24; 5.4 2.68; -0.8 -3.81; \n",
            "3.2 2.48; 7.0 5.08; -1.2 -0.94; \n",
            "5.6 3.45; 10.0 5.99; -0.7 -0.4; \n",
            "4.6 5.95; 6.5 9.29; 3.9 1.64; \n",
            "6.3 4.29; 11.2 6.38; 3.0 1.24; \n",
            "7.4 6.16; 14.6 9.51; 1.4 2.11; \n",
            "10.3 7.14; 16.5 11.52; 5.4 2.21; \n",
            "12.8 9.6; 17.0 14.21; 8.5 5.15; \n",
            "8.5 11.2; 14.0 15.35; 4.5 7.48; \n",
            "4.3 7.51; 7.2 11.27; 3.4 3.3; \n",
            "1.9 3.85; 3.5 6.23; 1.0 0.56; \n",
            "5.1 1.81; 6.5 3.7; 1.6 -0.97; \n",
            "8.6 5.3; 12.4 7.51; 4.9 2.04; \n",
            "7.2 8.46; 13.4 11.57; 3.0 4.74; \n",
            "8.0 6.91; 13.3 10.64; 0.7 2.6; \n",
            "7.5 8.34; 12.4 12.6; 2.1 3.37; \n",
            "9.2 7.95; 13.2 12.17; 1.8 2.81; \n",
            "9.9 9.58; 13.6 13.65; 5.7 4.29; \n",
            "8.0 9.51; 10.0 13.13; 6.5 5.04; \n",
            "12.6 7.27; 17.1 9.35; 6.7 4.09; \n",
            "12.3 11.97; 16.5 15.98; 10.0 7.72; \n",
            "11.8 11.73; 15.5 15.76; 8.3 7.79; \n",
            "11.7 11.38; 16.2 15.06; 9.4 7.19; \n",
            "10.1 11.17; 15.0 14.96; 7.3 7.28; \n",
            "10.6 10.0; 17.0 13.64; 3.6 5.81; \n",
            "11.5 10.87; 17.6 15.4; 5.2 5.62; \n",
            "10.8 11.83; 16.0 16.72; 5.9 6.64; \n",
            "10.5 11.01; 16.4 15.26; 6.7 6.13; \n",
            "8.2 10.9; 11.4 15.36; 4.1 6.18; \n",
            "10.7 8.79; 14.4 12.27; 6.5 4.12; \n",
            "8.7 11.08; 11.5 15.07; 6.5 6.58; \n",
            "11.7 8.95; 16.5 12.04; 5.8 4.94; \n",
            "10.9 12.05; 13.6 16.42; 9.0 7.07; \n",
            "12.3 10.71; 18.2 14.08; 6.7 6.97; \n",
            "13.8 12.28; 18.6 16.95; 9.3 7.29; \n",
            "14.3 13.53; 19.8 18.12; 10.8 8.89; \n",
            "15.6 14.04; 21.9 18.91; 8.5 9.41; \n",
            "12.1 15.16; 15.8 20.32; 10.8 9.95; \n",
            "10.2 11.85; 12.6 15.66; 8.9 8.02; \n",
            "15.1 10.09; 20.4 12.82; 9.1 6.6; \n",
            "17.2 14.97; 21.8 19.76; 13.0 10.34; \n",
            "18.0 16.64; 22.0 21.65; 12.3 12.05; \n",
            "14.8 16.94; 19.2 21.76; 12.4 12.5; \n",
            "15.1 14.39; 20.1 18.65; 9.6 10.26; \n",
            "12.3 15.38; 15.9 20.1; 9.8 10.34; \n",
            "10.9 12.69; 14.4 16.47; 8.8 8.29; \n",
            "8.2 11.31; 12.1 14.55; 4.4 7.25; \n",
            "5.9 8.92; 9.7 11.64; 3.9 4.65; \n",
            "6.6 7.07; 11.8 9.66; 2.1 3.21; \n",
            "7.3 8.09; 12.0 11.85; 2.2 3.03; \n",
            "8.4 8.7; 13.7 12.52; 2.6 3.66; \n",
            "10.1 9.58; 13.3 13.87; 5.3 4.16; \n",
            "9.0 10.6; 14.0 14.53; 7.0 6.01; \n",
            "8.5 9.23; 11.3 13.03; 6.9 4.84; \n",
            "9.5 8.6; 14.5 11.59; 6.3 4.89; \n",
            "9.8 9.48; 15.3 13.24; 4.1 5.38; \n",
            "12.7 9.8; 17.0 14.0; 3.5 5.04; \n",
            "14.3 12.59; 18.4 17.25; 9.9 7.35; \n",
            "11.6 13.5; 13.6 18.12; 10.2 9.01; \n",
            "12.3 10.8; 18.0 13.69; 9.5 7.38; \n",
            "10.4 11.92; 12.6 16.01; 8.0 7.67; \n",
            "12.2 10.21; 15.6 13.05; 9.3 6.6; \n",
            "14.0 11.87; 18.7 15.29; 10.1 8.08; \n",
            "16.5 13.75; 22.9 17.97; 9.0 9.55; \n",
            "17.8 16.16; 23.6 21.49; 11.2 10.87; \n",
            "17.2 16.96; 22.9 22.42; 9.6 11.98; \n",
            "14.8 16.8; 19.7 22.3; 11.0 11.36; \n",
            "17.6 14.84; 22.6 19.41; 12.9 9.94; \n",
            "18.3 17.35; 24.0 22.48; 9.4 12.46; \n",
            "21.6 17.91; 28.3 23.29; 15.5 12.13; \n",
            "23.3 20.38; 29.2 26.18; 15.7 15.11; \n",
            "23.6 21.48; 27.9 27.27; 18.5 16.08; \n",
            "18.7 21.52; 23.5 27.0; 17.2 16.59; \n",
            "18.7 18.42; 23.5 23.52; 15.0 13.55; \n",
            "20.3 18.44; 25.2 23.39; 15.0 13.57; \n",
            "14.4 19.83; 19.0 24.94; 12.0 14.71; \n",
            "16.0 15.23; 21.9 19.64; 11.5 10.29; \n",
            "15.9 16.74; 19.7 21.49; 10.5 11.73; \n",
            "14.8 16.76; 19.5 21.63; 8.6 11.45; \n",
            "12.9 16.01; 18.0 20.91; 7.5 10.35; \n",
            "13.7 14.4; 15.8 19.18; 10.3 8.7; \n",
            "15.9 14.59; 20.6 18.45; 11.1 9.97; \n",
            "16.1 16.45; 20.8 21.29; 13.0 11.33; \n",
            "20.7 16.43; 27.1 21.36; 13.9 11.61; \n",
            "22.5 19.84; 28.8 25.37; 14.4 14.56; \n",
            "21.0 21.02; 27.8 26.91; 16.0 15.62; \n",
            "20.1 20.15; 27.1 25.93; 15.2 14.76; \n",
            "21.0 19.55; 28.9 25.23; 14.9 14.21; \n",
            "21.1 20.34; 27.7 26.21; 16.1 14.77; \n",
            "22.8 20.35; 27.8 26.05; 16.0 15.0; \n",
            "21.6 21.35; 28.0 26.85; 16.7 16.2; \n",
            "21.2 20.81; 27.3 26.48; 16.4 15.49; \n",
            "23.2 20.81; 27.7 26.51; 16.7 15.46; \n",
            "21.0 21.97; 28.4 27.46; 17.4 16.63; \n",
            "16.4 20.82; 19.8 26.59; 15.0 15.3; \n",
            "18.6 17.04; 22.9 21.42; 12.7 12.36; \n",
            "21.4 18.88; 25.7 23.85; 14.4 13.58; \n",
            "22.7 20.93; 28.5 26.3; 14.5 15.45; \n",
            "19.4 21.8; 24.8 27.36; 16.6 16.13; \n",
            "19.9 19.4; 24.8 24.66; 14.4 14.33; \n",
            "20.4 19.84; 25.1 25.04; 13.8 14.54; \n",
            "21.0 20.25; 25.2 25.57; 17.4 14.71; \n",
            "23.8 20.55; 28.7 25.72; 14.1 15.56; \n",
            "16.3 22.25; 24.4 27.49; 13.9 16.61; \n",
            "17.4 17.36; 22.1 22.87; 12.3 11.88; \n",
            "19.8 18.22; 24.0 23.26; 12.8 12.81; \n",
            "20.4 19.79; 25.3 25.14; 14.1 14.23; \n",
            "22.0 20.33; 26.7 25.69; 17.7 14.64; \n",
            "22.1 21.0; 27.5 26.33; 15.0 16.02; \n",
            "19.5 21.17; 23.1 26.64; 16.4 15.86; \n",
            "20.6 19.4; 28.1 24.45; 17.4 14.39; \n",
            "21.5 20.46; 27.8 26.07; 16.5 15.3; \n",
            "14.4 20.96; 20.7 26.41; 13.3 15.66; \n",
            "15.3 15.5; 20.1 20.23; 11.5 10.49; \n",
            "13.8 16.22; 17.3 20.92; 11.0 11.36; \n",
            "15.6 14.94; 19.3 19.18; 9.1 10.36; \n",
            "18.3 16.67; 23.5 21.49; 10.8 11.24; \n",
            "15.2 18.6; 19.6 24.09; 13.2 13.08; \n",
            "19.1 15.64; 24.3 20.21; 12.4 11.03; \n",
            "22.3 18.94; 27.9 24.3; 14.4 13.68; \n",
            "19.5 21.19; 24.7 26.96; 17.2 15.63; \n",
            "24.3 18.92; 31.6 24.08; 15.2 14.05; \n",
            "18.2 22.3; 24.2 27.96; 16.3 16.81; \n",
            "19.3 18.2; 24.6 23.57; 14.0 13.2; \n",
            "23.1 19.05; 30.1 24.18; 13.6 13.91; \n",
            "23.3 21.88; 30.7 27.69; 16.3 16.09; \n",
            "17.0 22.23; 22.6 28.05; 15.5 16.43; \n",
            "21.1 17.42; 25.6 22.59; 14.7 12.41; \n",
            "22.3 20.54; 27.7 25.92; 15.5 15.32; \n",
            "22.7 21.65; 29.0 27.3; 16.7 15.91; \n",
            "21.2 21.87; 26.2 27.57; 17.7 16.38; \n",
            "23.2 20.58; 29.5 25.89; 17.3 15.42; \n",
            "26.1 22.03; 31.8 27.59; 17.6 16.7; \n",
            "27.1 23.74; 34.5 29.26; 19.7 18.33; \n",
            "19.9 24.4; 26.6 29.97; 18.5 18.92; \n",
            "20.4 19.98; 25.6 25.32; 16.3 14.74; \n",
            "15.9 20.36; 24.0 25.55; 12.7 15.26; \n",
            "13.5 17.63; 16.3 23.28; 11.1 11.72; \n",
            "13.1 15.11; 15.3 19.23; 12.1 10.27; \n",
            "17.3 14.34; 22.1 17.96; 11.8 10.06; \n",
            "18.1 18.09; 22.5 23.24; 15.9 12.95; \n",
            "18.2 18.35; 21.6 23.58; 14.3 13.71; \n",
            "19.4 18.11; 25.1 23.06; 12.8 13.51; \n",
            "20.8 19.14; 27.3 24.47; 13.5 13.77; \n",
            "21.5 20.37; 27.6 26.06; 15.4 14.82; \n",
            "23.5 20.6; 30.1 26.15; 15.9 15.26; \n",
            "20.4 21.75; 25.3 27.28; 17.2 16.39; \n",
            "20.4 19.54; 26.0 24.67; 16.4 14.85; \n",
            "20.1 19.77; 25.7 24.98; 16.1 15.02; \n",
            "22.1 19.91; 28.8 25.3; 13.5 14.79; \n",
            "20.9 21.61; 26.0 27.25; 19.0 15.76; \n",
            "20.0 20.36; 24.7 25.77; 16.1 15.58; \n",
            "20.1 19.7; 26.8 24.82; 15.0 14.78; \n",
            "18.4 20.14; 22.0 25.74; 16.5 14.63; \n",
            "20.5 18.72; 25.7 23.66; 15.7 14.08; \n",
            "22.3 20.1; 27.9 25.31; 14.3 15.03; \n",
            "24.0 21.56; 29.4 27.03; 18.2 16.15; \n",
            "18.6 22.45; 24.2 27.95; 16.3 17.27; \n",
            "19.9 18.65; 24.0 23.76; 12.8 13.88; \n",
            "20.7 19.84; 26.6 24.89; 14.4 14.39; \n",
            "18.3 20.66; 23.5 26.14; 15.0 15.04; \n",
            "20.1 18.66; 26.3 23.75; 13.4 13.58; \n",
            "22.3 20.08; 30.0 25.44; 14.5 14.45; \n",
            "19.3 21.87; 27.6 27.82; 17.4 15.97; \n",
            "16.8 19.74; 21.9 25.75; 14.0 14.33; \n",
            "17.1 17.68; 22.0 22.91; 13.1 12.45; \n",
            "18.1 17.93; 24.0 23.16; 12.3 12.55; \n",
            "21.6 18.7; 29.6 24.28; 13.8 13.13; \n",
            "23.4 21.21; 30.0 27.31; 18.3 15.33; \n",
            "23.4 22.07; 30.1 27.95; 18.5 16.77; \n",
            "24.8 21.88; 32.5 27.72; 17.0 16.72; \n",
            "26.6 22.96; 34.0 28.84; 18.7 17.38; \n",
            "25.5 24.14; 31.8 29.86; 19.5 18.45; \n",
            "21.0 23.35; 25.0 28.92; 18.6 17.93; \n",
            "19.6 20.3; 25.0 25.36; 15.5 15.49; \n",
            "16.7 19.62; 21.1 24.73; 14.2 14.41; \n",
            "19.1 17.56; 23.5 22.32; 13.7 12.55; \n",
            "17.4 19.51; 23.4 24.59; 13.7 14.06; \n",
            "18.3 18.42; 24.0 23.72; 12.4 12.9; \n",
            "20.9 19.08; 27.8 24.47; 12.8 13.45; \n",
            "20.0 20.96; 25.1 26.94; 17.4 14.85; \n",
            "16.0 20.02; 19.0 25.63; 14.8 14.85; \n",
            "14.3 16.55; 18.5 20.76; 11.5 12.02; \n",
            "13.2 15.23; 18.0 19.48; 9.4 10.63; \n",
            "12.8 14.45; 19.0 18.8; 8.4 9.46; \n",
            "13.4 14.13; 20.1 18.94; 6.8 8.86; \n",
            "14.8 14.8; 21.7 20.03; 7.7 8.95; \n",
            "17.1 15.87; 22.6 21.59; 10.0 9.8; \n",
            "16.0 17.44; 22.3 23.22; 11.1 11.71; \n",
            "15.5 16.58; 20.7 22.43; 8.4 10.76; \n",
            "15.5 16.22; 18.5 21.59; 10.7 10.32; \n",
            "15.6 15.7; 16.9 20.47; 12.7 10.68; \n",
            "19.3 15.28; 25.9 19.2; 13.6 11.05; \n",
            "20.5 18.61; 26.5 24.11; 13.2 13.32; \n",
            "20.6 19.55; 26.3 25.19; 13.8 14.1; \n",
            "17.7 19.49; 22.7 25.1; 14.4 14.03; \n",
            "19.4 17.43; 24.7 22.52; 13.7 12.44; \n",
            "16.3 19.15; 19.9 24.45; 15.2 13.72; \n",
            "15.8 16.39; 21.0 20.78; 13.3 11.94; \n",
            "12.4 16.03; 17.8 20.57; 8.1 11.52; \n",
            "13.0 13.48; 20.1 17.65; 6.6 8.56; \n",
            "12.8 14.73; 19.0 20.11; 7.1 8.89; \n",
            "10.8 14.37; 17.0 19.75; 8.7 8.37; \n",
            "8.1 12.2; 10.7 17.03; 7.0 6.99; \n",
            "11.2 9.32; 16.5 12.31; 3.3 5.06; \n",
            "11.5 12.55; 16.0 17.51; 9.0 6.86; \n",
            "10.5 12.3; 11.5 16.89; 9.6 7.51; \n",
            "12.5 10.79; 19.0 13.71; 7.1 7.35; \n",
            "12.4 12.82; 16.8 17.58; 10.0 7.78; \n",
            "14.3 12.51; 19.1 16.81; 8.2 8.27; \n",
            "14.1 14.01; 19.0 18.75; 10.9 9.09; \n",
            "15.6 13.74; 21.5 18.36; 12.5 9.37; \n",
            "14.1 15.24; 18.7 20.09; 11.2 10.73; \n",
            "13.6 13.58; 18.3 17.83; 11.0 9.62; \n",
            "15.1 13.4; 21.2 17.74; 9.3 9.31; \n",
            "13.5 15.14; 18.5 20.14; 12.3 10.16; \n",
            "12.1 13.57; 13.1 17.94; 11.8 9.66; \n",
            "11.5 11.93; 14.6 14.73; 10.0 8.77; \n",
            "8.5 11.51; 10.8 14.6; 6.3 8.2; \n",
            "9.3 9.05; 14.6 11.36; 5.2 5.57; \n",
            "11.1 10.16; 13.4 13.97; 6.3 5.69; \n",
            "10.2 11.61; 12.4 14.87; 9.3 7.6; \n",
            "8.3 10.25; 12.2 12.75; 6.8 6.95; \n",
            "8.5 8.64; 12.2 11.11; 6.8 5.07; \n",
            "8.2 8.83; 10.3 11.64; 3.7 5.23; \n",
            "10.7 8.66; 15.6 11.16; 5.0 4.94; \n",
            "10.5 11.09; 14.0 15.0; 8.5 6.6; \n",
            "12.0 10.36; 17.1 13.32; 9.4 6.83; \n",
            "13.1 11.65; 18.6 15.54; 8.6 7.83; \n",
            "16.3 12.79; 21.2 17.23; 10.3 8.52; \n",
            "16.0 15.67; 20.0 20.68; 14.0 11.06; \n",
            "14.6 14.98; 16.7 19.37; 13.4 11.25; \n",
            "14.0 13.65; 18.1 17.07; 8.9 10.44; \n",
            "11.0 13.52; 15.0 17.35; 7.0 9.37; \n",
            "13.0 11.01; 17.4 14.44; 9.5 6.93; \n",
            "14.4 13.01; 19.8 16.87; 11.5 8.8; \n",
            "12.4 14.4; 17.6 18.82; 10.9 10.09; \n",
            "11.7 12.61; 16.5 16.56; 9.3 8.53; \n",
            "12.1 12.07; 13.6 16.03; 9.3 7.99; \n",
            "11.2 12.37; 12.5 15.67; 10.2 8.72; \n",
            "13.8 11.43; 16.6 14.1; 11.0 8.17; \n",
            "12.4 13.69; 18.1 17.18; 10.0 10.17; \n",
            "9.0 12.28; 13.3 16.09; 7.4 8.43; \n",
            "7.6 9.17; 10.0 12.03; 6.0 5.73; \n",
            "6.1 8.07; 10.6 10.3; 2.6 4.88; \n",
            "6.3 6.97; 8.3 9.76; 4.2 2.73; \n",
            "6.3 6.99; 8.2 9.15; 3.4 3.58; \n",
            "8.4 6.65; 10.9 8.69; 6.9 3.49; \n",
            "8.1 8.45; 9.3 10.62; 7.1 5.58; \n",
            "9.5 8.09; 10.3 9.7; 7.9 5.47; \n",
            "10.1 9.18; 11.0 11.09; 9.4 6.48; \n",
            "8.2 9.35; 9.7 11.06; 7.8 7.05; \n",
            "8.4 7.42; 9.0 8.61; 7.4 5.19; \n",
            "6.8 7.74; 10.0 8.7; 5.3 5.83; \n",
            "7.0 6.17; 9.2 7.63; 2.6 3.63; \n",
            "6.2 6.88; 8.5 8.36; 2.5 3.97; \n",
            "6.4 6.11; 8.7 7.66; 4.0 3.03; \n",
            "6.0 6.39; 10.7 7.82; 3.9 3.51; \n",
            "6.1 6.06; 7.9 8.08; 3.4 2.71; \n",
            "5.8 6.3; 9.1 7.86; 3.4 3.25; \n",
            "7.4 5.84; 8.2 7.82; 5.1 2.63; \n",
            "6.0 7.32; 8.7 8.85; 5.0 4.66; \n",
            "6.5 5.73; 7.9 7.36; 4.3 2.88; \n",
            "6.3 6.31; 7.2 7.94; 5.7 3.69; \n",
            "7.2 5.71; 9.5 6.73; 5.7 3.66; \n",
            "5.3 6.64; 7.6 8.19; 3.6 4.16; \n",
            "6.7 4.89; 8.5 6.2; 2.4 2.27; \n",
            "4.7 6.56; 9.0 8.42; 1.7 3.61; \n",
            "2.1 4.43; 6.0 6.42; 0.0 1.05; \n",
            "0.6 2.21; 1.6 3.93; -0.8 -1.08; \n",
            "2.5 0.99; 5.7 1.8; -0.6 -1.67; \n",
            "3.3 2.97; 4.8 4.89; 2.0 -0.31; \n",
            "10.1 3.32; 12.2 4.43; 2.8 0.7; \n",
            "9.1 9.94; 10.6 13.03; 6.0 6.26; \n",
            "10.3 8.09; 11.7 10.26; 8.4 5.15; \n",
            "10.5 9.28; 11.0 11.32; 9.2 6.71; \n",
            "10.4 9.05; 11.8 10.57; 9.8 6.71; \n",
            "7.1 8.95; 11.0 10.48; 5.3 6.71; \n",
            "2.8 5.86; 5.3 7.39; 1.6 3.03; \n",
            "5.5 2.32; 6.8 3.15; 2.9 -0.01; \n",
            "6.0 5.63; 7.4 6.97; 4.8 3.02; \n",
            "4.9 5.86; 6.3 6.93; 2.7 3.45; \n",
            "4.0 4.88; 5.9 5.84; 2.9 2.21; \n",
            "4.8 4.0; 5.8 4.99; 2.1 1.6; \n",
            "4.8 5.14; 6.1 6.15; 2.3 2.62; \n",
            "6.2 4.96; 7.0 6.04; 5.4 2.11; \n",
            "5.9 5.93; 8.4 6.86; 2.5 3.74; \n",
            "6.6 5.36; 7.7 6.76; 4.2 2.5; \n",
            "4.8 6.08; 9.2 7.24; 3.7 3.75; \n",
            "2.9 4.28; 5.3 5.94; 2.0 1.35; \n",
            "1.6 2.68; 2.4 3.64; -1.1 0.21; \n",
            "1.1 1.82; 5.0 2.68; -1.3 -0.73; \n",
            "-1.4 1.18; 1.0 2.97; -2.5 -2.04; \n",
            "-0.5 -1.17; 1.5 -0.29; -4.0 -3.84; \n",
            "-0.3 0.24; 0.5 1.96; -2.1 -2.93; \n",
            "2.2 0.34; 3.8 1.24; -0.4 -2.18; \n",
            "1.8 2.57; 3.0 4.0; 0.8 -0.31; \n",
            "1.4 1.64; 2.2 2.53; -0.5 -0.83; \n",
            "2.0 1.41; 3.0 2.54; 1.0 -0.92; \n",
            "1.4 1.68; 2.6 2.44; 0.5 -0.31; \n",
            "3.9 1.04; 8.0 1.64; 0.8 -1.08; \n",
            "4.4 3.33; 7.2 5.51; 0.9 0.36; \n",
            "6.1 3.64; 8.9 5.38; 4.3 1.04; \n",
            "3.8 5.03; 6.2 6.84; 1.0 2.67; \n",
            "2.6 3.01; 3.4 4.32; 1.0 0.39; \n",
            "0.5 2.18; 3.2 3.1; -1.5 -0.12; \n",
            "2.3 0.16; 3.5 1.32; 0.5 -2.53; \n",
            "2.6 2.2; 4.5 3.23; 1.5 -0.1; \n",
            "3.2 2.23; 4.7 3.1; 2.3 0.03; \n",
            "2.1 2.91; 3.9 3.96; -0.2 0.7; \n",
            "-2.0 2.01; 0.2 3.2; -4.2 -0.52; \n",
            "-2.4 -1.84; 0.4 -0.52; -5.0 -5.01; \n",
            "-2.4 -1.68; 1.5 0.05; -5.9 -4.82; \n",
            "-1.0 -1.97; 5.3 0.09; -4.0 -5.6; \n",
            "-2.2 -0.73; 3.4 2.11; -5.6 -4.66; \n",
            "-6.0 -2.1; -1.5 0.85; -9.6 -6.07; \n",
            "-5.9 -5.4; -2.0 -2.46; -10.0 -9.87; \n",
            "-5.0 -4.52; -2.2 -1.1; -7.7 -9.09; \n",
            "-6.8 -3.91; -2.7 -1.1; -9.7 -7.86; \n",
            "-5.9 -6.23; -0.8 -3.26; -9.7 -10.4; \n",
            "-1.9 -4.98; 0.6 -1.23; -3.5 -9.34; \n",
            "-2.2 -1.06; -0.5 1.65; -3.2 -4.1; \n",
            "-0.8 -1.96; 1.5 0.35; -2.5 -5.01; \n",
            "-3.2 -0.61; 0.0 2.16; -5.0 -3.55; \n",
            "-3.4 -3.6; 0.0 -1.1; -6.9 -6.56; \n",
            "-7.8 -3.27; -3.0 -0.27; -11.5 -6.65; \n",
            "-6.1 -8.12; -2.5 -5.13; -10.0 -12.12; \n",
            "-3.9 -5.12; -1.6 -2.12; -7.5 -9.14; \n",
            "0.3 -3.23; 3.8 -0.82; -2.7 -6.6; \n",
            "3.2 0.5; 6.8 3.46; 0.5 -2.9; \n",
            "4.1 2.69; 7.2 5.3; 2.1 -0.21; \n",
            "2.8 3.26; 6.0 5.81; -0.1 0.48; \n",
            "2.3 1.97; 4.0 4.52; -0.1 -1.01; \n",
            "0.9 1.56; 1.9 3.71; -0.5 -1.12; \n",
            "-0.2 -0.02; 2.7 1.31; -3.3 -2.27; \n",
            "-0.6 -0.95; 0.6 1.01; -1.4 -3.9; \n",
            "1.9 -1.09; 7.0 -0.22; -2.3 -3.08; \n",
            "1.3 1.74; 4.2 4.46; -0.7 -1.86; \n",
            "3.3 1.11; 6.5 2.96; 0.4 -1.87; \n",
            "3.9 3.35; 7.0 5.81; 1.4 0.14; \n",
            "4.2 3.47; 5.8 5.71; 3.0 0.41; \n",
            "5.0 3.66; 9.2 5.3; 2.7 1.3; \n",
            "4.5 4.13; 7.5 6.59; 0.9 1.14; \n",
            "3.0 3.81; 6.4 5.91; -0.5 0.97; \n",
            "4.2 2.36; 6.8 4.59; 2.2 -0.84; \n",
            "4.0 3.81; 9.5 5.79; 0.8 1.07; \n",
            "3.2 3.5; 7.0 6.36; 0.5 -0.27; \n",
            "0.7 2.93; 3.5 5.38; -1.5 -0.45; \n",
            "3.0 0.59; 5.0 2.63; 0.9 -2.46; \n",
            "3.7 3.18; 5.6 5.14; 2.0 0.31; \n",
            "3.8 3.65; 5.9 5.38; 0.6 0.81; \n",
            "2.7 3.61; 5.1 5.73; 0.5 0.53; \n",
            "2.4 2.38; 3.4 4.09; 1.4 -0.29; \n",
            "2.1 2.25; 3.2 3.38; 1.4 -0.09; \n",
            "2.0 2.04; 4.2 3.01; 0.1 -0.36; \n",
            "3.7 1.82; 7.4 3.34; 1.1 -0.91; \n",
            "4.3 3.3; 8.6 5.29; 0.2 0.45; \n",
            "6.7 3.9; 11.1 6.37; 3.8 0.61; \n",
            "5.2 6.23; 10.5 9.09; 1.8 2.99; \n",
            "6.1 4.66; 9.6 7.52; 2.9 1.03; \n",
            "6.3 5.6; 12.2 8.3; 2.0 2.31; \n",
            "6.9 5.81; 12.8 9.33; 1.3 1.81; \n",
            "8.1 6.61; 13.3 10.48; 4.3 2.17; \n",
            "9.4 7.66; 17.1 11.41; 2.4 3.72; \n",
            "11.6 9.22; 15.6 14.37; 7.8 3.86; \n",
            "12.7 10.94; 18.3 15.23; 8.0 6.86; \n",
            "13.3 12.05; 20.6 17.08; 8.3 7.32; \n",
            "12.3 12.81; 19.5 18.27; 6.8 7.74; \n",
            "12.1 12.2; 16.6 17.66; 7.9 6.85; \n",
            "12.0 11.72; 15.4 16.4; 8.9 7.04; \n",
            "9.3 11.54; 11.6 15.53; 7.4 7.42; \n",
            "11.6 9.01; 14.9 11.96; 9.6 5.16; \n",
            "12.9 11.37; 18.3 14.91; 8.2 7.77; \n",
            "13.0 12.77; 19.0 17.39; 8.2 8.13; \n",
            "13.5 13.17; 22.9 17.97; 6.2 8.36; \n",
            "10.2 14.18; 18.1 20.27; 7.8 8.0; \n",
            "5.4 10.87; 9.1 16.11; 1.8 5.55; \n",
            "6.3 6.25; 9.8 9.6; 1.9 1.56; \n",
            "4.6 7.12; 9.5 10.81; 1.6 2.5; \n",
            "3.6 5.35; 8.2 8.64; -1.0 0.86; \n",
            "9.4 4.51; 14.4 8.12; 6.4 -0.26; \n",
            "10.9 10.04; 14.9 14.56; 8.0 5.74; \n",
            "10.9 10.8; 16.1 15.13; 5.7 6.49; \n",
            "10.9 10.84; 13.6 15.49; 8.6 5.94; \n",
            "5.6 10.42; 8.6 14.41; 2.0 6.48; \n",
            "4.7 5.29; 8.6 7.97; 1.9 1.39; \n",
            "10.2 4.85; 15.2 7.61; 6.5 1.07; \n",
            "12.5 10.1; 17.4 13.96; 9.8 5.95; \n",
            "11.1 11.33; 17.4 15.2; 6.2 7.75; \n",
            "14.0 10.62; 18.5 15.14; 10.6 6.2; \n",
            "14.8 13.52; 19.8 18.24; 11.0 9.37; \n",
            "14.1 14.27; 20.7 19.18; 8.0 9.99; \n",
            "15.1 14.07; 22.2 19.47; 8.3 8.72; \n",
            "16.5 14.93; 24.6 20.32; 9.3 9.64; \n",
            "18.0 15.87; 26.0 21.74; 11.4 10.37; \n",
            "18.8 17.46; 27.3 23.66; 11.3 11.87; \n",
            "13.4 18.61; 22.3 25.08; 9.5 12.39; \n",
            "10.7 14.12; 18.0 20.18; 5.0 8.15; \n",
            "12.8 12.01; 19.5 17.73; 5.9 5.75; \n",
            "15.2 14.25; 19.4 20.38; 11.6 7.67; \n",
            "14.4 15.66; 22.3 21.14; 5.9 10.33; \n",
            "15.5 15.1; 24.8 21.36; 7.0 8.37; \n",
            "16.8 16.4; 25.3 23.33; 10.0 9.39; \n",
            "16.4 17.46; 22.7 24.45; 11.0 10.65; \n",
            "14.1 16.76; 19.3 23.1; 8.5 10.49; \n",
            "14.8 14.76; 17.3 20.29; 13.3 8.55; \n",
            "14.2 14.5; 17.0 19.0; 11.5 10.02; \n",
            "14.8 13.97; 19.0 18.15; 12.8 9.71; \n",
            "13.6 14.82; 18.6 19.5; 7.4 10.3; \n",
            "12.2 14.17; 15.8 18.78; 7.8 8.97; \n",
            "12.6 12.55; 17.6 16.62; 8.4 7.77; \n",
            "14.5 13.31; 19.3 17.78; 10.8 8.19; \n",
            "15.5 14.82; 20.2 19.55; 11.8 9.84; \n",
            "15.6 15.45; 20.6 20.01; 10.7 10.93; \n",
            "14.8 15.5; 19.7 20.37; 12.6 10.71; \n",
            "14.1 14.9; 18.2 19.39; 12.0 10.73; \n",
            "14.1 14.39; 20.5 18.71; 7.4 10.12; \n",
            "12.6 14.71; 18.0 19.75; 11.0 9.34; \n",
            "13.0 12.94; 18.4 17.33; 10.0 8.57; \n",
            "14.4 13.28; 19.3 17.66; 8.9 8.92; \n",
            "15.3 14.68; 21.0 19.49; 9.9 9.81; \n",
            "17.2 15.7; 21.9 21.01; 12.0 10.5; \n",
            "17.2 16.86; 23.5 22.09; 10.0 12.05; \n",
            "19.4 17.21; 25.9 22.83; 12.8 11.66; \n",
            "18.9 19.0; 23.0 24.87; 15.2 13.39; \n",
            "15.0 18.04; 19.4 23.17; 11.4 13.44; \n",
            "13.5 14.92; 16.6 19.34; 10.0 10.06; \n",
            "12.0 13.94; 15.8 17.82; 9.0 9.39; \n",
            "9.4 12.7; 12.6 16.47; 7.7 8.11; \n",
            "10.8 10.34; 15.2 13.32; 6.5 6.19; \n",
            "10.4 11.97; 15.7 15.85; 5.5 7.13; \n",
            "12.2 11.59; 18.9 15.76; 7.4 6.44; \n",
            "13.8 13.25; 18.4 18.44; 10.0 7.84; \n",
            "12.5 14.35; 17.0 19.31; 9.4 9.4; \n",
            "11.8 12.92; 16.0 17.24; 7.5 8.33; \n",
            "12.9 12.17; 19.3 16.29; 6.9 7.58; \n",
            "14.2 13.39; 19.6 18.5; 9.2 8.12; \n",
            "14.3 14.31; 20.5 19.28; 8.8 9.34; \n",
            "14.5 14.35; 18.7 19.53; 12.2 9.19; \n",
            "14.9 14.09; 19.5 18.53; 12.0 9.88; \n",
            "16.3 14.55; 21.3 19.19; 11.3 10.22; \n",
            "16.3 16.02; 22.5 21.15; 9.0 11.16; \n",
            "17.9 16.45; 23.7 21.93; 10.2 10.88; \n",
            "18.0 17.56; 24.6 23.12; 10.1 11.99; \n",
            "19.7 17.79; 25.6 23.56; 13.4 11.96; \n",
            "17.8 19.02; 25.3 24.76; 14.1 13.42; \n",
            "15.6 17.74; 18.4 23.49; 13.5 12.33; \n",
            "13.0 15.57; 17.0 19.88; 8.9 11.1; \n",
            "17.2 13.79; 24.1 17.98; 9.7 8.83; \n",
            "20.0 17.84; 25.5 23.62; 13.3 11.84; \n",
            "18.3 19.64; 24.8 25.38; 15.5 14.05; \n",
            "17.1 18.02; 22.3 23.71; 14.2 12.85; \n",
            "17.7 17.09; 24.1 22.15; 13.9 12.3; \n",
            "18.0 17.84; 23.6 23.43; 14.4 12.62; \n",
            "18.6 18.18; 23.7 23.66; 15.8 13.09; \n",
            "18.3 18.34; 22.0 23.58; 15.8 13.6; \n",
            "18.7 17.73; 25.5 22.34; 14.7 13.64; \n",
            "19.0 18.36; 24.4 23.87; 16.2 13.62; \n",
            "18.7 18.67; 24.5 24.0; 14.1 14.1; \n",
            "18.9 18.63; 24.1 23.97; 15.4 13.65; \n",
            "19.0 18.65; 23.6 23.78; 15.3 13.97; \n",
            "20.2 18.69; 25.1 23.71; 14.1 14.12; \n",
            "18.0 19.6; 22.8 24.82; 15.7 14.62; \n",
            "18.4 18.04; 23.0 23.0; 12.8 13.5; \n",
            "19.4 18.42; 24.5 23.32; 13.7 13.46; \n",
            "20.3 19.25; 26.3 24.47; 13.0 14.18; \n",
            "21.5 20.11; 28.5 25.64; 13.7 14.44; \n",
            "24.2 20.93; 31.2 26.66; 16.4 15.18; \n",
            "24.2 22.68; 27.8 28.45; 20.0 17.04; \n",
            "21.6 22.26; 27.3 27.58; 15.1 17.42; \n",
            "23.9 20.91; 29.6 26.31; 16.4 15.45; \n",
            "23.1 22.56; 27.8 28.05; 17.7 16.95; \n",
            "23.9 21.95; 29.8 27.3; 16.5 16.69; \n",
            "25.3 22.48; 33.0 27.91; 16.6 16.88; \n",
            "27.3 23.61; 33.2 29.24; 19.1 17.73; \n",
            "26.9 24.46; 33.8 29.88; 18.9 18.94; \n",
            "21.5 24.44; 30.7 29.94; 18.2 18.77; \n",
            "18.3 21.91; 23.4 27.87; 12.8 15.79; \n",
            "21.0 19.51; 26.3 24.74; 13.6 13.58; \n",
            "23.6 21.22; 29.8 26.83; 15.8 15.08; \n",
            "25.5 22.93; 31.2 28.61; 17.9 16.86; \n",
            "26.0 23.68; 33.3 29.24; 18.0 18.03; \n",
            "27.7 24.02; 34.0 29.76; 19.4 18.22; \n",
            "19.3 24.87; 30.5 30.41; 16.6 19.18; \n",
            "17.4 20.63; 21.9 27.02; 12.3 14.09; \n",
            "18.2 18.69; 23.2 24.01; 10.9 12.61; \n",
            "19.1 19.08; 25.4 24.5; 12.8 12.73; \n",
            "18.8 19.77; 23.8 25.51; 13.7 13.64; \n",
            "19.1 19.34; 24.5 24.88; 13.7 13.64; \n",
            "21.7 19.54; 26.3 25.26; 15.5 13.74; \n",
            "21.1 21.22; 26.0 26.91; 16.2 15.64; \n",
            "22.4 20.69; 32.5 26.33; 16.7 15.17; \n",
            "18.9 21.99; 24.0 28.11; 14.0 15.9; \n",
            "21.9 19.08; 28.6 24.48; 15.5 13.46; \n",
            "20.6 21.12; 26.6 26.81; 16.4 15.54; \n",
            "19.7 20.31; 24.6 25.97; 14.7 14.99; \n",
            "18.7 19.6; 23.9 24.88; 14.0 14.27; \n",
            "19.6 18.94; 25.3 24.26; 13.8 13.63; \n",
            "17.8 19.72; 23.4 25.32; 16.0 14.24; \n",
            "19.5 18.33; 24.0 23.53; 14.5 13.3; \n",
            "20.6 19.54; 25.3 24.84; 15.2 14.36; \n",
            "17.4 20.05; 22.0 25.3; 14.6 14.8; \n",
            "19.6 17.77; 24.5 22.73; 15.4 12.95; \n",
            "18.7 19.43; 24.2 24.61; 13.0 14.45; \n",
            "19.0 18.97; 25.7 24.27; 12.0 13.62; \n",
            "22.9 19.26; 31.8 24.82; 14.8 13.51; \n",
            "25.7 22.02; 31.6 28.05; 19.0 16.19; \n",
            "17.5 23.37; 27.6 29.02; 14.8 18.1; \n",
            "14.2 18.44; 16.7 24.61; 12.6 12.51; \n",
            "15.9 15.17; 19.8 19.4; 12.6 10.69; \n",
            "19.6 16.65; 26.8 21.42; 13.8 11.72; \n",
            "20.9 19.9; 27.3 25.76; 13.6 14.24; \n",
            "20.6 20.58; 27.0 26.37; 15.5 14.89; \n",
            "20.2 19.89; 25.5 25.71; 14.8 14.59; \n",
            "23.0 19.79; 29.9 25.48; 16.2 14.48; \n",
            "25.1 22.01; 32.0 27.96; 17.0 16.2; \n",
            "26.0 23.27; 33.9 28.98; 17.9 17.58; \n",
            "26.1 23.5; 34.0 29.2; 20.0 17.81; \n",
            "28.3 23.64; 35.5 29.36; 20.8 18.37; \n",
            "29.0 24.91; 36.6 30.42; 22.0 19.59; \n",
            "28.7 25.36; 36.7 30.77; 22.0 20.01; \n",
            "27.4 25.38; 33.3 30.77; 21.4 19.94; \n",
            "19.5 24.63; 31.4 29.93; 15.9 19.34; \n",
            "18.2 20.89; 24.6 27.24; 11.8 14.35; \n",
            "19.7 19.87; 25.9 25.59; 13.7 13.35; \n",
            "15.5 20.71; 21.5 26.55; 13.5 14.29; \n",
            "16.0 17.42; 21.6 22.92; 11.7 11.45; \n",
            "16.0 17.72; 20.9 23.21; 12.6 11.84; \n",
            "19.1 17.57; 26.5 23.19; 11.7 11.86; \n",
            "16.7 19.98; 23.4 26.28; 15.0 13.6; \n",
            "18.7 17.77; 24.1 23.72; 13.4 12.14; \n",
            "20.1 18.93; 27.7 24.53; 13.6 13.39; \n",
            "18.5 19.77; 24.2 25.86; 15.5 13.9; \n",
            "17.3 18.52; 22.4 24.17; 12.3 13.46; \n",
            "19.2 17.42; 24.7 22.61; 14.3 12.14; \n",
            "20.5 18.92; 27.9 24.4; 14.0 13.85; \n",
            "21.9 20.13; 30.0 26.04; 14.7 14.46; \n",
            "23.1 21.1; 30.8 27.17; 16.3 15.42; \n",
            "22.3 21.96; 27.7 27.97; 18.4 16.17; \n",
            "21.4 21.15; 28.3 26.82; 15.5 16.04; \n",
            "20.3 20.91; 26.5 26.7; 14.1 15.3; \n",
            "20.6 20.31; 28.7 26.09; 14.7 14.39; \n",
            "21.1 20.64; 29.1 26.6; 14.3 14.73; \n",
            "20.9 21.03; 28.9 27.1; 13.6 14.96; \n",
            "22.1 21.02; 30.1 27.15; 14.0 14.71; \n",
            "23.3 21.78; 30.5 27.99; 16.5 15.36; \n",
            "23.1 22.46; 28.4 28.54; 18.4 16.41; \n",
            "21.3 22.18; 27.4 27.94; 16.5 16.56; \n",
            "16.1 21.05; 20.9 26.81; 13.7 15.38; \n",
            "16.7 17.03; 21.5 22.07; 13.4 11.71; \n",
            "15.6 17.56; 20.6 22.65; 12.1 12.25; \n",
            "15.8 16.73; 21.0 21.78; 12.7 11.27; \n",
            "15.6 16.75; 23.8 21.72; 8.7 11.51; \n",
            "19.2 16.91; 26.0 22.81; 13.1 10.63; \n",
            "20.1 19.49; 29.4 25.58; 13.6 13.71; \n",
            "21.5 20.41; 25.3 26.92; 18.0 14.18; \n",
            "18.9 20.56; 26.7 26.13; 11.9 15.69; \n",
            "19.0 19.07; 30.0 24.99; 11.4 13.07; \n",
            "20.3 19.64; 31.3 26.36; 13.0 13.03; \n",
            "21.9 20.8; 31.6 27.51; 13.3 14.17; \n",
            "21.6 21.54; 27.3 28.14; 16.5 14.82; \n",
            "17.4 20.77; 25.5 26.75; 11.7 15.17; \n",
            "15.7 18.03; 25.6 24.43; 9.5 11.51; \n",
            "15.2 17.45; 23.6 24.29; 9.3 10.45; \n",
            "14.8 17.17; 23.9 24.01; 7.7 9.96; \n",
            "15.4 16.61; 25.2 23.36; 8.2 9.37; \n",
            "17.1 16.98; 26.0 23.99; 9.8 9.6; \n",
            "18.3 18.14; 24.7 25.27; 13.6 10.85; \n",
            "18.8 18.61; 26.0 25.26; 14.3 12.39; \n",
            "18.6 19.03; 27.1 25.65; 12.1 12.81; \n",
            "19.6 18.98; 27.3 25.62; 13.3 12.53; \n",
            "17.8 19.46; 23.3 25.99; 14.0 13.23; \n",
            "15.5 17.65; 20.5 23.58; 11.3 12.02; \n",
            "14.6 15.78; 17.9 21.01; 12.7 10.33; \n",
            "15.6 14.87; 19.1 19.39; 12.3 10.17; \n",
            "16.3 15.7; 21.8 20.32; 11.1 10.99; \n",
            "15.6 16.6; 22.4 21.81; 9.0 11.31; \n",
            "16.2 16.48; 21.0 22.05; 12.8 10.59; \n",
            "17.1 16.49; 21.0 21.6; 12.9 11.5; \n",
            "16.2 17.1; 20.6 22.05; 12.9 12.17; \n",
            "15.3 16.38; 21.6 21.16; 10.1 11.47; \n",
            "13.5 15.88; 20.4 20.92; 8.2 10.64; \n",
            "14.0 14.42; 21.6 19.61; 8.1 8.91; \n",
            "14.6 15.26; 18.2 20.87; 12.0 9.41; \n",
            "12.9 15.09; 16.6 19.77; 10.3 10.38; \n",
            "12.5 13.3; 18.4 17.33; 8.6 8.86; \n",
            "12.3 13.26; 21.4 18.08; 6.5 8.16; \n",
            "11.8 13.8; 18.4 19.8; 6.0 7.73; \n",
            "15.7 13.11; 18.4 18.64; 13.1 7.24; \n",
            "19.3 15.61; 23.1 20.39; 17.1 11.26; \n",
            "16.4 17.93; 19.1 23.04; 12.2 13.77; \n",
            "11.5 15.59; 18.0 19.92; 8.0 11.41; \n",
            "11.7 11.9; 18.0 16.53; 7.6 7.02; \n",
            "11.7 12.55; 14.3 17.24; 9.0 7.69; \n",
            "10.8 12.2; 15.1 15.65; 6.8 8.01; \n",
            "9.7 11.29; 16.0 15.01; 4.4 6.56; \n",
            "9.6 10.29; 16.0 14.51; 4.3 5.21; \n",
            "11.0 10.64; 18.0 15.36; 6.1 5.36; \n",
            "11.7 12.47; 18.9 18.06; 7.0 6.73; \n",
            "9.7 12.87; 12.5 18.37; 6.8 7.15; \n",
            "9.2 10.11; 10.8 13.68; 7.6 5.73; \n",
            "11.2 9.26; 15.0 12.32; 9.0 5.7; \n",
            "10.5 11.24; 15.9 15.12; 6.6 7.27; \n",
            "11.1 10.8; 14.8 14.98; 8.2 6.28; \n",
            "6.8 10.93; 10.0 14.7; 3.7 7.08; \n",
            "6.6 6.82; 8.1 9.49; 5.0 3.05; \n",
            "4.9 7.02; 6.1 9.11; 4.4 3.68; \n",
            "9.0 5.27; 11.0 6.84; 4.8 2.19; \n",
            "9.1 9.07; 11.2 11.65; 7.8 5.6; \n",
            "7.4 8.64; 8.3 10.56; 6.0 5.97; \n",
            "7.4 7.18; 9.6 8.46; 5.4 4.65; \n",
            "10.9 7.42; 13.1 9.13; 8.4 4.51; \n",
            "10.3 10.57; 11.4 13.26; 9.5 7.41; \n",
            "11.5 9.3; 12.4 10.85; 10.8 6.95; \n",
            "11.1 10.22; 12.0 11.78; 10.1 8.29; \n",
            "10.5 9.84; 13.5 11.05; 7.9 7.92; \n",
            "7.5 9.78; 9.5 11.81; 5.5 7.12; \n",
            "4.7 7.18; 7.2 8.5; 3.4 4.5; \n",
            "5.5 4.66; 6.8 5.62; 4.7 2.17; \n",
            "5.6 5.65; 7.6 6.29; 4.0 3.43; \n",
            "5.2 5.7; 8.0 6.81; 3.5 3.06; \n",
            "2.0 5.33; 4.1 6.71; 0.4 2.56; \n",
            "-0.2 2.39; 3.9 3.27; -2.7 -0.26; \n",
            "0.5 0.67; 3.5 2.42; -1.9 -2.88; \n",
            "-1.3 1.55; 2.0 3.34; -3.6 -1.85; \n",
            "-0.6 -0.81; 1.7 1.05; -3.5 -4.31; \n",
            "4.2 0.08; 6.0 1.83; 1.2 -3.03; \n",
            "5.8 4.42; 6.8 6.37; 4.5 1.63; \n",
            "10.3 5.21; 14.6 6.66; 6.7 2.92; \n",
            "9.7 9.36; 14.5 12.79; 6.5 6.13; \n",
            "7.2 8.34; 8.5 11.62; 5.5 5.07; \n",
            "6.6 5.87; 8.3 7.55; 5.5 3.58; \n",
            "8.8 5.35; 10.6 6.97; 5.0 3.07; \n",
            "8.9 7.74; 13.0 9.62; 5.3 4.88; \n",
            "7.8 7.63; 9.9 10.1; 6.0 4.42; \n",
            "9.8 6.73; 15.4 8.44; 5.0 4.37; \n",
            "10.5 9.41; 13.5 12.73; 6.3 5.58; \n",
            "7.9 10.35; 12.8 13.48; 3.5 6.57; \n",
            "2.2 8.0; 3.6 11.35; 0.8 3.5; \n",
            "1.5 2.19; 2.5 3.41; 0.2 -0.83; \n",
            "-1.0 2.21; 2.0 3.25; -3.7 -0.53; \n",
            "-1.2 -0.19; 0.9 1.34; -3.8 -4.05; \n",
            "0.5 -0.06; 0.9 1.63; -0.4 -3.51; \n",
            "6.3 1.27; 10.5 2.31; 0.4 -1.26; \n",
            "5.3 6.93; 8.5 10.1; 2.3 2.82; \n",
            "-2.5 5.16; 2.3 7.73; -3.0 1.39; \n",
            "-5.1 -2.74; -2.0 -0.6; -8.3 -6.59; \n",
            "-8.2 -4.34; -2.2 -1.93; -10.9 -8.09; \n",
            "-4.5 -7.68; -0.7 -4.68; -9.3 -12.57; \n",
            "-2.7 -3.19; -0.5 0.05; -6.5 -7.48; \n",
            "-4.2 -2.24; -0.3 0.18; -7.3 -5.37; \n",
            "-1.3 -3.65; 1.5 -0.98; -3.7 -7.61; \n",
            "2.0 -0.08; 3.5 2.54; 0.1 -3.73; \n",
            "-1.1 2.17; 1.6 4.72; -4.5 -0.81; \n",
            "-2.2 -1.42; 1.5 1.07; -3.9 -4.94; \n",
            "-7.3 -2.42; -3.9 0.1; -9.9 -5.46; \n",
            "-7.2 -7.55; -4.4 -5.61; -10.8 -11.31; \n",
            "-6.9 -6.35; -5.1 -3.54; -8.6 -10.35; \n",
            "-5.2 -6.32; -2.6 -4.67; -7.8 -9.36; \n",
            "-0.5 -4.36; 1.9 -2.39; -3.1 -7.92; \n",
            "1.2 0.09; 2.8 2.42; 0.7 -2.68; \n",
            "0.6 0.98; 1.8 2.71; -0.2 -1.27; \n",
            "0.6 0.22; 1.7 1.52; -0.5 -1.83; \n",
            "3.1 0.09; 5.9 1.58; 0.7 -1.95; \n",
            "2.7 2.14; 3.9 4.23; 1.2 -0.19; \n",
            "0.2 1.22; 1.9 2.35; -1.2 -0.43; \n",
            "-3.4 -1.07; -1.2 -0.19; -5.0 -2.87; \n",
            "-4.9 -3.96; -3.0 -3.35; -7.2 -6.31; \n",
            "-4.3 -4.6; -2.7 -3.54; -5.7 -7.53; \n",
            "0.1 -3.84; 3.2 -2.81; -4.7 -6.49; \n",
            "-2.0 0.76; 2.3 2.81; -3.6 -2.47; \n",
            "-4.1 -2.29; -1.9 -0.64; -5.5 -5.42; \n",
            "-3.2 -3.46; -1.4 -1.93; -4.1 -6.51; \n",
            "-0.4 -2.53; 1.7 -0.9; -3.1 -5.31; \n",
            "1.6 0.08; 1.9 1.97; 1.0 -2.8; \n",
            "1.6 1.01; 3.2 2.07; 0.3 -0.68; \n",
            "4.0 0.65; 6.5 1.8; 1.9 -0.98; \n",
            "1.6 3.03; 5.0 4.69; -0.7 0.96; \n",
            "-1.3 0.69; 2.5 2.39; -3.6 -1.92; \n",
            "-0.9 -1.93; 1.2 0.24; -3.1 -5.05; \n",
            "-0.5 -1.06; 0.5 0.52; -1.0 -3.43; \n",
            "-0.2 -0.88; 0.5 -0.14; -0.8 -2.92; \n",
            "2.8 -0.46; 9.9 0.1; -1.8 -2.25; \n",
            "7.9 2.46; 12.1 5.79; 3.2 -1.35; \n",
            "1.4 7.34; 6.8 10.65; 0.5 4.15; \n",
            "4.3 0.26; 6.3 2.75; 0.4 -3.0; \n",
            "4.0 4.34; 6.4 6.9; 1.4 1.33; \n",
            "4.4 3.19; 7.1 5.19; 2.6 0.2; \n",
            "6.2 3.45; 8.3 5.61; 4.2 0.7; \n",
            "5.5 5.07; 7.1 6.93; 3.1 2.86; \n",
            "3.4 4.53; 5.2 5.89; 2.4 2.22; \n",
            "-2.4 2.99; 2.5 4.21; -3.6 0.55; \n",
            "-1.5 -2.61; 3.0 -0.34; -5.4 -6.31; \n",
            "-0.6 -0.63; 2.1 2.23; -2.4 -4.65; \n",
            "-2.1 -0.22; 0.4 1.86; -3.3 -3.16; \n",
            "-2.5 -1.88; -0.2 -0.36; -4.3 -4.83; \n",
            "0.9 -1.88; 4.6 -0.27; -2.5 -4.89; \n",
            "0.4 1.55; 3.3 4.31; -2.2 -1.92; \n",
            "0.0 0.48; 1.7 2.69; -2.1 -2.65; \n",
            "3.8 0.07; 5.4 1.88; 1.0 -2.6; \n",
            "2.9 3.54; 6.2 5.42; 0.5 0.99; \n",
            "0.2 2.03; 3.0 4.09; -1.3 -0.89; \n",
            "1.7 -0.53; 5.2 1.29; -0.1 -3.26; \n",
            "1.8 1.26; 3.5 3.34; 0.2 -1.34; \n",
            "1.4 1.3; 3.6 2.57; -0.6 -1.01; \n",
            "2.2 1.05; 4.4 2.7; -0.6 -1.64; \n",
            "6.4 1.85; 9.4 3.68; 3.2 -0.79; \n",
            "2.4 5.73; 4.7 8.05; 0.8 3.03; \n",
            "-0.3 1.54; 2.4 2.81; -1.4 -1.02; \n",
            "-2.1 -0.47; 0.9 1.02; -4.4 -3.17; \n",
            "3.9 -1.97; 6.5 -0.37; -0.2 -5.04; \n",
            "2.0 4.19; 3.7 6.63; 0.4 0.95; \n",
            "2.4 1.3; 5.3 2.54; 0.3 -1.16; \n",
            "5.2 2.12; 6.8 3.88; 4.1 -0.57; \n",
            "4.1 4.66; 6.5 6.09; 1.6 2.6; \n",
            "1.3 3.6; 3.2 5.46; -0.3 0.66; \n",
            "-1.8 0.81; 1.8 2.18; -4.0 -1.72; \n",
            "-2.5 -2.05; -0.6 -0.34; -4.3 -5.06; \n",
            "-4.0 -2.17; -2.0 -0.94; -6.2 -4.88; \n",
            "-1.5 -3.56; 1.7 -2.09; -5.1 -6.58; \n",
            "1.4 -0.84; 4.8 1.3; -0.8 -4.29; \n",
            "0.6 1.56; 3.4 3.53; -0.2 -1.34; \n",
            "2.4 0.42; 4.6 2.22; 0.9 -2.36; \n",
            "2.3 2.42; 4.2 4.28; 0.9 -0.09; \n",
            "3.0 1.74; 6.3 3.35; -0.8 -0.64; \n",
            "7.8 2.47; 11.6 4.87; 3.3 -0.59; \n",
            "13.2 6.75; 16.4 9.86; 10.5 3.68; \n",
            "6.5 10.93; 14.0 14.25; 3.5 8.36; \n",
            "0.2 4.49; 3.5 7.66; -1.1 0.92; \n",
            "1.1 -0.54; 5.6 1.43; -1.8 -3.44; \n",
            "0.3 1.13; 5.4 3.99; -4.0 -2.41; \n",
            "3.0 0.38; 6.0 3.42; -0.2 -3.93; \n",
            "3.7 3.14; 6.0 5.82; 1.6 -0.18; \n",
            "3.5 3.27; 5.1 5.37; 2.7 0.58; \n",
            "2.3 3.43; 6.2 5.16; -0.1 0.95; \n",
            "-1.7 2.59; -0.1 5.33; -2.7 -1.32; \n",
            "-3.0 -1.47; -1.5 0.33; -4.3 -4.54; \n",
            "-2.8 -2.63; -0.9 -0.87; -4.8 -5.19; \n",
            "-3.4 -2.28; -1.3 -0.78; -5.7 -5.23; \n",
            "-1.6 -2.85; 1.6 -1.28; -4.8 -5.91; \n",
            "-1.8 -1.12; 2.2 1.28; -6.0 -4.41; \n",
            "-0.4 -1.29; 2.5 1.16; -2.0 -5.04; \n",
            "-1.2 0.02; 1.4 2.04; -4.0 -3.1; \n",
            "0.0 -0.9; 1.3 1.07; -1.5 -4.19; \n",
            "0.9 0.03; 1.4 1.67; 0.5 -2.5; \n",
            "1.1 0.47; 4.5 1.28; -2.0 -1.27; \n",
            "1.9 0.54; 5.4 2.52; -0.5 -2.37; \n",
            "2.1 1.33; 5.4 3.37; -0.2 -1.25; \n",
            "2.9 1.45; 8.2 3.56; -1.3 -1.32; \n",
            "4.2 2.39; 9.4 5.35; -0.3 -1.21; \n",
            "6.1 3.68; 10.7 7.01; 1.2 -0.2; \n",
            "10.0 5.41; 16.7 8.73; 4.7 1.65; \n",
            "12.3 9.09; 16.6 13.67; 8.8 4.87; \n",
            "9.9 10.99; 12.7 15.19; 6.7 7.37; \n",
            "7.9 8.51; 13.8 11.51; 2.4 5.26; \n",
            "8.3 7.22; 14.0 11.2; 2.6 2.7; \n",
            "10.9 8.14; 16.7 12.31; 4.6 3.28; \n",
            "11.8 10.66; 15.0 15.33; 8.8 5.53; \n",
            "7.4 10.9; 10.7 14.68; 5.4 6.97; \n",
            "7.3 6.85; 10.1 9.42; 6.0 3.19; \n",
            "10.1 7.39; 16.1 10.1; 5.3 3.92; \n",
            "10.3 10.62; 16.7 15.31; 4.3 5.67; \n",
            "8.8 10.79; 11.6 15.61; 6.8 5.42; \n",
            "9.8 8.69; 14.0 11.73; 7.3 5.13; \n",
            "11.9 9.52; 17.3 13.03; 7.8 5.66; \n",
            "12.6 11.8; 18.4 16.29; 7.3 7.36; \n",
            "8.5 12.62; 14.4 17.66; 5.0 7.64; \n",
            "11.8 8.42; 15.7 12.33; 7.8 4.02; \n",
            "15.1 11.74; 20.8 15.71; 8.9 7.7; \n",
            "15.4 14.84; 19.4 20.14; 9.7 9.77; \n",
            "16.7 14.76; 20.6 19.6; 13.5 10.01; \n",
            "17.6 15.53; 24.5 20.15; 11.4 11.41; \n",
            "18.9 16.87; 25.4 22.41; 12.0 11.86; \n",
            "18.5 18.28; 25.6 24.04; 9.4 12.85; \n",
            "18.7 18.2; 26.1 24.16; 10.6 12.01; \n",
            "18.8 18.25; 27.1 24.11; 12.2 12.17; \n",
            "20.4 18.72; 27.0 24.86; 13.3 12.58; \n",
            "21.5 19.92; 27.2 25.96; 14.1 13.97; \n",
            "20.9 20.58; 27.7 26.42; 14.3 14.78; \n",
            "17.8 20.42; 24.0 26.46; 14.0 14.44; \n",
            "9.9 18.29; 14.0 24.02; 7.9 12.62; \n",
            "9.0 11.44; 13.9 15.56; 5.1 6.03; \n",
            "7.9 10.96; 14.6 15.24; 3.6 5.39; \n",
            "8.1 10.01; 12.2 14.76; 4.6 3.83; \n",
            "6.4 9.83; 11.1 13.96; 2.9 4.51; \n",
            "8.5 8.04; 13.0 12.05; 3.7 2.81; \n",
            "12.8 10.11; 18.3 14.51; 7.3 4.76; \n",
            "14.0 13.7; 18.1 19.25; 10.6 8.12; \n",
            "14.6 14.01; 19.7 19.2; 9.6 9.18; \n",
            "12.8 14.22; 18.9 19.06; 6.8 9.37; \n",
            "19.4 12.69; 27.6 17.62; 11.8 7.52; \n",
            "21.7 18.46; 27.1 24.68; 17.3 12.82; \n",
            "19.8 19.6; 24.3 25.39; 16.4 14.85; \n",
            "13.7 17.92; 20.9 22.92; 10.4 13.61; \n",
            "12.1 13.43; 14.9 18.24; 8.9 8.65; \n",
            "13.9 12.43; 20.7 16.24; 7.9 8.25; \n",
            "15.4 14.82; 21.6 20.14; 9.6 8.99; \n",
            "11.7 16.07; 14.8 21.49; 9.2 10.48; \n",
            "11.3 12.03; 15.0 15.53; 7.8 7.76; \n",
            "15.6 11.97; 22.0 15.95; 8.3 7.5; \n",
            "17.1 16.51; 21.7 22.32; 13.1 10.5; \n",
            "18.4 17.32; 26.3 22.8; 11.9 12.11; \n",
            "14.4 18.2; 22.8 24.11; 11.1 12.53; \n",
            "10.2 14.81; 13.4 20.44; 8.2 9.35; \n",
            "14.8 10.91; 21.0 14.49; 7.9 6.64; \n",
            "18.4 15.36; 24.6 20.94; 13.3 9.58; \n",
            "18.7 18.2; 24.3 23.93; 12.7 12.89; \n",
            "15.5 17.96; 20.8 23.47; 12.3 12.85; \n",
            "15.8 15.27; 21.0 20.38; 12.4 10.72; \n",
            "15.4 16.03; 20.7 21.22; 11.9 11.08; \n",
            "18.3 15.88; 24.5 21.04; 13.3 10.76; \n",
            "19.3 18.16; 24.3 23.76; 15.5 12.84; \n",
            "16.2 18.33; 20.7 23.49; 13.0 13.64; \n",
            "18.1 15.86; 23.7 20.49; 11.1 11.64; \n",
            "19.7 18.09; 23.2 23.58; 17.3 12.64; \n",
            "11.4 19.02; 18.9 24.17; 7.2 14.58; \n",
            "11.3 12.53; 13.4 17.08; 8.9 6.93; \n",
            "11.8 12.17; 15.4 15.42; 8.4 8.2; \n",
            "12.3 12.73; 16.8 16.44; 8.3 8.21; \n",
            "11.7 13.17; 13.9 17.35; 9.7 8.35; \n",
            "11.4 12.5; 14.3 15.86; 8.8 8.46; \n",
            "12.2 11.85; 16.4 15.16; 8.4 7.83; \n",
            "14.3 12.83; 18.3 16.67; 9.5 8.61; \n",
            "16.8 14.7; 22.3 19.39; 9.9 9.79; \n",
            "17.6 16.52; 24.0 21.52; 14.5 11.49; \n",
            "15.5 16.83; 18.3 22.09; 12.5 12.27; \n",
            "15.9 14.93; 20.8 18.82; 10.4 11.06; \n",
            "18.2 15.6; 25.0 20.25; 11.0 10.91; \n",
            "22.8 18.0; 29.2 23.55; 16.1 12.55; \n",
            "25.0 21.09; 31.8 26.78; 18.1 16.0; \n",
            "22.0 22.34; 29.0 28.09; 18.7 17.32; \n",
            "20.2 20.54; 24.1 26.29; 18.3 15.67; \n",
            "23.5 19.2; 28.3 24.13; 18.3 14.95; \n",
            "24.6 21.8; 29.3 27.19; 19.0 16.91; \n",
            "22.3 22.57; 26.7 27.81; 19.0 17.67; \n",
            "24.3 20.9; 29.0 25.87; 18.5 16.41; \n",
            "25.9 22.17; 30.7 27.29; 20.4 17.52; \n",
            "27.1 23.41; 33.6 28.67; 20.5 18.62; \n",
            "25.1 24.39; 30.1 29.65; 23.7 19.33; \n",
            "20.3 23.13; 23.8 28.18; 19.0 18.7; \n",
            "17.9 20.03; 23.1 24.37; 15.2 15.74; \n",
            "15.6 18.77; 18.8 23.42; 12.7 14.02; \n",
            "16.8 17.1; 20.2 21.22; 13.0 12.38; \n",
            "15.0 17.77; 18.6 22.04; 12.4 13.0; \n",
            "16.7 16.25; 21.9 20.28; 11.3 11.78; \n",
            "16.4 17.73; 21.2 22.65; 12.2 12.53; \n",
            "15.4 17.37; 17.7 22.34; 13.4 12.33; \n",
            "14.0 16.11; 16.5 20.22; 12.4 11.69; \n",
            "13.6 14.69; 15.6 18.08; 11.1 10.64; \n",
            "15.2 14.18; 21.5 17.39; 8.9 10.34; \n",
            "15.9 15.84; 21.7 20.6; 12.6 10.67; \n",
            "16.8 16.22; 21.3 21.15; 11.6 11.65; \n",
            "18.8 16.76; 23.5 21.44; 12.4 12.06; \n",
            "21.1 18.26; 28.0 23.39; 14.0 13.34; \n",
            "24.0 20.25; 30.1 26.02; 17.1 14.87; \n",
            "23.3 22.02; 28.4 27.68; 18.6 16.9; \n",
            "20.4 21.47; 25.2 26.89; 15.9 16.72; \n",
            "18.4 19.48; 24.0 24.57; 14.3 14.65; \n",
            "18.4 18.28; 23.3 23.32; 16.3 13.36; \n",
            "20.1 18.4; 26.0 23.39; 14.4 13.58; \n",
            "19.6 19.85; 24.7 25.15; 17.3 14.56; \n",
            "20.0 19.3; 25.1 24.45; 16.7 14.66; \n",
            "19.1 19.63; 23.0 24.83; 16.0 14.96; \n",
            "22.5 19.01; 27.9 24.03; 16.9 14.37; \n",
            "23.6 21.65; 29.0 27.09; 17.4 16.57; \n",
            "25.0 22.15; 30.3 27.57; 19.0 17.13; \n",
            "23.0 22.77; 28.8 28.04; 19.5 17.99; \n",
            "22.7 21.63; 27.9 26.96; 17.8 16.87; \n",
            "22.7 21.53; 28.3 26.69; 16.3 16.75; \n",
            "25.2 21.81; 32.6 27.1; 17.3 16.49; \n",
            "27.2 23.53; 33.7 29.05; 21.0 18.01; \n",
            "24.3 24.42; 30.1 29.75; 21.0 19.35; \n",
            "19.7 22.82; 23.6 28.21; 17.0 17.93; \n",
            "19.5 19.86; 23.6 24.68; 14.3 14.98; \n",
            "20.3 19.96; 26.4 24.96; 14.3 14.66; \n",
            "22.2 20.84; 28.1 26.29; 15.0 15.06; \n",
            "25.0 21.91; 31.5 27.38; 18.9 16.19; \n",
            "25.5 23.26; 31.0 28.81; 18.1 17.95; \n",
            "27.4 23.45; 32.4 28.95; 22.1 18.16; \n",
            "26.8 24.44; 32.6 29.76; 21.1 19.46; \n",
            "25.8 24.36; 32.0 29.66; 19.8 19.2; \n",
            "27.5 23.82; 34.0 29.08; 20.7 18.53; \n",
            "23.3 24.68; 31.3 29.9; 18.0 19.52; \n",
            "23.9 22.57; 29.6 28.18; 18.2 16.95; \n",
            "24.4 22.86; 29.2 28.11; 20.5 17.45; \n",
            "25.3 23.15; 30.8 28.45; 20.2 18.0; \n",
            "24.9 23.66; 32.4 28.9; 18.0 18.57; \n",
            "26.3 23.83; 33.9 29.37; 19.5 18.17; \n",
            "27.8 24.57; 34.3 30.09; 21.1 19.02; \n",
            "28.1 25.09; 34.1 30.42; 21.7 19.79; \n",
            "24.2 25.19; 31.2 30.44; 20.3 19.94; \n",
            "23.5 23.24; 27.7 28.68; 20.0 17.82; \n",
            "21.4 22.49; 26.1 27.58; 18.1 17.54; \n",
            "19.0 21.38; 23.8 26.5; 14.3 16.27; \n",
            "18.4 19.95; 22.6 24.97; 14.6 14.48; \n",
            "19.2 19.3; 25.0 24.14; 14.0 14.09; \n",
            "19.9 19.93; 25.0 25.28; 15.9 14.33; \n",
            "20.0 20.32; 25.2 25.66; 14.5 15.0; \n",
            "21.8 20.34; 28.9 25.73; 15.9 14.84; \n",
            "23.9 21.52; 29.2 27.25; 18.4 15.94; \n",
            "19.3 22.61; 23.9 28.12; 16.0 17.46; \n",
            "22.0 19.41; 29.4 24.55; 15.2 14.36; \n",
            "21.7 21.46; 25.6 27.06; 20.0 15.93; \n",
            "22.1 20.79; 29.8 25.97; 15.3 16.31; \n",
            "20.7 21.42; 24.9 27.04; 16.6 15.93; \n",
            "18.7 20.29; 25.7 25.49; 12.1 15.32; \n",
            "17.3 19.27; 21.6 24.81; 14.2 13.47; \n",
            "17.5 17.98; 24.2 22.97; 9.7 12.9; \n",
            "19.5 18.73; 27.4 24.42; 12.2 12.42; \n",
            "21.6 20.06; 30.2 26.02; 13.9 13.77; \n",
            "22.4 21.46; 29.2 27.67; 18.8 15.41; \n",
            "22.3 21.62; 28.5 27.63; 16.7 16.07; \n",
            "21.9 21.63; 28.5 27.45; 18.3 16.17; \n",
            "16.4 21.25; 20.1 27.16; 15.0 15.76; \n",
            "14.9 16.97; 19.8 21.72; 12.5 12.35; \n",
            "14.9 15.7; 23.1 20.45; 8.2 10.72; \n",
            "17.9 16.46; 27.3 22.12; 9.8 10.37; \n",
            "23.4 18.8; 30.8 25.26; 17.9 12.15; \n",
            "22.1 22.02; 27.2 28.17; 19.5 16.6; \n",
            "15.0 20.91; 20.4 26.72; 11.0 15.95; \n",
            "14.7 15.96; 23.1 20.98; 8.5 10.53; \n",
            "16.8 16.35; 25.5 22.65; 9.5 9.89; \n",
            "17.1 18.16; 22.4 24.59; 13.0 11.51; \n",
            "13.0 17.57; 15.8 23.12; 11.7 12.06; \n",
            "11.4 13.29; 14.8 17.13; 9.1 9.04; \n",
            "12.2 12.07; 18.5 15.83; 6.6 7.76; \n",
            "12.5 13.75; 18.0 19.18; 8.6 7.81; \n",
            "12.6 13.96; 16.6 19.37; 10.4 8.31; \n",
            "12.2 13.19; 16.3 17.34; 9.4 8.74; \n",
            "11.1 12.52; 16.1 16.49; 8.0 8.18; \n",
            "12.6 11.72; 18.7 15.98; 8.3 7.02; \n",
            "14.1 13.25; 20.2 18.38; 10.2 8.13; \n",
            "13.3 14.46; 18.3 19.58; 8.2 9.63; \n",
            "15.2 13.55; 19.2 18.16; 12.6 8.77; \n",
            "14.1 14.75; 20.2 19.3; 9.3 10.72; \n",
            "15.4 14.1; 20.2 19.1; 12.6 9.19; \n",
            "16.7 15.19; 23.8 20.04; 11.6 10.81; \n",
            "16.3 16.62; 23.6 22.18; 11.4 11.56; \n",
            "16.2 16.18; 24.9 21.77; 10.6 11.05; \n",
            "16.3 16.55; 24.6 22.57; 10.4 10.9; \n",
            "16.8 16.74; 23.8 23.03; 11.8 10.78; \n",
            "15.8 17.05; 19.8 22.94; 13.0 11.57; \n",
            "16.7 15.85; 21.7 21.01; 14.3 11.05; \n",
            "16.7 16.54; 23.0 21.66; 13.3 12.09; \n",
            "14.5 16.8; 22.9 22.35; 8.9 11.84; \n",
            "13.6 15.5; 21.1 21.48; 8.0 9.65; \n",
            "12.6 14.72; 20.0 20.55; 7.5 8.75; \n",
            "12.3 13.84; 19.9 19.59; 6.7 7.81; \n",
            "12.7 13.62; 20.2 19.44; 6.9 7.34; \n",
            "11.9 13.94; 15.0 19.99; 10.0 7.7; \n",
            "10.0 12.43; 13.9 16.87; 7.2 7.93; \n",
            "9.9 10.83; 13.8 14.93; 7.3 6.25; \n",
            "8.2 10.87; 14.2 15.03; 4.0 6.22; \n",
            "8.9 9.34; 16.4 13.87; 3.3 4.02; \n",
            "9.8 9.92; 15.4 15.24; 4.4 4.11; \n",
            "11.3 10.62; 15.7 15.49; 7.1 5.22; \n",
            "10.4 11.52; 13.4 16.1; 8.6 6.6; \n",
            "7.1 10.34; 13.4 13.99; 2.0 6.37; \n",
            "8.1 7.61; 16.5 11.91; 1.7 2.26; \n",
            "8.1 9.2; 14.7 14.55; 3.2 3.32; \n",
            "8.0 8.89; 14.4 13.89; 3.4 3.41; \n",
            "7.4 8.53; 14.5 13.21; 2.3 3.19; \n",
            "7.0 8.04; 14.4 13.06; 2.4 2.39; \n",
            "6.9 7.59; 11.6 12.94; 2.0 1.89; \n",
            "8.3 7.54; 12.2 12.21; 5.1 2.45; \n",
            "8.7 8.64; 12.3 13.0; 6.5 4.05; \n",
            "9.3 8.66; 11.5 12.31; 7.8 4.66; \n",
            "12.5 8.8; 14.3 12.1; 11.4 5.39; \n",
            "8.0 11.41; 11.4 14.88; 5.3 8.38; \n",
            "9.7 7.38; 13.6 10.18; 7.1 3.8; \n",
            "7.5 9.39; 10.1 12.67; 5.3 5.87; \n",
            "11.4 7.13; 13.0 9.55; 10.1 3.82; \n",
            "10.0 10.55; 12.5 13.05; 8.4 7.85; \n",
            "11.3 9.19; 14.3 11.3; 9.6 6.38; \n",
            "11.4 10.54; 15.6 13.18; 7.8 7.73; \n",
            "10.7 11.01; 14.0 14.16; 8.9 7.64; \n",
            "9.2 10.47; 10.9 13.49; 8.5 7.22; \n",
            "7.4 8.91; 8.9 10.53; 6.6 6.41; \n",
            "9.0 7.07; 9.8 8.49; 7.2 4.55; \n",
            "9.1 8.74; 10.8 10.13; 7.4 6.41; \n",
            "9.8 8.71; 10.8 10.46; 8.4 6.12; \n",
            "6.4 9.42; 8.4 10.84; 3.8 7.17; \n",
            "4.1 6.41; 8.4 7.62; 3.4 3.53; \n",
            "2.5 4.48; 4.7 6.1; 0.5 1.38; \n",
            "4.0 3.14; 6.6 4.36; 0.9 0.08; \n",
            "7.8 4.51; 9.7 6.29; 6.2 1.28; \n",
            "6.8 7.7; 10.7 9.4; 4.0 5.16; \n",
            "3.4 6.43; 5.2 8.61; 1.4 3.26; \n",
            "3.1 3.46; 5.7 4.68; 1.2 0.76; \n",
            "0.7 3.39; 3.2 5.18; -0.3 0.47; \n",
            "1.7 0.83; 3.9 1.91; -0.3 -2.04; \n",
            "1.8 2.0; 4.7 3.61; 0.4 -0.89; \n",
            "1.1 1.55; 2.7 3.16; -0.6 -1.04; \n",
            "0.6 1.19; 2.5 2.31; 0.0 -1.16; \n",
            "0.6 0.75; 2.1 2.01; -0.6 -1.77; \n",
            "-0.1 0.96; 1.3 2.19; -1.5 -1.55; \n",
            "1.1 -0.05; 2.1 1.08; -0.3 -2.41; \n",
            "2.5 1.09; 4.4 2.1; 1.6 -0.96; \n",
            "-0.8 2.0; 2.4 3.07; -2.7 0.01; \n",
            "-1.7 -1.23; 0.6 0.02; -2.8 -3.89; \n",
            "-3.8 -1.62; 0.5 -0.28; -6.6 -4.06; \n",
            "-2.8 -3.68; -0.7 -1.65; -4.8 -7.03; \n",
            "-2.3 -2.26; 2.4 -0.69; -5.9 -5.1; \n",
            "-1.7 -2.05; -1.0 0.49; -4.1 -5.6; \n",
            "-1.9 -1.32; -0.6 -0.03; -3.1 -3.81; \n",
            "-3.4 -1.65; -0.6 -0.53; -4.1 -4.01; \n",
            "-2.7 -3.25; -2.3 -1.81; -4.1 -6.26; \n",
            "2.2 -2.07; 5.3 -1.07; -2.3 -4.32; \n",
            "-0.9 2.2; 2.7 4.82; -2.8 -0.9; \n",
            "-0.6 -1.63; 1.5 0.04; -2.9 -4.41; \n",
            "2.2 -0.62; 3.0 1.27; 1.5 -3.3; \n",
            "0.6 1.82; 1.9 3.02; -0.6 -0.06; \n",
            "4.9 -0.11; 7.6 0.86; 1.1 -2.3; \n",
            "3.6 4.22; 7.1 6.25; 2.8 1.57; \n",
            "2.6 2.18; 5.1 3.67; 1.2 0.08; \n",
            "1.0 1.74; 2.8 3.2; -0.3 -0.39; \n",
            "-1.3 0.55; 0.8 1.63; -2.5 -1.69; \n",
            "-5.9 -1.58; -1.8 -0.34; -7.4 -4.21; \n",
            "-5.5 -6.25; -2.5 -4.7; -7.0 -9.43; \n",
            "-6.5 -4.93; -4.1 -3.07; -9.5 -7.75; \n",
            "-6.3 -5.69; -4.6 -4.13; -7.4 -8.91; \n",
            "-5.8 -5.22; -5.0 -3.83; -6.7 -8.37; \n",
            "-5.6 -4.78; -4.8 -3.66; -6.5 -7.59; \n",
            "-4.2 -4.63; -2.5 -3.46; -5.2 -7.41; \n",
            "-7.1 -3.43; -4.9 -2.0; -8.8 -5.88; \n",
            "-4.7 -6.88; -2.6 -5.67; -7.1 -9.83; \n",
            "-0.2 -3.77; 1.4 -1.92; -2.6 -6.5; \n",
            "0.8 -0.02; 1.8 1.83; -1.1 -2.21; \n",
            "-2.0 0.21; -0.6 1.37; -3.0 -1.71; \n",
            "-1.6 -2.81; -0.5 -2.08; -2.6 -4.7; \n",
            "-0.5 -1.81; 1.3 -1.05; -2.5 -3.67; \n",
            "1.6 -0.87; 2.0 0.11; 1.1 -3.0; \n",
            "1.3 0.9; 2.3 1.51; 0.4 -0.57; \n",
            "2.4 0.2; 4.5 0.59; 0.8 -1.19; \n",
            "2.0 1.48; 2.5 2.51; 1.2 -0.36; \n",
            "2.3 1.21; 4.2 1.69; 0.3 -0.31; \n",
            "-0.2 1.65; 1.3 2.76; -0.9 -0.5; \n",
            "-0.9 -0.94; -0.1 -0.65; -1.2 -2.68; \n",
            "-2.3 -1.21; -0.8 -1.0; -3.4 -2.88; \n",
            "-6.5 -2.47; -2.7 -2.17; -7.8 -4.47; \n",
            "-7.6 -6.61; -6.1 -5.57; -8.3 -9.7; \n",
            "-8.1 -6.88; -5.4 -6.48; -11.7 -9.41; \n",
            "-8.8 -6.99; -5.5 -5.33; -10.9 -10.68; \n",
            "-9.4 -7.77; -6.7 -6.05; -11.2 -11.58; \n",
            "-12.3 -8.23; -8.4 -6.67; -14.9 -11.92; \n",
            "-13.6 -11.5; -11.1 -9.51; -16.6 -16.16; \n",
            "-8.2 -12.17; -5.9 -10.55; -12.6 -16.92; \n",
            "-4.5 -5.7; -0.5 -2.81; -6.8 -9.92; \n",
            "-6.2 -3.35; -4.5 -0.47; -7.7 -6.73; \n",
            "-10.6 -5.64; -7.7 -3.76; -12.2 -8.41; \n",
            "-11.2 -10.21; -6.9 -8.65; -14.6 -14.18; \n",
            "-7.7 -9.99; -5.2 -7.04; -9.0 -15.01; \n",
            "-7.7 -6.47; -6.3 -3.95; -8.9 -9.73; \n",
            "-6.6 -7.34; -4.2 -5.99; -9.7 -9.65; \n",
            "-7.2 -5.89; -4.9 -3.9; -8.3 -8.95; \n",
            "-7.8 -6.77; -5.8 -5.21; -9.8 -9.7; \n",
            "-8.7 -7.0; -6.0 -4.92; -11.9 -10.55; \n",
            "-6.5 -7.98; -3.6 -5.68; -9.7 -11.44; \n",
            "-7.4 -5.41; -4.5 -3.1; -8.8 -8.8; \n",
            "-9.9 -7.19; -7.5 -5.65; -11.5 -10.23; \n",
            "-11.8 -9.59; -9.4 -8.15; -13.8 -13.08; \n",
            "-9.8 -11.14; -3.1 -9.98; -14.7 -15.02; \n",
            "-8.2 -8.25; -4.7 -4.16; -10.0 -13.66; \n",
            "-3.0 -7.16; 1.3 -4.32; -8.8 -10.57; \n",
            "-3.2 -1.58; 0.1 2.42; -4.6 -5.5; \n",
            "-6.4 -3.09; -2.7 -0.6; -11.7 -6.06; \n",
            "-4.2 -5.7; 0.3 -2.26; -8.8 -10.36; \n",
            "-4.2 -3.43; 2.2 0.68; -9.7 -7.79; \n",
            "-0.2 -3.86; 1.3 0.41; -1.9 -8.53; \n",
            "1.3 -0.18; 2.5 2.19; 0.8 -2.91; \n",
            "0.5 0.58; 1.2 2.2; -0.4 -1.41; \n",
            "1.5 -0.29; 3.6 1.27; 0.2 -2.72; \n",
            "1.0 0.97; 2.8 2.92; 0.1 -1.29; \n",
            "-2.7 -0.0; 1.1 1.88; -6.0 -2.21; \n",
            "-3.4 -3.18; -2.1 -1.07; -5.7 -6.16; \n",
            "-0.2 -3.33; 2.5 -1.81; -3.3 -6.01; \n",
            "0.4 -0.03; 6.0 2.03; -2.7 -3.03; \n",
            "-0.6 -0.22; 0.8 2.63; -2.5 -3.84; \n",
            "1.4 -0.65; 2.5 0.65; 0.5 -3.1; \n",
            "-0.2 1.28; 2.5 2.5; -2.9 -0.75; \n",
            "-2.2 -0.28; 1.7 1.22; -5.4 -3.3; \n",
            "-2.3 -2.15; 0.7 0.28; -4.1 -5.86; \n",
            "-3.9 -2.27; -0.1 -0.18; -7.2 -4.96; \n",
            "-5.3 -3.8; -0.5 -1.5; -9.0 -7.26; \n",
            "-3.4 -4.74; -0.1 -1.98; -7.5 -9.07; \n",
            "-5.9 -2.41; -2.4 0.62; -8.3 -6.43; \n",
            "-9.3 -5.58; -4.8 -3.01; -12.2 -9.37; \n",
            "-9.5 -8.49; -3.7 -5.67; -14.1 -13.24; \n",
            "-7.7 -8.03; -0.2 -4.03; -13.3 -13.53; \n",
            "-1.4 -6.16; 3.9 -0.94; -6.7 -12.04; \n",
            "2.0 -0.1; 5.2 4.65; -0.5 -4.71; \n",
            "1.9 1.95; 5.0 5.32; -0.1 -1.33; \n",
            "-0.6 1.36; 4.9 4.45; -5.0 -1.89; \n",
            "2.3 -1.09; 6.8 3.06; -1.6 -5.46; \n",
            "5.1 1.85; 13.0 5.93; 0.9 -1.9; \n",
            "3.9 3.89; 8.5 8.59; 0.2 -0.5; \n",
            "3.2 2.41; 6.8 5.91; 1.3 -1.21; \n",
            "5.5 1.93; 12.4 5.0; 1.3 -1.13; \n",
            "7.5 4.52; 12.5 9.06; 4.9 0.29; \n",
            "7.2 6.67; 10.6 10.8; 5.8 2.96; \n",
            "3.7 6.15; 6.9 9.44; 1.9 3.08; \n",
            "-0.3 2.76; 3.4 5.22; -2.4 -0.03; \n",
            "-0.7 -0.48; 3.9 2.13; -4.4 -3.86; \n",
            "-0.3 -0.21; 5.8 3.36; -4.4 -4.49; \n",
            "2.0 0.05; 3.9 4.06; 1.3 -4.37; \n",
            "1.5 2.09; 2.6 4.21; 0.3 -0.56; \n",
            "3.4 1.57; 5.5 3.2; 1.9 -1.07; \n",
            "5.2 3.45; 7.6 5.73; 3.4 0.52; \n",
            "4.7 4.85; 6.4 7.27; 4.0 2.05; \n",
            "2.8 3.82; 4.4 5.62; 1.2 1.66; \n",
            "0.8 2.08; 4.2 3.43; -1.8 0.03; \n",
            "4.4 0.34; 10.1 2.16; -1.5 -2.65; \n",
            "6.5 4.27; 13.3 7.62; 0.6 0.21; \n",
            "9.8 5.97; 15.7 10.08; 6.2 1.45; \n",
            "8.3 9.01; 11.1 12.96; 6.3 5.28; \n",
            "9.1 7.19; 14.0 9.73; 5.8 4.26; \n",
            "7.4 8.47; 13.0 12.15; 2.5 4.71; \n",
            "10.2 7.14; 14.0 11.1; 7.2 2.62; \n",
            "7.9 9.63; 11.3 13.4; 6.8 5.98; \n",
            "5.7 6.88; 8.4 9.45; 3.3 3.88; \n",
            "4.2 5.28; 7.0 7.59; 2.3 2.12; \n",
            "3.8 4.22; 7.5 6.5; -0.1 0.95; \n",
            "6.6 4.17; 12.4 7.2; 1.1 0.15; \n",
            "8.8 7.18; 15.4 11.04; 1.3 2.48; \n",
            "9.1 9.3; 14.6 14.07; 3.2 3.87; \n",
            "11.6 9.09; 15.8 13.42; 8.2 4.15; \n",
            "10.0 11.24; 15.8 15.64; 2.3 6.95; \n",
            "10.4 10.17; 13.8 14.87; 7.5 4.46; \n",
            "14.3 10.12; 21.5 13.9; 8.4 5.98; \n",
            "14.3 13.87; 18.4 19.31; 12.6 8.65; \n",
            "14.1 13.13; 19.0 17.45; 9.8 9.31; \n",
            "10.6 13.36; 16.4 17.94; 8.7 8.91; \n",
            "12.5 10.15; 17.2 14.43; 8.2 5.87; \n",
            "15.4 12.56; 21.1 16.92; 8.5 8.12; \n",
            "16.1 15.32; 19.8 20.82; 11.4 9.81; \n",
            "17.7 15.45; 23.4 20.09; 10.7 11.09; \n",
            "18.1 16.77; 22.5 22.07; 14.6 11.63; \n",
            "16.9 17.22; 23.8 22.36; 10.6 12.87; \n",
            "17.8 16.96; 23.4 22.54; 11.5 11.26; \n",
            "17.8 17.65; 24.0 23.05; 11.3 12.27; \n",
            "18.1 17.72; 25.0 23.18; 11.7 12.08; \n",
            "17.5 17.97; 25.3 23.66; 13.1 12.21; \n",
            "17.0 17.84; 22.0 23.76; 14.3 12.23; \n",
            "16.5 17.14; 23.5 22.44; 12.9 12.1; \n",
            "12.4 17.03; 17.6 22.64; 8.6 11.79; \n",
            "11.1 13.66; 17.0 18.57; 6.7 8.19; \n",
            "13.1 12.63; 18.3 17.53; 7.6 7.17; \n",
            "15.4 14.28; 21.0 19.51; 7.0 8.68; \n",
            "15.1 16.18; 20.0 21.84; 10.2 10.06; \n",
            "17.9 15.45; 23.9 20.74; 11.3 10.05; \n",
            "19.0 17.74; 23.7 23.54; 12.4 12.13; \n",
            "13.5 18.52; 22.4 24.14; 10.2 12.97; \n",
            "10.9 14.59; 15.2 20.5; 6.7 8.51; \n",
            "11.1 11.77; 14.4 16.02; 8.3 6.54; \n",
            "12.3 11.74; 17.0 15.57; 7.2 7.19; \n",
            "15.4 13.05; 20.7 17.6; 7.8 7.72; \n",
            "16.8 15.7; 23.2 21.0; 9.4 10.14; \n",
            "18.3 16.85; 24.3 22.72; 10.6 11.02; \n",
            "18.7 18.08; 26.6 24.08; 12.1 12.27; \n",
            "19.0 18.67; 24.5 24.95; 14.2 12.52; \n",
            "18.5 18.6; 25.5 24.32; 13.0 13.08; \n",
            "19.3 18.08; 25.9 23.79; 11.9 12.41; \n",
            "18.5 18.9; 24.8 24.72; 12.7 13.08; \n",
            "19.7 18.38; 26.3 24.14; 12.5 12.7; \n",
            "19.5 19.37; 25.6 25.3; 14.4 13.46; \n",
            "18.1 19.29; 23.5 25.13; 12.7 13.63; \n",
            "17.9 18.24; 22.7 23.78; 12.8 12.56; \n",
            "13.2 18.07; 20.1 23.45; 10.1 12.58; \n",
            "11.3 14.6; 14.5 19.86; 9.4 8.77; \n",
            "13.4 12.7; 20.7 16.59; 9.3 7.92; \n",
            "14.4 14.81; 18.0 20.24; 11.4 9.11; \n",
            "16.0 15.13; 21.0 19.82; 10.2 10.29; \n",
            "17.6 16.36; 24.7 21.56; 14.5 11.12; \n",
            "20.3 17.66; 27.5 23.59; 15.9 12.56; \n",
            "21.9 19.71; 27.8 25.71; 15.9 14.64; \n",
            "20.3 20.55; 26.2 26.39; 16.4 15.45; \n",
            "18.9 19.32; 22.7 24.87; 14.3 14.5; \n",
            "20.4 17.96; 24.9 22.74; 15.3 13.37; \n",
            "20.4 19.38; 26.0 24.53; 14.2 14.7; \n",
            "18.5 19.7; 22.5 25.07; 15.2 14.41; \n",
            "16.7 18.03; 21.2 22.67; 13.0 13.59; \n",
            "16.0 16.93; 21.2 21.48; 10.1 12.15; \n",
            "17.9 16.93; 23.2 21.88; 13.3 11.37; \n",
            "20.0 18.49; 26.4 23.75; 14.7 13.1; \n",
            "19.7 19.95; 26.6 25.59; 15.9 14.49; \n",
            "21.8 19.61; 26.8 25.21; 15.5 14.43; \n",
            "21.0 20.95; 26.2 26.49; 17.1 15.79; \n",
            "20.0 20.28; 25.8 25.81; 17.1 15.35; \n",
            "19.1 19.73; 25.6 25.09; 13.8 14.81; \n",
            "19.1 19.24; 24.8 24.71; 13.4 13.87; \n",
            "20.2 19.06; 24.6 24.41; 16.0 13.81; \n",
            "21.6 19.6; 26.6 24.8; 15.0 14.73; \n",
            "21.0 20.76; 28.0 26.12; 14.8 15.55; \n",
            "19.7 20.75; 24.7 26.48; 17.5 15.07; \n",
            "15.4 19.56; 19.1 24.86; 12.1 14.74; \n",
            "18.3 16.21; 23.5 20.57; 13.0 11.33; \n",
            "20.0 18.81; 25.1 23.99; 13.4 13.43; \n",
            "17.7 19.97; 23.4 25.36; 16.1 14.47; \n",
            "15.2 17.84; 18.4 22.94; 12.7 13.09; \n",
            "18.8 15.88; 22.9 20.01; 14.2 11.41; \n",
            "22.9 18.73; 29.3 23.75; 15.7 13.93; \n",
            "24.4 21.74; 29.2 27.4; 19.7 16.5; \n",
            "23.7 22.35; 27.7 27.78; 18.6 17.54; \n",
            "22.0 21.62; 28.5 26.62; 19.0 17.08; \n",
            "22.8 20.81; 28.5 26.25; 17.8 16.18; \n",
            "25.4 21.63; 31.4 26.9; 17.2 16.76; \n",
            "28.4 23.31; 35.4 28.69; 20.2 17.95; \n",
            "27.3 24.81; 32.6 30.07; 22.5 19.69; \n",
            "26.3 24.09; 32.3 29.34; 20.7 19.45; \n",
            "25.7 23.88; 30.1 29.15; 22.7 18.93; \n",
            "23.6 23.68; 28.5 28.82; 18.2 18.93; \n",
            "23.9 22.65; 28.4 27.71; 18.8 17.51; \n",
            "23.7 22.79; 28.3 27.81; 17.5 17.72; \n",
            "22.7 22.74; 28.5 27.82; 16.8 17.44; \n",
            "24.5 22.19; 30.4 27.45; 16.4 16.74; \n",
            "25.8 23.45; 31.7 28.83; 17.8 17.78; \n",
            "23.5 24.13; 31.4 29.52; 19.0 18.42; \n",
            "19.1 23.01; 23.4 28.6; 14.5 17.42; \n",
            "22.1 19.99; 28.1 25.09; 14.4 14.3; \n",
            "22.9 22.04; 28.2 27.52; 19.6 16.12; \n",
            "22.5 22.34; 27.3 27.83; 18.4 17.11; \n",
            "23.5 21.83; 28.8 27.05; 16.9 16.73; \n",
            "22.3 22.42; 26.9 27.81; 17.3 17.06; \n",
            "23.4 21.64; 28.4 27.03; 18.9 16.42; \n",
            "23.5 22.26; 28.8 27.57; 15.4 17.18; \n",
            "22.8 22.59; 28.2 27.99; 15.9 16.9; \n",
            "24.9 21.97; 31.5 27.23; 16.7 16.34; \n",
            "26.5 23.21; 33.4 28.68; 18.4 17.72; \n",
            "27.6 24.29; 33.6 29.78; 20.8 18.66; \n",
            "26.5 24.84; 33.0 30.12; 21.5 19.51; \n",
            "25.0 24.2; 30.5 29.59; 21.3 19.01; \n",
            "26.6 23.38; 31.6 28.62; 19.4 18.35; \n",
            "26.9 24.39; 32.5 29.59; 20.3 19.04; \n",
            "27.8 24.53; 33.7 29.76; 20.8 19.24; \n",
            "26.8 24.92; 33.5 30.07; 21.2 19.66; \n",
            "21.5 24.51; 28.4 29.81; 16.0 19.26; \n",
            "17.3 21.82; 24.1 27.3; 15.3 15.92; \n",
            "17.2 19.01; 22.9 24.34; 15.0 13.25; \n",
            "18.5 18.92; 23.5 24.1; 15.6 13.43; \n",
            "19.9 19.62; 25.5 24.83; 14.5 14.27; \n",
            "23.7 20.47; 30.2 25.97; 16.0 15.01; \n",
            "22.7 22.72; 28.1 28.54; 19.1 17.16; \n",
            "25.5 21.92; 32.5 27.65; 18.6 16.87; \n",
            "26.1 23.64; 33.0 29.34; 19.5 18.19; \n",
            "26.0 23.82; 31.0 29.38; 21.9 18.51; \n",
            "26.5 23.38; 32.5 28.62; 19.6 18.61; \n",
            "27.8 23.73; 34.4 29.01; 21.6 18.67; \n",
            "24.7 24.68; 30.6 29.96; 20.3 19.65; \n",
            "21.8 23.09; 26.9 28.4; 18.2 18.02; \n",
            "20.0 21.32; 24.1 26.45; 17.0 16.3; \n",
            "20.3 20.33; 26.6 25.16; 12.6 15.26; \n",
            "23.5 20.95; 29.5 26.36; 16.7 14.94; \n",
            "22.2 22.84; 27.1 28.33; 18.1 17.2; \n",
            "20.0 21.82; 23.2 27.21; 17.9 16.5; \n",
            "20.0 19.99; 29.5 24.73; 17.3 15.34; \n",
            "20.0 20.77; 23.6 26.72; 17.6 15.17; \n",
            "18.7 20.19; 25.1 25.28; 12.3 15.4; \n",
            "20.7 19.38; 25.9 24.77; 16.0 13.68; \n",
            "16.3 20.52; 22.0 25.93; 11.7 15.38; \n",
            "19.5 17.28; 26.4 22.35; 10.5 12.01; \n",
            "20.7 19.88; 26.6 25.73; 16.5 13.7; \n",
            "15.6 20.62; 22.6 26.38; 13.1 15.23; \n",
            "17.9 16.56; 24.5 21.77; 11.5 11.2; \n",
            "21.1 18.68; 27.6 24.33; 15.4 12.97; \n",
            "21.1 20.86; 27.1 26.88; 15.8 15.06; \n",
            "22.0 20.53; 28.2 26.26; 16.2 15.23; \n",
            "23.8 21.17; 31.0 27.0; 16.2 15.69; \n",
            "22.6 22.37; 29.0 28.24; 18.7 16.67; \n",
            "20.2 21.36; 24.4 27.15; 18.0 16.29; \n",
            "17.5 19.71; 18.9 24.91; 16.3 14.87; \n",
            "17.9 17.31; 19.4 21.2; 16.6 13.25; \n",
            "18.4 17.55; 23.5 21.33; 13.8 13.78; \n",
            "20.3 18.54; 27.2 23.4; 14.3 13.64; \n",
            "21.6 20.25; 27.9 25.71; 15.8 14.94; \n",
            "21.3 20.99; 26.9 26.55; 17.3 15.75; \n",
            "21.1 20.6; 27.0 26.0; 15.4 15.69; \n",
            "19.8 20.74; 25.6 26.16; 15.6 15.39; \n",
            "18.5 19.88; 22.3 25.27; 17.1 14.66; \n",
            "17.2 18.52; 20.2 23.18; 16.3 14.26; \n",
            "16.6 17.33; 19.6 21.48; 15.6 13.45; \n",
            "15.4 16.85; 20.0 20.8; 14.8 13.09; \n",
            "15.9 15.96; 21.7 20.17; 11.7 11.96; \n",
            "15.8 16.68; 22.3 21.52; 11.7 11.9; \n",
            "18.2 16.78; 24.8 22.01; 12.8 11.67; \n",
            "18.1 18.55; 24.0 24.11; 13.7 13.36; \n",
            "18.1 18.2; 25.5 23.61; 12.0 13.22; \n",
            "18.6 18.46; 26.1 24.22; 13.3 12.94; \n",
            "18.8 18.87; 27.2 24.78; 12.5 13.45; \n",
            "19.4 19.17; 28.0 25.31; 13.0 13.41; \n",
            "20.4 19.67; 28.2 25.94; 14.2 13.67; \n",
            "20.9 20.2; 28.6 26.41; 14.9 14.37; \n",
            "19.3 20.41; 24.8 26.63; 16.3 14.58; \n",
            "19.4 19.12; 25.4 24.92; 16.8 13.92; \n",
            "17.4 19.23; 25.1 24.96; 12.1 14.08; \n",
            "16.7 18.09; 23.8 24.06; 10.7 12.26; \n",
            "15.4 17.63; 20.3 23.59; 9.7 11.52; \n",
            "13.1 16.32; 18.0 21.7; 11.3 10.52; \n",
            "14.5 14.13; 18.7 18.91; 11.7 9.05; \n",
            "12.6 15.4; 16.6 20.13; 9.8 10.41; \n",
            "10.1 13.54; 13.9 17.95; 8.2 8.69; \n",
            "12.1 11.23; 16.7 14.86; 7.8 6.82; \n",
            "13.0 13.25; 17.8 17.73; 10.2 8.31; \n",
            "13.4 13.79; 20.5 18.36; 8.6 9.09; \n",
            "13.8 14.11; 21.1 19.44; 9.3 8.71; \n",
            "16.0 14.24; 20.0 19.67; 12.3 9.06; \n",
            "12.5 15.74; 16.8 20.63; 9.8 11.33; \n",
            "11.4 12.63; 16.2 16.87; 7.1 8.26; \n",
            "11.7 11.95; 17.6 16.13; 7.5 7.34; \n",
            "12.8 12.23; 16.0 16.82; 10.9 7.38; \n",
            "12.7 12.76; 16.5 16.65; 11.4 9.01; \n",
            "11.2 12.57; 18.3 16.34; 7.0 8.8; \n",
            "12.1 11.76; 16.1 16.39; 9.8 6.86; \n",
            "12.8 12.39; 20.1 16.57; 8.0 8.31; \n",
            "14.3 13.4; 22.1 18.84; 9.9 8.15; \n",
            "11.5 14.83; 18.1 20.47; 8.2 9.6; \n",
            "10.0 11.96; 14.0 16.83; 7.5 7.15; \n",
            "8.0 10.13; 13.9 14.05; 3.0 6.13; \n",
            "7.7 8.83; 14.6 13.19; 2.2 3.82; \n",
            "10.9 8.91; 15.6 13.84; 7.9 3.22; \n",
            "11.5 11.43; 16.0 16.01; 9.2 7.01; \n",
            "9.5 11.39; 17.0 15.8; 4.6 7.12; \n",
            "10.1 10.11; 17.7 15.07; 4.0 4.81; \n",
            "11.4 10.99; 17.7 16.81; 7.0 5.05; \n",
            "11.8 11.88; 14.4 17.43; 10.0 6.52; \n",
            "11.2 11.59; 15.6 15.63; 7.4 7.59; \n",
            "10.8 10.98; 14.3 15.02; 8.1 6.64; \n",
            "8.6 10.36; 10.2 14.02; 6.6 6.58; \n",
            "8.2 8.39; 10.6 11.09; 7.3 5.09; \n",
            "7.1 8.28; 12.3 10.84; 3.0 5.04; \n",
            "5.2 7.72; 10.7 10.92; 1.5 3.3; \n",
            "8.4 5.74; 11.8 9.16; 4.9 1.16; \n",
            "8.8 8.8; 12.8 12.2; 4.5 4.91; \n",
            "9.2 9.01; 12.7 12.48; 6.8 4.65; \n",
            "9.0 9.34; 12.0 12.44; 6.5 5.62; \n",
            "9.6 8.85; 13.7 11.89; 6.5 5.27; \n",
            "13.6 9.39; 19.1 12.69; 8.5 5.73; \n",
            "15.3 13.34; 21.2 18.0; 11.2 8.92; \n",
            "14.9 14.45; 19.5 19.42; 10.5 10.12; \n",
            "13.0 13.79; 18.0 18.18; 10.2 9.68; \n",
            "10.4 12.32; 13.8 16.56; 6.7 8.26; \n",
            "6.8 10.32; 11.3 13.58; 4.5 6.35; \n",
            "6.1 7.0; 8.3 10.03; 3.5 2.93; \n",
            "10.1 6.65; 17.5 8.92; 5.2 3.17; \n",
            "13.2 10.69; 19.2 15.26; 8.6 5.77; \n",
            "10.8 13.41; 14.6 18.52; 9.1 8.68; \n",
            "9.1 10.8; 13.5 14.75; 6.6 6.76; \n",
            "7.1 9.48; 11.0 13.14; 2.0 5.33; \n",
            "11.8 7.91; 18.6 11.51; 8.0 3.12; \n",
            "9.3 12.23; 12.7 17.34; 7.9 7.31; \n",
            "6.4 8.91; 10.5 12.06; 2.5 5.41; \n",
            "7.3 6.29; 12.2 9.12; 2.6 2.53; \n",
            "9.5 7.87; 14.5 11.57; 6.5 3.45; \n",
            "7.2 9.83; 12.9 14.2; 4.5 5.32; \n",
            "5.3 7.53; 7.6 11.37; 2.2 2.95; \n",
            "8.1 5.66; 9.7 8.31; 5.8 2.04; \n",
            "5.9 8.05; 9.9 10.44; 2.2 5.02; \n",
            "3.6 6.04; 6.9 9.09; 0.0 1.81; \n",
            "7.0 4.06; 10.2 6.84; 4.0 -0.02; \n",
            "9.5 7.18; 10.4 9.98; 8.2 3.75; \n",
            "10.3 8.79; 12.6 10.87; 8.1 6.16; \n",
            "7.0 9.55; 10.4 12.15; 4.8 6.37; \n",
            "3.0 6.47; 6.7 8.79; 0.0 3.14; \n",
            "0.7 2.99; 4.7 5.07; -1.9 -0.33; \n",
            "-1.9 1.15; 1.4 3.35; -4.6 -2.55; \n",
            "-0.8 -1.14; 2.1 0.78; -3.5 -4.91; \n",
            "-0.5 -0.04; 0.8 1.98; -1.5 -3.51; \n",
            "0.9 -0.02; 2.4 1.25; 0.0 -2.69; \n",
            "-1.0 1.45; 1.9 2.86; -4.4 -1.24; \n",
            "-1.3 -0.24; 0.5 1.62; -2.9 -3.93; \n",
            "-1.7 -0.57; 1.6 1.21; -4.4 -3.61; \n",
            "-1.7 -1.26; 1.7 0.96; -3.9 -4.61; \n",
            "-4.7 -1.45; -1.9 0.78; -5.1 -4.79; \n",
            "-4.5 -4.77; -3.0 -3.33; -5.7 -7.54; \n",
            "-2.9 -4.0; -2.0 -2.56; -3.9 -6.67; \n",
            "-2.5 -2.42; -1.6 -1.34; -3.1 -4.59; \n",
            "-5.4 -2.28; -2.8 -1.33; -8.1 -4.47; \n",
            "-4.0 -5.2; -2.8 -3.77; -6.1 -8.12; \n",
            "-3.4 -3.27; -1.6 -1.75; -4.8 -5.75; \n",
            "-5.4 -3.02; -2.2 -1.8; -6.8 -5.55; \n",
            "-12.1 -5.32; -6.8 -3.78; -14.2 -8.49; \n",
            "-10.5 -12.6; -7.6 -10.96; -13.4 -16.93; \n",
            "-2.9 -9.13; -1.4 -6.96; -7.6 -13.07; \n",
            "-1.0 -1.18; 1.0 1.28; -1.8 -4.26; \n",
            "-3.4 -1.07; -1.3 0.51; -5.4 -3.46; \n",
            "-4.7 -3.43; -2.5 -1.99; -8.1 -5.98; \n",
            "-9.5 -4.19; -5.4 -2.03; -12.8 -7.47; \n",
            "-5.0 -9.21; -2.4 -6.83; -8.6 -13.74; \n",
            "-2.4 -3.67; -2.0 -0.88; -2.8 -7.34; \n",
            "-0.8 -2.41; 2.0 -1.55; -3.6 -4.1; \n",
            "2.4 -1.09; 3.8 0.97; 1.0 -3.9; \n",
            "-1.5 1.83; 2.7 3.39; -2.9 -0.03; \n",
            "-3.8 -2.35; -2.1 -0.28; -5.5 -5.44; \n",
            "-4.0 -3.72; -3.2 -2.04; -4.7 -6.29; \n",
            "-3.4 -3.93; -1.7 -2.86; -5.6 -5.96; \n",
            "-1.9 -3.48; 0.3 -2.35; -4.1 -6.07; \n",
            "-1.4 -2.16; 2.8 -0.64; -5.5 -4.43; \n",
            "-0.9 -1.63; 2.0 0.78; -3.4 -4.86; \n",
            "-6.8 -0.7; -1.4 1.09; -8.8 -3.51; \n",
            "-7.1 -6.96; -5.2 -4.45; -9.9 -11.24; \n",
            "-7.1 -5.86; -6.4 -3.81; -7.8 -9.66; \n",
            "-7.1 -6.49; -6.7 -5.39; -7.3 -9.06; \n",
            "-9.4 -6.58; -7.3 -6.2; -10.2 -9.0; \n",
            "-8.4 -9.12; -7.9 -8.71; -9.7 -11.96; \n",
            "-7.9 -7.23; -6.5 -6.31; -8.9 -10.01; \n",
            "-9.3 -6.89; -7.4 -5.73; -10.1 -9.79; \n",
            "-10.2 -8.63; -9.0 -7.52; -11.2 -11.85; \n",
            "-8.3 -9.46; -5.5 -8.96; -11.2 -12.41; \n",
            "-6.2 -7.2; -3.2 -5.09; -8.9 -10.48; \n",
            "-6.4 -5.32; -3.6 -3.31; -7.9 -8.28; \n",
            "-7.8 -5.97; -6.1 -4.38; -10.1 -8.64; \n",
            "-9.6 -7.15; -7.2 -6.02; -12.7 -10.01; \n",
            "-11.2 -8.85; -8.6 -7.37; -12.9 -12.6; \n",
            "-12.0 -10.59; -9.5 -9.54; -13.9 -14.37; \n",
            "-12.5 -11.31; -9.8 -10.42; -13.7 -14.94; \n",
            "-10.4 -11.82; -1.8 -11.1; -15.9 -15.38; \n",
            "-4.9 -8.83; 4.0 -4.02; -13.8 -14.72; \n",
            "-7.5 -2.99; -0.4 3.27; -9.1 -8.98; \n",
            "0.3 -7.14; 2.7 -2.29; -6.4 -11.73; \n",
            "2.0 2.09; 2.8 6.41; 1.5 -1.82; \n",
            "2.5 1.26; 3.5 3.37; 0.5 -1.03; \n",
            "-1.8 1.46; 3.2 3.77; -3.8 -0.98; \n",
            "-5.2 -3.65; -2.0 -0.83; -7.7 -6.64; \n",
            "-0.8 -5.65; 1.1 -3.29; -2.8 -8.63; \n",
            "-2.0 -0.64; 0.8 1.73; -5.2 -3.6; \n",
            "0.2 -2.4; 4.0 0.1; -2.9 -5.71; \n",
            "6.3 -0.12; 8.1 3.0; 1.6 -3.72; \n",
            "4.6 5.67; 6.5 8.43; 2.9 3.1; \n",
            "4.2 3.38; 6.0 5.14; 2.0 0.79; \n",
            "3.9 3.65; 7.6 5.22; 1.6 1.11; \n",
            "-0.4 2.98; 2.3 5.06; -1.8 -0.07; \n",
            "-3.2 -1.24; -1.0 0.2; -5.1 -3.88; \n",
            "-2.0 -3.44; 0.7 -1.92; -4.8 -6.26; \n",
            "4.1 -1.54; 5.4 0.1; 0.7 -4.55; \n",
            "2.6 4.21; 4.3 6.07; 1.2 1.45; \n",
            "3.8 1.97; 5.9 3.35; 0.7 -0.5; \n",
            "2.9 3.69; 4.3 5.45; 1.2 0.88; \n",
            "-1.9 2.55; 2.9 3.65; -5.0 0.11; \n",
            "-5.0 -1.98; -1.5 0.28; -8.3 -6.07; \n",
            "-5.1 -4.72; -2.6 -2.51; -7.9 -8.41; \n",
            "-1.5 -4.44; 1.3 -2.65; -4.6 -7.75; \n",
            "1.4 -0.82; 4.9 1.21; -0.7 -4.13; \n",
            "5.2 1.42; 8.9 3.68; 1.8 -1.66; \n",
            "5.0 4.86; 7.5 7.72; 2.3 1.64; \n",
            "2.2 4.33; 4.7 6.68; 0.7 1.53; \n",
            "-2.0 1.55; 2.0 3.55; -4.9 -1.28; \n",
            "-3.2 -2.38; 0.8 0.03; -7.7 -6.02; \n",
            "-3.3 -3.14; 0.7 -0.14; -8.4 -7.02; \n",
            "-2.0 -3.17; 1.4 -0.29; -5.3 -7.13; \n",
            "-1.1 -1.73; 0.3 0.7; -2.3 -5.26; \n",
            "2.2 -0.7; 4.2 0.79; 0.0 -3.57; \n",
            "2.8 2.59; 4.2 4.77; 1.5 -0.54; \n",
            "3.1 2.58; 5.1 4.32; 1.9 -0.07; \n",
            "2.5 2.57; 4.6 4.42; 1.1 0.06; \n",
            "3.2 1.75; 7.0 3.42; 0.4 -0.52; \n",
            "0.8 2.47; 4.8 4.86; -1.6 -0.45; \n",
            "0.7 -0.13; 5.0 2.0; -3.3 -3.11; \n",
            "0.9 0.31; 4.8 2.99; -0.3 -3.08; \n",
            "1.3 0.35; 2.7 2.39; 0.1 -2.42; \n",
            "-0.1 1.14; 2.5 2.46; -3.1 -1.17; \n",
            "-1.9 -0.19; 1.9 1.62; -3.7 -3.26; \n",
            "-1.4 -1.79; 0.2 0.27; -2.4 -4.96; \n",
            "-0.9 -1.01; 1.4 0.5; -2.2 -3.5; \n",
            "-2.3 -0.63; 0.2 1.12; -5.2 -3.33; \n",
            "1.2 -1.99; 3.5 -0.06; 0.0 -5.2; \n",
            "2.0 1.28; 4.3 3.23; 0.0 -1.18; \n",
            "2.7 1.53; 6.0 3.39; -0.1 -0.96; \n",
            "2.1 2.26; 4.9 4.56; 1.1 -0.61; \n",
            "0.8 1.39; 2.3 2.98; 0.4 -0.86; \n",
            "0.3 0.09; 3.2 1.25; -1.5 -1.94; \n",
            "-2.0 -0.19; 1.4 1.52; -5.5 -2.65; \n",
            "-1.7 -2.23; 2.0 -0.26; -5.8 -5.46; \n",
            "0.2 -1.5; 4.8 0.87; -4.6 -4.78; \n",
            "1.5 0.41; 3.1 3.34; 0.7 -3.4; \n",
            "2.4 1.45; 4.0 2.93; 0.9 -1.07; \n",
            "5.0 2.19; 7.6 3.7; 3.4 -0.38; \n",
            "7.1 4.34; 12.1 6.43; 4.6 1.72; \n",
            "5.3 6.13; 9.3 9.2; 2.5 3.07; \n",
            "4.5 4.22; 10.6 6.9; -0.5 1.18; \n",
            "8.3 3.86; 12.7 7.39; 4.0 -0.05; \n",
            "10.8 7.43; 14.8 10.91; 7.9 3.77; \n",
            "10.8 9.3; 12.7 12.8; 9.3 6.04; \n",
            "9.9 9.03; 10.7 11.65; 9.1 6.47; \n",
            "12.0 8.36; 16.2 10.02; 7.4 6.44; \n",
            "12.4 11.0; 16.2 14.49; 8.4 7.51; \n",
            "13.6 11.72; 17.0 15.43; 10.8 7.96; \n",
            "14.0 12.55; 20.2 16.06; 9.5 9.01; \n",
            "15.3 13.0; 21.0 17.2; 10.8 8.89; \n",
            "15.9 14.46; 18.7 19.13; 13.7 10.15; \n",
            "10.7 14.91; 17.0 18.96; 8.7 11.31; \n",
            "9.1 10.72; 15.0 14.51; 4.8 6.6; \n",
            "8.6 9.96; 12.8 13.74; 5.2 5.39; \n",
            "7.3 9.4; 10.6 12.97; 5.3 5.16; \n",
            "6.1 7.86; 10.3 10.78; 1.5 4.09; \n",
            "10.7 7.09; 16.9 10.24; 5.6 2.56; \n",
            "11.0 11.56; 16.7 16.41; 5.0 6.54; \n",
            "12.1 11.59; 18.7 16.63; 4.8 6.31; \n",
            "14.2 12.71; 19.3 18.27; 10.0 6.82; \n",
            "12.8 14.22; 15.7 19.38; 11.1 9.26; \n",
            "11.9 12.17; 16.4 16.07; 7.0 8.22; \n",
            "13.1 11.69; 17.8 15.84; 8.9 7.03; \n",
            "13.9 12.88; 19.7 17.39; 5.7 8.3; \n",
            "13.8 13.74; 18.5 18.58; 6.9 8.36; \n",
            "14.0 13.73; 19.6 18.64; 6.8 8.38; \n",
            "15.8 14.24; 23.0 19.31; 8.8 8.46; \n",
            "17.9 15.82; 24.2 21.54; 11.8 9.9; \n",
            "14.0 17.69; 19.1 23.57; 10.2 11.99; \n",
            "15.2 14.28; 21.7 19.24; 10.1 8.89; \n",
            "13.6 15.59; 17.7 20.91; 11.6 10.19; \n",
            "12.3 14.01; 17.5 18.71; 9.0 9.19; \n",
            "12.1 12.97; 17.7 17.57; 7.3 7.99; \n",
            "10.9 12.84; 17.2 17.68; 5.5 7.57; \n",
            "13.3 11.89; 19.2 16.8; 5.0 6.39; \n",
            "14.6 14.18; 20.6 19.66; 7.0 8.11; \n",
            "13.4 15.3; 18.5 21.19; 11.6 9.1; \n",
            "13.4 13.71; 17.5 18.54; 9.0 8.78; \n",
            "11.9 13.68; 15.2 18.24; 8.8 8.83; \n",
            "12.2 12.21; 15.2 16.25; 8.3 7.57; \n",
            "15.2 12.57; 19.8 16.42; 11.3 8.08; \n",
            "14.1 14.99; 16.8 19.71; 12.8 10.37; \n",
            "13.1 13.71; 17.5 17.41; 8.4 9.94; \n",
            "14.5 12.99; 19.8 17.02; 5.5 8.49; \n",
            "15.8 14.75; 22.1 19.63; 9.0 9.25; \n",
            "14.5 16.09; 19.5 21.58; 9.9 10.31; \n",
            "14.0 14.75; 18.0 19.44; 10.5 9.67; \n",
            "17.3 14.07; 22.5 18.2; 9.0 9.5; \n",
            "18.6 17.1; 22.9 22.26; 12.0 11.67; \n",
            "17.9 18.07; 25.5 23.43; 10.9 12.86; \n",
            "19.5 18.08; 27.0 23.94; 12.5 12.02; \n",
            "16.0 19.31; 19.8 25.31; 14.4 13.38; \n",
            "12.6 15.94; 16.9 20.66; 8.9 11.31; \n",
            "14.2 13.15; 20.8 17.35; 7.8 8.05; \n",
            "16.5 15.22; 22.8 20.51; 8.6 9.32; \n",
            "16.5 17.25; 20.4 23.0; 13.5 11.04; \n",
            "16.4 16.48; 21.4 21.54; 11.2 11.73; \n",
            "12.3 16.59; 18.7 21.76; 11.5 11.3; \n",
            "14.0 13.2; 18.9 17.96; 10.7 8.25; \n",
            "16.7 14.81; 21.9 19.73; 10.9 9.87; \n",
            "17.5 16.9; 23.1 22.35; 11.5 11.49; \n",
            "17.3 17.47; 23.1 22.78; 10.0 12.25; \n",
            "18.3 17.13; 24.2 22.63; 10.9 11.61; \n",
            "17.1 18.04; 21.9 23.77; 12.9 12.45; \n",
            "18.9 17.15; 24.6 22.47; 11.4 11.85; \n",
            "20.9 18.67; 26.8 24.13; 13.0 13.06; \n",
            "22.1 20.1; 28.7 25.75; 14.4 14.34; \n",
            "20.8 20.94; 26.3 26.78; 17.6 15.18; \n",
            "21.5 19.95; 28.5 25.52; 14.7 14.89; \n",
            "23.7 20.89; 30.1 26.69; 17.6 15.08; \n",
            "23.1 22.21; 28.2 27.96; 19.5 16.71; \n",
            "22.2 21.64; 27.4 27.12; 17.5 16.67; \n",
            "23.0 21.08; 29.2 26.42; 14.8 15.94; \n",
            "24.1 22.01; 31.4 27.58; 15.7 16.35; \n",
            "23.0 22.84; 27.1 28.64; 19.7 16.9; \n",
            "22.3 21.79; 26.7 27.07; 19.2 16.87; \n",
            "15.8 21.36; 19.2 26.44; 14.2 16.41; \n",
            "17.8 16.7; 22.7 20.77; 13.2 12.07; \n",
            "21.4 18.57; 27.2 23.48; 12.9 13.32; \n",
            "23.7 21.36; 30.5 26.92; 16.5 15.49; \n",
            "25.2 22.7; 31.1 28.36; 17.9 17.03; \n",
            "24.2 23.2; 29.3 28.75; 18.2 17.85; \n",
            "23.3 22.49; 29.9 27.99; 18.5 17.28; \n",
            "23.2 22.34; 31.0 27.9; 19.4 16.9; \n",
            "20.8 22.53; 28.6 28.24; 17.6 17.17; \n",
            "22.7 20.89; 28.5 26.43; 17.9 15.51; \n",
            "23.6 21.79; 29.5 27.24; 18.5 16.67; \n",
            "22.0 22.34; 26.6 27.89; 18.8 17.22; \n",
            "22.8 21.35; 28.2 26.7; 18.1 16.42; \n",
            "21.8 22.02; 25.1 27.46; 19.1 16.89; \n",
            "21.1 21.1; 26.7 26.14; 17.4 16.52; \n",
            "21.7 20.79; 26.6 25.95; 17.2 15.89; \n",
            "22.4 21.17; 28.1 26.33; 16.9 16.22; \n",
            "25.3 21.67; 30.5 26.93; 20.4 16.49; \n",
            "25.1 23.2; 30.8 28.47; 19.2 18.42; \n",
            "25.3 23.26; 31.3 28.57; 19.2 18.29; \n",
            "23.5 23.43; 27.6 28.72; 19.7 18.32; \n",
            "16.2 22.27; 22.9 27.37; 13.4 17.57; \n",
            "14.8 17.53; 20.0 22.44; 10.8 12.16; \n",
            "15.2 16.62; 20.8 21.2; 10.9 11.31; \n",
            "18.2 16.86; 23.7 21.86; 13.2 11.27; \n",
            "20.8 18.9; 27.6 24.2; 12.8 13.56; \n",
            "17.9 20.88; 24.3 26.81; 15.8 14.95; \n",
            "16.7 18.59; 21.4 24.36; 13.8 13.3; \n",
            "17.6 17.51; 23.0 22.72; 10.3 12.47; \n",
            "20.1 18.36; 26.4 24.03; 12.6 12.39; \n",
            "23.0 20.1; 29.7 25.86; 15.0 14.23; \n",
            "21.0 21.55; 27.2 27.36; 17.1 15.9; \n",
            "15.8 20.04; 20.1 25.68; 14.2 14.97; \n",
            "18.7 16.18; 25.0 20.82; 14.9 11.45; \n",
            "22.9 18.8; 29.6 24.28; 17.4 13.67; \n",
            "24.0 21.88; 31.0 27.63; 17.8 16.54; \n",
            "24.6 22.44; 30.2 28.16; 18.0 17.05; \n",
            "24.7 22.46; 29.5 28.01; 20.3 17.42; \n",
            "24.9 22.49; 31.3 27.97; 19.0 17.72; \n",
            "25.6 23.03; 30.7 28.58; 19.8 17.84; \n",
            "25.8 23.46; 31.0 28.77; 19.0 18.36; \n",
            "25.7 23.39; 32.5 28.53; 18.5 18.3; \n",
            "26.8 23.52; 33.3 28.91; 19.6 18.26; \n",
            "27.1 24.42; 34.3 29.76; 19.9 19.03; \n",
            "25.6 24.73; 31.5 30.12; 21.2 19.18; \n",
            "21.1 23.87; 25.6 29.17; 19.7 18.65; \n",
            "21.2 21.13; 26.3 26.15; 15.6 16.16; \n",
            "22.0 21.41; 27.5 26.57; 15.6 15.95; \n",
            "23.0 22.07; 28.5 27.5; 15.7 16.31; \n",
            "24.2 22.54; 30.5 27.98; 16.6 16.8; \n",
            "23.9 23.12; 29.0 28.66; 18.5 17.41; \n",
            "23.6 22.82; 28.5 28.27; 19.4 17.4; \n",
            "22.9 22.53; 28.5 27.86; 15.6 17.35; \n",
            "22.4 22.32; 30.0 27.74; 16.8 16.58; \n",
            "17.3 22.23; 22.1 27.87; 15.5 16.37; \n",
            "16.0 18.31; 21.0 23.2; 13.2 13.22; \n",
            "16.3 17.21; 21.1 21.95; 11.5 12.04; \n",
            "21.6 17.66; 26.9 22.65; 15.9 12.12; \n",
            "21.9 21.18; 29.4 26.74; 16.1 15.86; \n",
            "23.7 21.46; 31.6 27.38; 17.8 15.93; \n",
            "22.9 22.62; 30.2 28.56; 16.0 17.09; \n",
            "19.8 22.08; 25.0 28.0; 17.4 16.41; \n",
            "16.6 19.69; 19.1 25.25; 15.7 14.59; \n",
            "16.5 16.9; 19.4 21.08; 14.9 12.53; \n",
            "18.9 16.68; 24.4 20.79; 15.1 12.56; \n",
            "20.3 18.8; 26.7 23.77; 15.8 14.18; \n",
            "18.7 19.91; 23.5 25.48; 16.0 15.01; \n",
            "19.4 18.66; 26.1 23.69; 13.9 14.08; \n",
            "20.2 19.53; 25.8 25.15; 16.4 14.1; \n",
            "21.6 20.0; 28.4 25.48; 14.5 14.99; \n",
            "23.4 21.08; 29.2 26.76; 17.9 15.52; \n",
            "18.6 21.92; 26.2 27.41; 15.8 16.96; \n",
            "18.4 18.83; 22.8 24.38; 14.6 13.84; \n",
            "19.7 18.51; 25.0 23.51; 13.5 13.76; \n",
            "18.5 19.78; 25.6 25.25; 14.3 14.33; \n",
            "16.4 19.0; 21.8 24.67; 15.9 13.41; \n",
            "15.5 17.06; 22.3 21.96; 9.8 12.56; \n",
            "17.8 16.67; 25.3 22.13; 11.4 10.9; \n",
            "21.7 18.71; 28.5 24.72; 15.3 12.79; \n",
            "21.5 21.23; 28.5 27.32; 15.4 15.52; \n",
            "22.0 20.89; 28.8 26.87; 15.4 15.24; \n",
            "22.1 21.22; 30.4 27.13; 14.3 15.56; \n",
            "20.1 21.46; 25.4 27.68; 15.7 15.46; \n",
            "13.6 19.84; 17.7 25.52; 12.7 14.44; \n",
            "14.4 14.5; 18.4 18.89; 11.1 9.52; \n",
            "15.2 15.24; 17.4 19.57; 12.9 10.45; \n",
            "17.6 15.67; 22.7 19.75; 14.8 11.26; \n",
            "17.9 17.7; 23.7 22.83; 12.8 12.91; \n",
            "18.2 18.14; 25.8 23.5; 11.0 12.98; \n",
            "19.6 18.66; 27.2 24.61; 14.7 12.7; \n",
            "17.0 19.6; 20.7 25.69; 16.5 14.04; \n",
            "16.0 17.02; 19.3 21.85; 14.3 12.61; \n",
            "16.8 15.96; 19.9 19.97; 14.5 11.88; \n",
            "18.4 16.48; 23.2 20.71; 15.5 12.68; \n",
            "20.9 17.9; 27.2 22.7; 16.7 13.79; \n",
            "21.1 20.04; 29.0 25.53; 14.8 15.51; \n",
            "17.1 20.45; 23.7 26.29; 14.3 15.16; \n",
            "15.2 17.29; 20.3 22.57; 11.9 12.42; \n",
            "17.2 15.83; 27.1 20.63; 10.3 10.98; \n",
            "20.3 18.29; 28.7 24.49; 13.5 11.99; \n",
            "19.5 20.49; 25.4 26.62; 15.9 14.7; \n",
            "17.5 19.17; 22.3 24.91; 14.9 14.2; \n",
            "14.5 17.54; 19.4 22.77; 11.2 12.92; \n",
            "14.3 15.55; 21.8 20.63; 9.9 10.41; \n",
            "12.4 15.76; 16.7 21.59; 10.8 9.88; \n",
            "9.1 13.44; 13.0 18.05; 6.7 8.67; \n",
            "11.8 10.18; 16.6 13.63; 7.5 5.76; \n",
            "14.6 12.88; 21.8 17.31; 10.6 8.04; \n",
            "15.8 15.33; 22.7 21.15; 11.3 9.92; \n",
            "15.1 16.24; 23.0 22.1; 9.8 10.86; \n",
            "14.8 15.79; 22.4 21.79; 9.6 10.11; \n",
            "15.6 15.4; 22.4 21.3; 10.2 9.79; \n",
            "15.4 15.99; 22.3 21.9; 11.0 10.44; \n",
            "15.2 15.71; 23.5 21.58; 9.6 10.16; \n",
            "13.6 15.58; 17.8 21.53; 10.1 9.9; \n",
            "11.9 13.67; 16.6 18.47; 6.8 9.08; \n",
            "12.5 12.54; 15.1 17.34; 9.3 7.34; \n",
            "12.2 13.03; 17.1 17.27; 9.3 8.4; \n",
            "9.7 12.83; 18.7 17.33; 3.7 7.96; \n",
            "10.4 10.94; 20.7 16.45; 4.0 4.63; \n",
            "10.9 12.06; 20.2 18.45; 4.6 5.36; \n",
            "14.0 12.4; 20.8 18.92; 8.0 5.58; \n",
            "12.5 14.8; 17.5 21.04; 10.5 8.7; \n",
            "9.3 12.86; 12.8 18.18; 7.0 7.76; \n",
            "11.5 9.54; 14.9 13.52; 9.1 5.31; \n",
            "15.9 11.64; 20.5 15.97; 12.0 7.62; \n",
            "14.2 15.54; 18.0 20.84; 13.3 11.01; \n",
            "9.9 13.38; 13.3 17.56; 6.4 9.68; \n",
            "10.8 9.7; 14.4 13.02; 6.2 5.7; \n",
            "12.2 10.91; 16.2 14.62; 9.1 6.59; \n",
            "11.0 12.31; 14.8 16.31; 6.9 8.0; \n",
            "9.2 11.18; 12.6 14.75; 7.2 6.71; \n",
            "8.8 9.27; 11.7 11.85; 6.2 5.79; \n",
            "9.3 9.05; 10.7 11.58; 7.8 5.57; \n",
            "9.2 9.65; 10.3 11.95; 8.6 6.42; \n",
            "7.6 9.41; 8.9 11.48; 6.6 6.34; \n",
            "8.9 7.59; 11.7 8.97; 7.2 4.95; \n",
            "11.3 8.86; 15.3 10.98; 7.7 6.04; \n",
            "10.3 11.19; 12.8 14.56; 9.0 7.52; \n",
            "9.7 9.86; 12.2 12.22; 7.0 6.97; \n",
            "11.5 9.33; 15.6 11.55; 7.7 6.29; \n",
            "10.8 11.14; 14.9 14.32; 7.5 7.6; \n",
            "10.3 10.56; 14.2 13.68; 8.6 6.95; \n",
            "7.8 10.0; 10.4 12.88; 4.9 6.76; \n",
            "9.1 7.71; 12.5 9.62; 7.4 4.62; \n",
            "6.1 9.07; 9.6 11.65; 2.8 5.88; \n",
            "7.7 6.45; 9.2 8.79; 6.7 2.71; \n",
            "7.1 7.79; 7.7 9.85; 6.4 4.99; \n",
            "7.7 7.05; 9.5 8.19; 6.3 4.74; \n",
            "7.8 7.6; 9.0 9.34; 6.7 4.87; \n",
            "8.5 7.66; 10.4 9.11; 7.6 5.18; \n",
            "6.1 8.04; 8.2 9.88; 4.1 5.52; \n",
            "2.9 5.86; 6.5 7.05; -0.6 3.35; \n",
            "5.2 3.11; 6.8 4.91; 3.1 -0.41; \n",
            "6.5 5.42; 8.8 6.81; 4.9 2.85; \n",
            "7.9 6.14; 8.7 7.69; 7.4 3.47; \n",
            "8.4 7.27; 8.9 8.27; 8.1 5.28; \n",
            "8.2 7.54; 10.9 8.42; 6.0 5.83; \n",
            "8.4 7.52; 11.5 9.25; 5.3 5.01; \n",
            "9.1 8.1; 13.1 10.35; 6.0 5.11; \n",
            "10.8 8.64; 13.1 11.32; 8.9 5.36; \n",
            "9.5 9.7; 14.3 11.84; 7.9 7.2; \n",
            "6.6 8.45; 9.4 11.03; 4.9 5.49; \n",
            "4.2 6.09; 6.9 7.74; 2.3 3.39; \n",
            "7.3 4.15; 10.4 5.78; 3.4 1.4; \n",
            "9.9 7.63; 11.3 10.13; 8.2 4.24; \n",
            "7.6 9.54; 10.5 11.69; 4.7 6.84; \n",
            "3.6 7.16; 6.6 9.25; 0.5 4.01; \n",
            "7.5 3.74; 9.9 5.49; 4.8 0.44; \n",
            "11.7 7.81; 14.3 10.22; 8.6 4.59; \n",
            "9.9 11.28; 13.4 14.42; 7.3 7.8; \n",
            "5.3 9.19; 7.3 11.81; 2.7 5.81; \n",
            "5.0 4.81; 6.4 6.16; 4.2 1.98; \n",
            "8.9 4.95; 14.1 6.18; 4.6 2.62; \n",
            "9.5 9.18; 12.2 12.63; 8.0 5.0; \n",
            "4.7 9.11; 8.0 11.6; 3.0 5.99; \n",
            "2.7 4.06; 5.0 5.66; 0.6 1.32; \n",
            "0.7 2.9; 2.4 4.42; 0.5 0.11; \n",
            "0.6 1.4; 1.9 2.49; -1.2 -1.42; \n",
            "0.6 1.34; 2.4 2.8; -1.3 -1.77; \n",
            "0.1 0.94; 1.8 2.15; -1.8 -1.55; \n",
            "-0.6 0.43; 0.8 1.45; -1.5 -2.17; \n",
            "0.1 0.08; 1.2 1.0; -1.0 -2.54; \n",
            "-1.4 0.7; 0.3 1.91; -2.4 -1.96; \n",
            "-0.9 -1.13; 1.2 -0.21; -2.6 -3.77; \n",
            "0.2 -0.63; 1.3 0.69; -1.0 -3.13; \n",
            "-0.2 0.12; 1.3 1.01; -1.5 -1.87; \n",
            "0.1 -0.35; 0.8 0.47; -1.0 -2.43; \n",
            "-0.9 -0.02; 0.2 0.58; -1.5 -1.9; \n",
            "-0.6 -1.2; 0.7 -0.72; -1.5 -3.05; \n",
            "1.7 -0.78; 4.6 -0.13; -1.0 -2.67; \n",
            "3.4 1.42; 6.0 2.92; 1.4 -0.99; \n",
            "4.1 2.64; 5.0 4.05; 3.3 0.46; \n",
            "4.7 3.09; 5.6 3.93; 3.5 1.55; \n",
            "4.3 3.62; 5.9 4.46; 3.1 1.95; \n",
            "1.2 3.23; 3.3 4.07; 0.1 1.4; \n",
            "1.7 0.24; 2.8 0.97; -0.2 -1.77; \n",
            "1.5 1.29; 2.2 2.05; 0.9 -0.55; \n",
            "-0.7 0.97; 1.5 1.16; -1.5 -0.65; \n",
            "-0.8 -0.97; 1.0 -0.43; -2.9 -3.26; \n",
            "1.1 -0.57; 1.9 0.45; 0.6 -3.03; \n",
            "-0.6 1.17; 1.9 1.84; -1.6 -0.65; \n",
            "-1.3 -0.69; -0.1 0.1; -2.4 -3.1; \n",
            "1.8 -1.03; 3.4 -0.34; -0.3 -3.25; \n",
            "-1.7 1.86; 0.6 3.13; -3.3 -0.29; \n",
            "-2.3 -2.14; 1.3 -1.26; -5.4 -4.6; \n",
            "-2.5 -2.03; -1.0 -0.16; -4.0 -5.15; \n",
            "-0.5 -2.33; 1.2 -1.36; -2.4 -4.67; \n",
            "1.4 -0.23; 2.8 1.06; 0.4 -2.66; \n",
            "2.2 1.04; 3.0 2.04; 1.5 -1.03; \n",
            "0.5 1.65; 2.5 2.36; -1.2 -0.08; \n",
            "1.7 -0.12; 2.4 0.98; 0.9 -2.24; \n",
            "-1.3 1.44; 2.0 2.32; -3.3 -0.29; \n",
            "-3.1 -1.9; -0.6 -0.59; -5.7 -4.63; \n",
            "1.8 -3.07; 5.2 -1.63; -1.1 -5.86; \n",
            "4.0 1.73; 5.5 3.85; 1.2 -0.95; \n",
            "1.5 3.27; 4.4 4.6; -0.4 0.98; \n",
            "-1.4 0.78; 0.6 2.2; -1.7 -1.84; \n",
            "-2.1 -1.69; -0.7 -0.74; -3.0 -3.99; \n",
            "-1.2 -1.82; 0.1 -0.89; -2.1 -4.16; \n",
            "0.0 -1.1; 1.4 -0.0; -1.4 -3.37; \n",
            "-2.4 -0.13; 0.5 0.87; -3.1 -2.21; \n",
            "-1.3 -2.94; 0.0 -1.88; -2.1 -5.13; \n",
            "2.8 -0.99; 4.9 0.2; -0.5 -3.03; \n",
            "-0.4 2.84; 3.9 4.8; -2.0 0.23; \n",
            "1.5 -1.12; 2.8 0.64; -0.4 -4.09; \n",
            "-0.2 1.28; 2.8 2.79; -3.7 -0.73; \n",
            "0.0 -0.74; 2.5 0.91; -1.8 -3.53; \n",
            "1.9 -0.13; 4.4 1.4; -0.1 -2.75; \n",
            "2.6 1.49; 3.8 3.06; 1.5 -1.0; \n",
            "1.9 1.86; 2.8 2.9; 0.8 -0.1; \n",
            "1.0 1.29; 2.2 2.12; 0.5 -0.53; \n",
            "1.0 0.57; 2.7 1.33; -0.4 -1.45; \n",
            "1.4 0.78; 2.1 1.88; 0.5 -1.43; \n",
            "1.8 1.01; 2.6 1.91; 1.0 -0.84; \n",
            "4.1 1.34; 7.0 1.84; 1.4 -0.29; \n",
            "4.9 3.41; 8.8 4.96; 2.0 0.99; \n",
            "3.8 4.1; 8.7 6.1; 0.5 1.38; \n",
            "-0.9 3.13; 1.7 5.56; -2.1 -0.08; \n",
            "-2.1 -1.38; 0.8 -0.25; -4.2 -3.92; \n",
            "-0.1 -1.85; 3.5 -0.22; -2.1 -4.9; \n",
            "-1.5 0.03; 1.7 1.98; -3.6 -3.03; \n",
            "-5.8 -1.66; -3.4 0.13; -8.3 -4.59; \n",
            "-6.5 -5.6; -2.9 -4.07; -8.6 -8.69; \n",
            "-2.2 -5.34; 1.7 -3.03; -5.8 -9.09; \n",
            "-3.1 -0.84; -1.1 2.23; -5.2 -4.94; \n",
            "-5.9 -2.61; -2.3 -0.4; -9.7 -5.94; \n",
            "-1.3 -5.46; 2.7 -2.62; -4.7 -9.39; \n",
            "-3.0 -0.37; 2.2 2.54; -6.8 -3.93; \n",
            "-1.3 -2.85; 3.8 0.44; -5.6 -7.21; \n",
            "2.6 -0.86; 7.1 3.11; -1.7 -5.11; \n",
            "2.0 2.39; 4.6 5.74; 0.1 -1.1; \n",
            "0.7 1.13; 3.7 3.42; -1.0 -1.85; \n",
            "-1.8 0.14; 1.8 2.67; -3.7 -2.84; \n",
            "-0.8 -2.38; 1.8 0.21; -3.3 -5.62; \n",
            "-1.7 -0.76; 0.7 1.51; -2.6 -3.63; \n",
            "-1.5 -2.13; 1.1 -0.11; -3.5 -4.79; \n",
            "-0.6 -1.43; 2.6 0.67; -2.2 -4.28; \n",
            "-4.0 -0.68; -1.6 1.61; -6.3 -3.53; \n",
            "-2.0 -3.87; 1.8 -1.78; -6.1 -7.11; \n",
            "-1.8 -1.28; 0.3 1.78; -4.2 -5.01; \n",
            "0.3 -1.51; 2.9 0.33; -2.3 -4.44; \n",
            "-2.1 0.45; 2.4 2.63; -6.5 -2.58; \n",
            "-1.6 -2.26; 3.4 0.38; -4.2 -6.06; \n",
            "-1.8 -1.43; 2.2 1.53; -5.5 -5.2; \n",
            "-0.7 -1.56; 1.7 1.19; -2.5 -5.25; \n",
            "2.1 -0.5; 5.2 1.87; -0.1 -3.64; \n",
            "2.0 1.85; 5.0 4.21; 0.0 -1.01; \n",
            "0.3 1.25; 2.3 3.49; -2.6 -1.59; \n",
            "2.9 -0.06; 6.0 2.04; 0.5 -2.76; \n",
            "3.7 2.55; 7.1 5.08; 2.5 -0.34; \n",
            "1.0 2.86; 3.9 4.91; -0.8 0.27; \n",
            "-0.4 0.15; 1.5 2.2; -2.2 -2.73; \n",
            "0.4 -0.72; 3.6 1.01; -1.1 -3.09; \n",
            "0.3 0.13; 3.2 2.04; -2.5 -2.58; \n",
            "0.6 0.28; 5.1 2.24; -3.5 -2.8; \n",
            "1.8 0.62; 7.3 3.5; -2.5 -3.02; \n",
            "3.7 1.73; 9.7 4.82; -1.5 -2.02; \n",
            "7.4 3.65; 13.4 7.35; 2.0 -0.66; \n",
            "8.0 7.22; 14.8 11.72; 1.0 2.64; \n",
            "10.9 7.59; 16.0 12.39; 5.7 2.45; \n",
            "10.1 9.97; 13.7 14.55; 7.8 5.61; \n",
            "7.5 8.82; 13.5 12.51; 1.9 5.24; \n",
            "9.2 6.8; 15.2 10.91; 5.4 1.97; \n",
            "11.0 8.72; 15.5 13.13; 8.6 4.26; \n",
            "9.1 10.06; 15.2 14.18; 2.5 6.11; \n",
            "9.7 8.68; 13.7 13.13; 7.2 3.59; \n",
            "6.0 9.47; 11.4 13.49; 0.3 5.38; \n",
            "6.4 6.27; 9.8 10.2; 5.0 1.13; \n",
            "9.6 6.7; 14.3 10.03; 5.8 2.85; \n",
            "9.3 10.02; 13.8 14.16; 5.7 5.44; \n",
            "7.9 9.05; 11.6 12.71; 5.5 4.85; \n",
            "9.0 7.85; 14.8 11.08; 3.6 4.18; \n",
            "10.4 9.28; 15.4 13.85; 4.7 4.24; \n",
            "12.8 10.73; 18.3 15.1; 7.6 5.96; \n",
            "11.2 12.64; 15.5 17.77; 8.0 7.51; \n",
            "7.4 10.6; 11.5 14.34; 4.0 6.6; \n",
            "8.0 7.17; 14.8 10.25; 1.4 3.04; \n",
            "12.4 8.73; 18.5 13.37; 6.9 3.21; \n",
            "14.9 12.79; 19.7 18.05; 9.8 7.5; \n",
            "15.0 14.44; 20.6 19.48; 12.3 9.52; \n",
            "11.3 14.22; 16.6 19.24; 5.7 9.86; \n",
            "12.4 11.33; 18.8 15.83; 6.7 6.3; \n",
            "14.3 12.83; 17.8 18.26; 10.6 7.33; \n",
            "14.2 14.28; 16.8 19.07; 11.7 9.58; \n",
            "7.9 13.5; 15.3 17.25; 6.9 9.49; \n",
            "6.7 7.87; 8.4 11.51; 5.6 3.64; \n",
            "7.6 7.21; 9.0 9.69; 6.8 3.98; \n",
            "7.1 8.18; 8.1 10.53; 6.2 5.04; \n",
            "9.3 7.67; 13.8 9.67; 5.9 4.49; \n",
            "10.3 9.68; 14.4 12.85; 6.9 5.83; \n",
            "9.1 10.21; 12.1 13.76; 6.8 6.56; \n",
            "9.5 9.03; 13.8 11.91; 5.5 5.68; \n",
            "8.3 9.71; 11.4 13.02; 5.8 5.65; \n",
            "9.0 8.29; 11.5 10.83; 8.1 4.71; \n",
            "9.7 8.49; 12.5 10.81; 7.2 5.66; \n",
            "8.6 9.21; 11.8 11.65; 7.0 6.25; \n",
            "8.4 8.22; 12.6 10.41; 5.0 5.33; \n",
            "9.4 8.43; 13.0 11.31; 6.9 4.87; \n",
            "10.0 9.31; 14.1 12.4; 6.0 5.86; \n",
            "11.1 9.99; 16.8 13.31; 5.0 6.07; \n",
            "9.4 11.13; 12.0 15.36; 7.4 6.47; \n",
            "10.8 9.04; 16.6 11.73; 3.7 5.74; \n",
            "10.4 10.98; 14.6 15.28; 8.9 6.01; \n",
            "8.0 10.35; 11.1 13.87; 7.0 6.56; \n",
            "10.1 7.94; 15.2 10.44; 6.3 4.53; \n",
            "12.1 10.1; 17.8 13.84; 7.5 6.01; \n",
            "13.8 12.26; 18.4 16.88; 9.0 7.67; \n",
            "10.3 13.45; 16.4 18.11; 6.3 8.92; \n",
            "10.8 10.37; 16.1 14.75; 5.3 5.79; \n",
            "10.2 11.17; 14.4 15.64; 8.7 6.13; \n",
            "11.0 10.23; 13.9 13.92; 9.0 6.37; \n",
            "12.7 10.78; 18.4 14.23; 8.0 7.03; \n",
            "12.5 12.62; 15.8 17.02; 9.5 8.09; \n",
            "15.0 12.22; 19.8 16.06; 10.3 8.44; \n",
            "12.2 14.55; 17.8 19.34; 10.1 10.12; \n",
            "8.8 12.25; 10.2 16.71; 7.4 7.89; \n",
            "12.9 8.94; 17.4 11.21; 7.0 5.62; \n",
            "15.9 12.83; 20.7 16.97; 10.8 8.35; \n",
            "14.6 15.47; 19.5 20.26; 9.4 10.9; \n",
            "17.4 14.34; 22.4 18.81; 11.0 9.66; \n",
            "17.5 16.74; 23.3 21.84; 12.9 12.0; \n",
            "21.2 16.98; 28.3 22.29; 14.0 12.06; \n",
            "22.3 20.07; 28.3 25.92; 16.6 14.71; \n",
            "22.9 20.76; 28.4 26.46; 19.6 15.63; \n",
            "13.1 20.75; 25.1 26.11; 10.4 16.19; \n",
            "12.1 14.13; 16.4 20.15; 5.9 8.38; \n",
            "11.3 13.53; 15.3 18.32; 9.5 8.02; \n",
            "14.6 12.4; 19.9 16.72; 12.0 7.58; \n",
            "16.8 15.24; 21.7 20.17; 12.7 10.48; \n",
            "17.3 16.97; 21.6 22.18; 11.9 12.1; \n",
            "17.9 17.18; 22.5 22.63; 12.7 12.27; \n",
            "17.5 17.68; 21.4 23.12; 13.9 12.7; \n",
            "16.8 17.48; 21.6 22.66; 13.2 12.56; \n",
            "15.1 16.82; 19.4 21.66; 11.7 11.85; \n",
            "14.7 14.84; 18.4 19.02; 11.0 10.39; \n",
            "13.7 14.55; 18.5 18.38; 10.5 10.34; \n",
            "18.2 14.14; 23.8 18.29; 13.0 9.68; \n",
            "15.8 18.16; 20.0 23.41; 11.3 13.2; \n",
            "16.0 16.06; 21.9 20.74; 10.1 11.24; \n",
            "18.7 16.4; 23.9 21.54; 15.1 11.16; \n",
            "17.3 18.46; 21.4 23.8; 15.0 13.68; \n",
            "16.9 17.16; 20.0 21.95; 16.2 12.74; \n",
            "17.7 16.47; 22.7 20.61; 13.5 12.7; \n",
            "17.8 17.36; 24.2 22.14; 13.5 12.94; \n",
            "14.6 17.65; 18.9 22.82; 13.5 12.91; \n",
            "13.8 15.04; 17.7 19.42; 11.8 10.9; \n",
            "14.5 14.2; 16.8 18.05; 12.2 10.14; \n",
            "15.8 14.66; 18.2 18.14; 14.4 11.0; \n",
            "15.7 15.6; 20.3 19.45; 11.4 11.97; \n",
            "16.2 15.82; 20.9 20.11; 14.1 11.56; \n",
            "18.5 16.26; 24.0 20.73; 13.9 12.25; \n",
            "19.1 18.15; 25.2 23.22; 11.4 13.69; \n",
            "16.0 18.73; 22.7 24.18; 13.1 13.45; \n",
            "16.0 16.35; 20.8 21.44; 13.3 11.4; \n",
            "19.9 16.07; 27.6 20.66; 12.9 11.75; \n",
            "21.7 19.55; 27.1 25.31; 15.1 14.21; \n",
            "22.7 20.76; 27.7 26.42; 17.0 15.59; \n",
            "22.3 21.02; 27.6 26.48; 18.1 16.22; \n",
            "23.5 20.86; 27.8 26.34; 19.5 16.09; \n",
            "23.9 21.79; 30.5 27.13; 17.2 17.11; \n",
            "26.3 22.23; 32.1 27.78; 19.3 16.97; \n",
            "26.9 23.54; 33.9 28.9; 19.8 18.45; \n",
            "26.2 23.99; 32.0 29.41; 22.3 18.74; \n",
            "19.5 23.61; 24.1 28.95; 18.1 18.86; \n",
            "18.6 19.58; 24.7 24.4; 13.6 14.76; \n",
            "21.8 19.38; 27.1 24.52; 15.0 13.89; \n",
            "23.4 21.74; 28.9 27.1; 15.9 16.17; \n",
            "21.5 22.59; 26.3 28.06; 18.0 16.93; \n",
            "19.7 21.1; 24.9 26.34; 14.5 16.09; \n",
            "18.0 20.04; 23.5 25.35; 14.5 14.55; \n",
            "15.3 18.96; 18.7 24.28; 13.0 13.51; \n",
            "16.1 16.7; 20.8 21.25; 11.3 11.59; \n",
            "20.0 17.17; 24.4 21.87; 14.3 11.79; \n",
            "21.2 19.84; 27.8 24.96; 15.3 14.8; \n",
            "17.3 20.64; 24.9 26.39; 13.7 15.26; \n",
            "16.4 18.04; 20.7 23.73; 14.0 12.59; \n",
            "16.7 17.12; 22.5 22.02; 11.7 12.23; \n",
            "19.1 17.44; 25.5 22.72; 11.9 12.06; \n",
            "24.4 19.35; 29.4 25.04; 18.6 13.6; \n",
            "24.3 22.33; 31.1 27.84; 17.0 17.39; \n",
            "26.1 22.19; 32.4 27.97; 17.9 17.05; \n",
            "26.5 23.45; 32.8 29.11; 19.0 18.16; \n",
            "22.1 23.87; 29.2 29.49; 19.3 18.49; \n",
            "19.6 21.29; 24.2 26.9; 16.7 15.99; \n",
            "21.6 19.54; 26.6 24.44; 17.3 14.48; \n",
            "22.4 20.89; 27.6 26.07; 18.3 15.85; \n",
            "20.2 21.4; 26.5 26.65; 19.0 16.53; \n",
            "22.1 20.23; 27.3 25.64; 17.0 15.35; \n",
            "21.0 21.6; 25.6 26.92; 18.1 16.55; \n",
            "22.6 20.73; 29.3 26.06; 15.6 15.87; \n",
            "23.9 22.03; 29.8 27.61; 18.4 16.53; \n",
            "21.0 22.67; 25.3 28.15; 18.3 17.47; \n",
            "17.1 20.48; 22.4 25.46; 13.7 15.82; \n",
            "19.0 17.75; 23.4 22.53; 14.1 12.85; \n",
            "22.2 19.38; 27.5 24.35; 16.9 14.36; \n",
            "20.1 21.54; 25.3 26.91; 18.5 16.36; \n",
            "16.8 19.86; 19.3 24.98; 15.1 15.32; \n",
            "17.8 17.18; 21.8 21.15; 14.6 12.97; \n",
            "16.1 18.09; 20.2 22.71; 13.4 13.63; \n",
            "15.5 16.95; 20.5 21.52; 10.4 12.26; \n",
            "18.4 16.55; 23.6 21.2; 13.7 11.34; \n",
            "21.5 18.51; 26.6 23.49; 15.5 13.7; \n",
            "22.2 20.45; 29.1 25.81; 14.7 15.63; \n",
            "24.2 21.23; 31.4 26.97; 16.5 15.85; \n",
            "24.6 22.7; 31.8 28.47; 16.5 17.15; \n",
            "24.1 22.86; 31.6 28.57; 16.4 17.26; \n",
            "19.7 22.73; 26.4 28.51; 15.4 17.01; \n",
            "16.1 19.87; 20.0 25.51; 14.3 14.15; \n",
            "16.4 16.62; 21.6 21.1; 11.5 11.87; \n",
            "17.3 17.31; 22.7 22.36; 12.1 11.78; \n",
            "16.5 18.29; 22.9 23.72; 10.0 12.54; \n",
            "17.7 17.71; 24.4 23.33; 13.8 11.6; \n",
            "17.4 18.44; 22.5 24.35; 11.8 12.75; \n",
            "18.2 18.2; 24.8 23.8; 13.0 12.39; \n",
            "19.9 18.71; 26.6 24.63; 14.1 12.81; \n",
            "20.8 19.89; 26.9 25.81; 16.2 14.17; \n",
            "20.9 20.16; 28.2 25.89; 14.4 14.85; \n",
            "21.8 20.4; 28.4 26.3; 14.1 14.84; \n",
            "22.6 21.0; 28.5 26.94; 15.1 15.18; \n",
            "22.9 21.4; 28.8 27.14; 17.6 15.78; \n",
            "21.3 21.62; 25.6 27.35; 19.2 16.17; \n",
            "18.4 20.36; 20.4 25.52; 16.3 15.65; \n",
            "14.4 18.05; 16.3 22.3; 13.1 13.74; \n",
            "15.0 15.01; 18.9 18.41; 12.4 10.93; \n",
            "14.0 16.01; 20.6 20.12; 10.5 11.34; \n",
            "14.3 15.54; 20.7 20.32; 9.5 10.24; \n",
            "16.8 15.68; 22.2 20.7; 13.2 10.23; \n",
            "17.1 17.29; 22.3 22.48; 11.5 12.36; \n",
            "19.4 17.54; 24.8 22.83; 14.6 12.31; \n",
            "21.3 19.29; 28.4 24.84; 14.5 14.16; \n",
            "21.9 20.73; 28.2 26.62; 14.8 15.31; \n",
            "18.1 20.83; 24.9 26.53; 13.7 15.54; \n",
            "17.4 18.18; 25.0 23.77; 11.5 12.88; \n",
            "16.4 17.8; 19.9 23.54; 13.5 12.0; \n",
            "16.5 16.6; 21.9 21.28; 12.3 11.81; \n",
            "18.0 16.91; 23.9 22.09; 13.4 11.57; \n",
            "19.0 18.18; 26.3 23.57; 13.3 13.01; \n",
            "20.4 19.21; 27.6 25.18; 15.4 13.56; \n",
            "18.3 20.17; 23.3 26.26; 14.6 14.66; \n",
            "15.6 18.46; 21.2 23.97; 11.7 13.24; \n",
            "14.3 16.32; 19.4 21.46; 10.5 10.9; \n",
            "14.0 15.23; 19.5 20.14; 10.0 10.09; \n",
            "15.2 14.93; 21.4 19.87; 10.3 9.65; \n",
            "15.4 16.02; 21.5 21.27; 10.1 10.74; \n",
            "15.0 16.11; 21.8 21.55; 9.2 10.64; \n",
            "15.8 15.88; 25.2 21.54; 9.5 10.1; \n",
            "14.5 16.99; 19.9 23.58; 12.1 10.49; \n",
            "12.7 15.38; 16.1 20.86; 10.9 10.07; \n",
            "14.5 13.24; 20.6 17.49; 9.4 8.79; \n",
            "13.9 15.03; 21.4 20.31; 8.6 9.76; \n",
            "14.9 14.76; 23.3 20.5; 9.4 9.08; \n",
            "15.8 15.64; 24.5 21.86; 9.9 9.76; \n",
            "17.2 16.45; 23.8 22.89; 11.6 10.38; \n",
            "17.5 17.28; 22.9 23.33; 13.0 11.58; \n",
            "18.8 17.23; 25.0 23.01; 15.6 11.96; \n",
            "19.6 18.23; 25.0 24.11; 14.6 13.16; \n",
            "16.0 18.9; 22.1 24.52; 13.3 13.87; \n",
            "15.1 16.07; 23.4 21.46; 9.7 11.23; \n",
            "16.4 15.79; 25.6 21.57; 10.2 10.02; \n",
            "17.4 17.18; 26.9 23.53; 11.6 10.91; \n",
            "18.4 18.08; 26.1 24.65; 13.1 11.75; \n",
            "18.3 18.52; 24.1 24.84; 15.0 12.65; \n",
            "18.0 18.22; 22.4 24.07; 14.8 13.09; \n",
            "15.2 17.96; 18.9 23.54; 13.6 13.03; \n",
            "12.4 15.62; 19.7 20.5; 7.6 11.11; \n",
            "12.8 13.69; 20.4 19.0; 7.7 7.98; \n",
            "11.5 14.1; 14.4 19.67; 10.6 8.34; \n",
            "9.6 12.17; 13.3 16.07; 7.8 7.94; \n",
            "7.6 10.4; 14.4 13.94; 3.3 6.03; \n",
            "8.3 9.12; 12.8 13.56; 6.2 3.64; \n",
            "6.9 9.57; 13.2 13.7; 1.5 5.01; \n",
            "7.0 8.31; 15.0 12.87; 1.8 2.88; \n",
            "7.8 8.48; 17.8 13.62; 1.5 2.6; \n",
            "9.2 9.31; 18.6 15.39; 2.9 2.77; \n",
            "11.4 10.18; 15.9 16.79; 9.0 3.69; \n",
            "7.8 11.61; 13.8 16.85; 2.6 6.91; \n",
            "6.8 8.09; 12.3 12.95; 3.1 2.64; \n",
            "6.8 7.2; 12.1 11.79; 2.5 2.42; \n",
            "7.2 7.17; 11.4 12.01; 4.0 2.09; \n",
            "5.5 7.3; 10.9 11.35; 1.9 2.96; \n",
            "6.0 5.73; 13.0 9.73; 0.9 1.04; \n",
            "7.3 6.39; 12.5 11.29; 3.6 0.92; \n",
            "7.0 7.63; 15.4 12.18; 1.9 2.93; \n",
            "6.1 7.5; 13.8 13.25; 1.6 1.48; \n",
            "6.1 6.71; 13.5 11.76; 1.3 1.25; \n",
            "6.9 6.5; 14.6 11.81; 1.7 1.0; \n",
            "8.5 7.28; 15.3 12.86; 3.6 1.69; \n",
            "9.7 8.8; 13.9 14.36; 7.1 3.42; \n",
            "8.8 9.31; 14.8 13.89; 2.9 5.08; \n",
            "12.9 8.61; 15.9 13.62; 10.2 3.54; \n",
            "14.8 12.12; 18.4 16.77; 12.3 8.15; \n",
            "11.5 13.52; 14.0 18.19; 10.1 9.66; \n",
            "9.8 10.26; 11.6 13.55; 8.5 6.89; \n",
            "7.5 9.08; 9.2 11.59; 6.8 6.14; \n",
            "4.7 6.97; 8.8 8.92; 0.9 4.14; \n",
            "2.0 5.12; 4.8 7.66; 0.0 1.2; \n",
            "2.2 2.55; 4.7 4.55; 0.2 -0.97; \n",
            "3.7 3.11; 4.6 4.78; 2.9 0.07; \n",
            "3.5 4.26; 4.4 5.49; 2.9 1.51; \n",
            "5.7 4.09; 7.0 5.04; 3.7 1.37; \n",
            "3.9 5.89; 6.7 7.42; 2.0 3.18; \n",
            "2.1 3.85; 4.5 5.33; 1.0 1.05; \n",
            "1.2 2.14; 2.5 3.47; -0.2 -0.51; \n",
            "-0.8 1.35; 2.2 2.31; -2.9 -0.95; \n",
            "-2.2 -0.85; 0.0 0.6; -3.4 -3.85; \n",
            "-3.9 -2.04; -1.5 -1.02; -6.0 -4.61; \n",
            "-3.6 -3.55; -2.2 -2.26; -4.9 -6.44; \n",
            "-0.3 -2.77; 1.2 -1.87; -2.6 -5.33; \n",
            "2.3 0.51; 4.7 1.85; 0.6 -2.16; \n",
            "3.1 2.2; 7.1 3.82; 0.6 -0.38; \n",
            "4.0 2.61; 7.4 4.9; 2.4 -0.24; \n",
            "-0.3 3.2; 2.6 5.37; -2.3 0.72; \n",
            "-4.1 -0.99; -1.6 0.63; -5.3 -3.69; \n",
            "-5.4 -4.44; 0.4 -2.82; -9.9 -7.27; \n",
            "-3.7 -5.27; 0.2 -2.19; -7.2 -9.45; \n",
            "2.0 -3.37; 6.0 -0.67; -0.8 -6.86; \n",
            "5.3 2.04; 6.8 4.84; 3.0 -0.88; \n",
            "3.9 4.59; 6.6 6.67; 2.0 2.13; \n",
            "5.5 3.19; 7.3 5.31; 2.6 0.37; \n",
            "3.0 4.87; 6.0 7.45; 1.1 2.03; \n",
            "-1.2 1.97; 1.7 4.09; -2.8 -0.77; \n",
            "-0.3 -2.0; 0.8 -0.26; -1.3 -4.8; \n",
            "0.6 -0.51; 2.0 0.61; -0.8 -2.57; \n",
            "0.1 0.11; 1.3 1.24; -0.6 -2.12; \n",
            "4.8 -0.19; 8.2 0.76; 1.3 -2.37; \n",
            "6.3 4.69; 7.2 7.1; 5.6 1.8; \n",
            "4.2 5.41; 5.6 6.67; 3.5 3.56; \n",
            "1.6 3.41; 3.7 4.46; 0.0 1.42; \n",
            "4.3 1.02; 7.7 2.15; 1.1 -1.38; \n",
            "4.3 3.88; 7.5 5.88; 3.3 1.12; \n",
            "2.2 3.15; 3.9 4.71; 0.8 0.84; \n",
            "2.0 1.45; 5.4 2.33; -1.0 -0.51; \n",
            "2.3 1.68; 5.4 3.3; -1.1 -1.11; \n",
            "-1.8 2.38; 1.0 4.3; -4.6 -0.74; \n",
            "0.2 -1.76; 2.5 0.02; -1.2 -5.22; \n",
            "-0.8 0.7; 0.0 2.33; -1.4 -1.96; \n",
            "0.4 -0.66; 1.5 -0.18; -1.0 -2.91; \n",
            "4.2 0.76; 9.1 1.93; 1.5 -1.8; \n",
            "1.4 3.98; 5.7 6.78; 0.0 0.77; \n",
            "3.2 0.75; 4.9 2.8; 2.2 -2.17; \n",
            "2.6 3.0; 3.8 4.79; 1.8 0.89; \n",
            "1.0 1.89; 2.0 3.2; 0.6 -0.14; \n",
            "0.4 0.35; 1.0 1.15; -0.1 -1.56; \n",
            "1.2 -0.26; 1.8 0.43; 0.6 -1.82; \n",
            "2.1 0.64; 4.3 1.17; 0.4 -0.68; \n",
            "2.0 1.61; 4.1 2.5; -0.6 -0.3; \n",
            "5.8 1.74; 9.3 3.0; 3.4 -0.79; \n",
            "1.9 5.18; 5.6 7.38; 0.3 2.59; \n",
            "-0.2 0.99; 2.2 2.49; -3.5 -1.71; \n",
            "1.7 -0.13; 4.8 1.47; 0.8 -3.09; \n",
            "2.7 1.43; 6.2 3.01; 0.0 -0.99; \n",
            "4.7 2.29; 10.0 4.09; 1.0 -0.58; \n",
            "5.6 4.18; 9.9 7.08; 2.5 0.82; \n",
            "2.7 4.98; 6.5 7.81; 0.8 1.89; \n",
            "-2.5 2.06; 0.8 4.26; -4.2 -0.93; \n",
            "-5.0 -2.47; -1.0 -0.32; -7.6 -5.96; \n",
            "-3.5 -4.55; -0.2 -1.66; -5.8 -8.52; \n",
            "-4.8 -2.88; -2.0 -0.39; -7.4 -6.11; \n",
            "-5.5 -4.47; -3.7 -2.23; -6.2 -7.87; \n",
            "-5.8 -4.71; -4.4 -3.06; -6.7 -7.65; \n",
            "-5.8 -4.67; -4.7 -3.01; -6.6 -7.88; \n",
            "-4.4 -4.67; -2.0 -2.93; -6.0 -7.95; \n",
            "-4.9 -3.56; -3.0 -1.33; -5.8 -6.57; \n",
            "-3.6 -4.66; -1.6 -3.1; -5.3 -7.08; \n",
            "-4.5 -3.14; -2.5 -1.41; -5.7 -5.55; \n",
            "-5.6 -4.46; -3.4 -2.93; -8.2 -6.96; \n",
            "-3.9 -5.24; -1.8 -3.59; -4.7 -8.19; \n",
            "-4.7 -3.75; -2.3 -2.26; -5.9 -5.97; \n",
            "-4.9 -4.77; -4.2 -3.6; -5.5 -7.09; \n",
            "-5.5 -4.74; -1.7 -4.2; -7.5 -6.68; \n",
            "-9.2 -5.35; -5.4 -3.54; -11.8 -8.32; \n",
            "-5.5 -9.14; -2.5 -7.33; -9.6 -12.86; \n",
            "-1.3 -4.14; 0.3 -1.31; -3.6 -7.56; \n",
            "1.9 -0.89; 3.6 1.01; -0.8 -3.3; \n",
            "-0.1 1.61; 2.8 3.34; -2.5 -0.71; \n",
            "-1.6 -0.96; -0.4 0.88; -2.2 -3.66; \n",
            "-3.8 -1.88; -0.4 -0.67; -7.2 -3.96; \n",
            "-2.8 -3.98; 1.5 -1.92; -7.0 -7.3; \n",
            "-2.0 -2.52; 1.2 0.23; -3.6 -6.33; \n",
            "-4.4 -2.33; -2.9 -0.34; -5.6 -5.05; \n",
            "-4.5 -4.68; -2.9 -3.56; -6.0 -7.17; \n",
            "1.8 -3.96; 7.4 -2.53; -2.9 -6.79; \n",
            "2.2 2.28; 5.7 5.75; 0.0 -1.69; \n",
            "0.1 1.58; 1.3 4.06; -0.5 -1.3; \n",
            "3.3 -0.52; 5.1 1.07; 0.0 -2.49; \n",
            "0.5 2.98; 3.8 4.92; -1.2 0.49; \n",
            "6.4 -0.43; 10.8 1.36; 1.8 -3.39; \n",
            "4.9 5.69; 8.8 9.16; 0.9 2.25; \n",
            "8.0 3.42; 10.8 5.81; 5.9 0.46; \n",
            "10.5 6.65; 13.3 8.9; 6.9 4.19; \n",
            "9.9 8.92; 13.4 11.83; 7.0 6.01; \n",
            "4.5 8.49; 9.1 11.54; 3.2 5.22; \n",
            "7.1 3.37; 10.4 5.51; 5.0 0.33; \n",
            "6.9 6.56; 8.9 9.07; 5.8 3.76; \n",
            "7.2 6.1; 9.7 7.72; 5.5 3.59; \n",
            "5.7 6.58; 8.0 8.78; 3.7 3.76; \n",
            "3.3 5.21; 6.7 6.91; -0.6 2.61; \n",
            "6.0 3.44; 10.5 5.69; 2.7 -0.01; \n",
            "7.8 6.49; 11.8 9.49; 4.0 2.76; \n",
            "7.7 7.87; 12.5 10.98; 3.0 3.99; \n",
            "11.1 7.45; 15.0 10.6; 8.0 3.33; \n",
            "10.9 10.49; 14.4 14.16; 8.0 6.97; \n",
            "13.1 10.13; 19.0 13.47; 10.8 6.61; \n",
            "8.6 12.45; 10.8 16.91; 7.1 8.62; \n",
            "7.4 7.85; 10.5 10.2; 5.5 4.85; \n",
            "8.4 6.83; 13.5 9.16; 3.4 3.94; \n",
            "7.7 8.39; 11.8 11.9; 5.5 4.21; \n",
            "10.2 7.59; 17.1 10.66; 4.5 3.87; \n",
            "10.3 10.32; 15.5 14.76; 4.5 5.64; \n",
            "9.2 10.38; 12.3 14.8; 8.6 5.59; \n",
            "7.7 9.11; 11.0 12.1; 5.0 5.72; \n",
            "7.5 7.92; 11.5 11.05; 3.8 3.93; \n",
            "9.1 7.85; 12.7 11.08; 6.8 3.71; \n",
            "9.1 9.1; 13.8 12.34; 6.0 5.44; \n",
            "8.7 8.85; 14.3 12.33; 4.4 5.07; \n",
            "7.1 8.79; 13.1 12.62; 2.7 4.37; \n",
            "7.5 7.52; 13.9 11.61; 3.5 2.73; \n",
            "9.0 7.89; 14.0 12.27; 4.0 3.12; \n",
            "9.6 9.39; 12.5 13.73; 7.5 4.53; \n",
            "7.5 9.39; 9.8 12.73; 4.8 5.75; \n",
            "6.3 7.22; 9.2 9.75; 4.9 3.85; \n",
            "5.3 6.21; 9.1 8.76; 3.1 2.93; \n",
            "2.3 5.64; 6.3 8.37; 0.2 1.98; \n",
            "0.4 2.65; 3.3 5.26; -1.7 -1.14; \n",
            "2.3 1.14; 6.5 3.38; -0.3 -2.29; \n",
            "1.8 2.96; 7.0 5.84; -1.6 -0.91; \n",
            "6.6 2.34; 10.8 5.5; 2.2 -1.89; \n",
            "6.7 6.93; 10.5 10.71; 4.0 2.88; \n",
            "3.0 6.32; 7.6 9.36; -0.6 2.91; \n",
            "6.5 2.86; 13.2 5.74; 2.7 -1.16; \n",
            "8.0 6.62; 11.4 10.93; 4.4 2.24; \n",
            "8.7 7.41; 15.3 10.84; 3.7 3.74; \n",
            "9.4 7.92; 14.4 12.2; 6.3 3.48; \n",
            "6.0 8.57; 9.1 12.5; 3.2 4.81; \n",
            "3.8 5.28; 8.4 8.0; 1.1 1.82; \n",
            "4.7 3.72; 10.8 6.98; -1.1 -0.2; \n",
            "7.4 5.19; 10.0 9.37; 6.5 0.14; \n",
            "7.2 7.03; 9.9 9.78; 4.1 3.92; \n",
            "5.0 6.76; 9.2 9.63; 1.6 3.37; \n",
            "5.0 4.91; 10.4 7.9; 0.4 0.91; \n",
            "8.0 5.57; 13.5 9.2; 3.7 1.05; \n",
            "7.6 8.16; 12.8 12.66; 3.5 3.47; \n",
            "5.0 7.57; 8.4 11.36; 1.4 3.18; \n",
            "6.6 4.77; 11.4 7.54; 1.5 0.79; \n",
            "9.0 6.66; 16.9 10.27; 2.5 2.39; \n",
            "9.2 9.26; 15.2 14.69; 4.0 3.55; \n",
            "11.6 9.43; 20.0 14.17; 3.8 4.35; \n",
            "13.2 11.68; 19.2 17.54; 8.7 5.7; \n",
            "13.8 12.67; 18.9 18.05; 11.0 7.73; \n",
            "13.0 13.11; 15.2 18.3; 11.3 8.51; \n",
            "12.4 12.08; 15.4 16.07; 11.1 8.36; \n",
            "12.7 11.5; 17.5 15.04; 8.8 8.08; \n",
            "11.2 12.1; 15.6 16.27; 6.4 7.96; \n",
            "15.0 11.09; 21.9 15.14; 8.6 6.68; \n",
            "13.4 14.77; 21.4 20.11; 8.6 9.42; \n",
            "15.1 13.52; 20.9 18.97; 9.5 8.2; \n",
            "12.4 15.06; 17.9 20.34; 11.2 9.8; \n",
            "13.4 12.62; 18.7 17.29; 10.0 8.12; \n",
            "15.0 13.75; 21.5 18.48; 8.7 9.16; \n",
            "16.5 15.5; 21.9 21.03; 11.0 10.07; \n",
            "15.7 16.48; 19.8 22.07; 12.8 11.35; \n",
            "8.8 15.19; 14.7 19.89; 5.7 10.85; \n",
            "10.5 9.42; 15.0 13.47; 5.7 4.55; \n",
            "13.5 11.52; 20.2 15.83; 6.4 6.44; \n",
            "17.0 14.25; 23.4 19.82; 12.3 8.34; \n",
            "17.0 16.86; 24.2 22.54; 12.6 11.59; \n",
            "20.1 16.82; 25.8 22.63; 15.0 11.6; \n",
            "19.5 18.95; 23.4 24.81; 15.9 14.03; \n",
            "20.7 18.46; 26.4 23.9; 17.4 13.85; \n",
            "19.9 19.56; 24.8 25.19; 16.0 14.76; \n",
            "18.7 18.82; 24.5 23.89; 14.0 14.27; \n",
            "19.5 17.86; 26.0 23.02; 12.5 13.03; \n",
            "20.2 18.86; 26.7 24.32; 12.8 13.6; \n",
            "20.6 19.75; 27.7 25.47; 13.3 14.02; \n",
            "20.5 20.31; 26.4 26.09; 12.7 14.43; \n",
            "20.9 20.27; 25.9 26.03; 15.3 14.34; \n",
            "19.5 20.47; 25.9 25.97; 11.1 14.98; \n",
            "15.7 19.91; 24.0 25.72; 11.3 13.62; \n",
            "12.6 17.27; 15.7 23.24; 11.9 10.84; \n",
            "14.2 14.01; 19.7 18.13; 8.6 9.18; \n",
            "13.2 15.52; 15.3 20.61; 11.8 9.66; \n",
            "16.1 14.26; 21.7 18.24; 11.5 9.65; \n",
            "17.0 16.69; 23.0 21.98; 10.9 11.32; \n",
            "19.1 17.37; 25.9 23.02; 11.6 11.91; \n",
            "20.7 19.21; 26.9 25.31; 13.0 13.23; \n",
            "19.5 19.95; 25.2 25.89; 13.7 14.25; \n",
            "19.5 18.98; 24.4 24.6; 13.4 13.49; \n",
            "17.7 18.92; 23.2 24.2; 12.5 13.43; \n",
            "18.2 17.63; 24.5 22.88; 11.1 12.42; \n",
            "18.3 18.31; 23.7 23.78; 13.7 12.46; \n",
            "17.3 18.42; 21.7 23.85; 12.5 13.08; \n",
            "16.7 17.54; 23.7 22.57; 10.7 12.2; \n",
            "19.4 17.46; 26.4 23.12; 11.4 11.45; \n",
            "16.4 19.74; 23.6 25.79; 13.5 13.48; \n",
            "15.8 17.29; 22.3 23.17; 8.4 11.5; \n",
            "15.0 16.94; 20.1 22.61; 13.2 10.67; \n",
            "13.0 15.85; 16.5 21.08; 11.7 10.67; \n",
            "12.8 13.84; 16.2 18.04; 10.1 9.34; \n",
            "9.2 13.53; 13.9 17.73; 7.9 8.94; \n",
            "8.5 10.45; 10.7 14.14; 6.6 6.05; \n",
            "12.8 9.58; 17.6 12.48; 7.7 5.77; \n",
            "14.7 13.56; 20.1 18.15; 8.2 8.79; \n",
            "15.9 15.14; 22.6 20.38; 9.8 9.65; \n",
            "15.4 15.83; 20.2 21.27; 11.1 10.62; \n",
            "15.6 15.21; 22.0 20.22; 8.2 10.41; \n",
            "18.3 15.85; 24.9 21.25; 9.5 10.19; \n",
            "19.6 18.18; 24.9 24.02; 14.4 12.23; \n",
            "19.7 18.69; 25.2 24.23; 14.3 13.53; \n",
            "20.8 18.5; 27.9 23.84; 15.1 13.48; \n",
            "20.4 19.78; 23.7 25.67; 15.9 14.5; \n",
            "19.3 19.29; 25.4 24.48; 16.3 14.47; \n",
            "22.2 18.74; 28.8 24.17; 15.2 13.74; \n",
            "23.1 21.2; 28.2 26.87; 16.0 15.65; \n",
            "22.4 21.6; 28.2 27.12; 16.2 16.23; \n",
            "22.9 21.09; 27.4 26.65; 17.5 15.76; \n",
            "24.0 21.53; 29.3 26.86; 19.1 16.41; \n",
            "22.1 22.4; 26.6 27.74; 18.3 17.36; \n",
            "21.8 21.2; 29.5 26.39; 17.2 16.29; \n",
            "24.1 21.34; 30.1 26.85; 17.0 15.97; \n",
            "19.9 22.83; 28.7 28.27; 15.8 17.46; \n",
            "18.5 20.48; 22.5 26.43; 14.9 14.63; \n",
            "18.5 19.09; 22.2 24.09; 16.9 13.9; \n",
            "19.5 18.83; 25.0 23.7; 14.8 14.18; \n",
            "21.7 19.81; 27.1 25.11; 14.1 14.61; \n",
            "22.2 21.36; 28.8 26.91; 16.3 15.85; \n",
            "16.8 21.57; 23.0 27.28; 13.8 16.12; \n",
            "17.1 17.71; 21.7 23.02; 13.0 12.39; \n",
            "18.1 17.9; 23.2 22.9; 14.2 12.6; \n",
            "17.7 18.59; 23.5 23.86; 15.1 13.29; \n",
            "15.0 18.0; 17.8 23.12; 13.5 13.09; \n",
            "15.9 15.57; 21.7 19.53; 13.0 11.44; \n",
            "19.1 16.63; 24.9 21.62; 14.5 11.94; \n",
            "20.6 19.13; 26.2 24.66; 14.5 14.19; \n",
            "21.4 20.12; 28.2 25.78; 13.4 14.87; \n",
            "24.0 20.61; 31.2 26.34; 16.6 15.0; \n",
            "25.4 22.24; 32.3 28.06; 18.7 16.88; \n",
            "22.1 23.1; 28.6 28.83; 19.5 17.89; \n",
            "18.9 21.13; 23.0 26.74; 16.0 16.14; \n",
            "15.9 18.64; 21.3 23.38; 12.5 13.96; \n",
            "17.2 16.62; 22.9 21.4; 13.4 11.65; \n",
            "19.4 18.06; 24.2 23.28; 12.6 12.77; \n",
            "20.5 19.61; 26.8 24.98; 13.2 14.01; \n",
            "20.5 20.29; 25.9 26.0; 15.6 14.57; \n",
            "22.1 20.19; 29.2 25.84; 13.9 14.84; \n",
            "25.5 21.55; 31.4 27.5; 18.4 15.58; \n",
            "19.2 23.52; 28.8 29.17; 17.7 18.0; \n",
            "19.1 19.72; 25.5 25.76; 13.8 14.05; \n",
            "21.9 19.31; 28.0 24.72; 13.5 13.88; \n",
            "23.9 21.4; 31.4 27.21; 20.2 15.41; \n",
            "25.1 22.55; 31.1 28.45; 19.5 17.25; \n",
            "23.9 23.08; 28.2 28.65; 20.2 17.99; \n",
            "22.1 22.21; 27.0 27.62; 18.0 17.32; \n",
            "18.6 21.21; 24.9 26.57; 17.1 16.31; \n",
            "17.4 19.06; 20.0 24.43; 15.8 14.03; \n",
            "18.8 18.04; 24.4 22.31; 15.7 13.5; \n",
            "19.6 18.95; 25.2 23.95; 15.8 14.03; \n",
            "19.3 19.51; 23.2 24.61; 17.1 14.83; \n",
            "20.3 19.19; 25.8 24.11; 13.3 14.72; \n",
            "17.9 20.26; 23.8 25.64; 16.1 14.96; \n",
            "15.3 18.55; 17.4 23.84; 14.1 13.66; \n",
            "18.5 15.99; 25.8 19.68; 11.9 12.01; \n",
            "17.9 18.86; 24.2 24.31; 13.4 13.42; \n",
            "20.3 18.41; 26.2 23.72; 13.6 13.26; \n",
            "19.1 19.91; 25.2 25.42; 15.2 14.67; \n",
            "21.1 19.03; 27.0 24.57; 17.1 13.99; \n",
            "21.7 20.57; 29.7 26.16; 17.7 15.51; \n",
            "20.1 21.01; 24.4 26.9; 17.0 15.93; \n",
            "17.7 19.61; 21.8 24.87; 15.1 14.91; \n",
            "18.6 17.63; 25.5 22.28; 11.7 13.11; \n",
            "20.0 18.92; 26.4 24.51; 13.0 13.48; \n",
            "17.8 20.03; 24.1 25.75; 16.0 14.21; \n",
            "18.2 18.1; 23.7 23.56; 12.8 13.13; \n",
            "20.4 18.39; 28.7 23.61; 12.9 13.15; \n",
            "24.3 20.51; 31.0 26.6; 18.1 14.47; \n",
            "24.4 22.84; 30.7 28.74; 17.6 17.42; \n",
            "24.6 22.69; 31.7 28.44; 18.0 17.19; \n",
            "25.9 22.91; 32.0 28.65; 19.4 17.4; \n",
            "21.8 23.5; 28.7 29.13; 18.8 18.28; \n",
            "22.6 21.07; 29.4 26.76; 17.4 15.82; \n",
            "24.3 21.89; 30.3 27.45; 18.6 16.34; \n",
            "25.6 22.77; 30.6 28.28; 20.3 17.46; \n",
            "19.9 23.31; 27.2 28.65; 18.4 18.36; \n",
            "21.3 20.19; 26.6 25.81; 16.0 14.9; \n",
            "19.9 21.26; 24.7 26.6; 16.4 15.91; \n",
            "20.0 20.24; 24.0 25.58; 17.2 15.0; \n",
            "17.6 20.07; 21.6 25.1; 13.9 15.21; \n",
            "14.4 18.27; 17.7 22.89; 12.8 13.29; \n",
            "14.5 15.57; 16.7 19.51; 13.3 11.17; \n",
            "14.1 15.51; 19.7 19.17; 11.0 11.45; \n",
            "17.3 15.47; 21.0 20.03; 13.5 10.56; \n",
            "17.7 17.76; 22.7 22.32; 13.5 13.14; \n",
            "17.2 17.74; 22.2 22.72; 10.2 13.06; \n",
            "16.2 17.48; 20.2 22.46; 15.0 12.29; \n",
            "16.8 16.52; 21.8 21.1; 14.3 12.22; \n",
            "16.8 16.92; 21.2 21.61; 12.8 12.56; \n",
            "18.1 16.76; 25.2 21.24; 13.5 12.33; \n",
            "18.5 18.08; 23.0 23.46; 15.5 13.15; \n",
            "18.8 17.94; 27.2 22.85; 14.6 13.76; \n",
            "17.0 18.76; 21.4 24.59; 14.2 13.62; \n",
            "19.0 17.27; 24.5 22.28; 14.3 12.63; \n",
            "20.4 18.6; 26.6 23.86; 15.0 13.87; \n",
            "19.5 19.78; 23.2 25.39; 17.9 14.73; \n",
            "17.3 18.9; 22.9 23.84; 13.0 14.75; \n",
            "18.4 17.35; 24.7 22.28; 14.6 12.54; \n",
            "19.6 18.45; 26.3 23.86; 14.5 13.61; \n",
            "21.5 19.55; 28.8 25.16; 15.2 14.22; \n",
            "18.3 20.87; 24.1 26.71; 16.5 15.46; \n",
            "16.2 18.36; 23.1 23.63; 11.1 13.53; \n",
            "17.0 17.01; 24.5 22.44; 11.7 11.57; \n",
            "17.0 18.0; 22.0 23.91; 14.3 12.27; \n",
            "16.8 17.7; 21.5 23.14; 13.5 12.54; \n",
            "15.0 17.07; 19.8 22.01; 12.2 12.36; \n",
            "12.2 15.64; 20.3 20.45; 7.1 10.91; \n",
            "13.7 13.82; 21.2 19.36; 8.0 7.88; \n",
            "14.7 15.26; 22.2 21.19; 8.8 9.27; \n",
            "14.0 16.02; 18.9 22.12; 10.3 9.73; \n",
            "13.1 14.67; 17.4 19.7; 9.4 9.51; \n",
            "13.6 13.65; 17.4 18.36; 10.2 8.77; \n",
            "14.0 14.05; 18.7 18.76; 10.4 9.27; \n",
            "14.5 14.56; 20.9 19.44; 10.3 9.75; \n",
            "13.2 14.98; 20.2 20.29; 8.8 9.77; \n",
            "13.2 13.76; 14.9 18.92; 12.4 8.52; \n",
            "15.4 13.01; 22.2 16.63; 11.3 9.34; \n",
            "16.8 15.41; 20.7 20.69; 14.1 10.46; \n",
            "17.0 16.35; 23.2 21.16; 14.0 12.09; \n",
            "17.9 16.59; 25.0 21.76; 13.8 12.17; \n",
            "17.8 17.4; 25.7 22.99; 12.5 12.77; \n",
            "18.2 17.8; 25.5 23.64; 13.0 12.59; \n",
            "19.1 18.07; 25.8 23.94; 14.2 12.71; \n",
            "19.0 18.61; 25.9 24.35; 14.4 13.53; \n",
            "18.6 18.6; 23.9 24.33; 14.2 13.4; \n",
            "17.7 18.34; 23.7 23.8; 13.5 13.54; \n",
            "16.5 17.76; 22.0 23.3; 11.8 12.6; \n",
            "16.9 17.04; 24.4 22.34; 11.8 11.82; \n",
            "18.7 17.63; 25.0 23.48; 14.3 11.85; \n",
            "19.1 18.78; 23.4 24.54; 16.4 13.4; \n",
            "16.9 18.62; 20.4 23.89; 14.4 13.89; \n",
            "15.6 16.86; 17.5 21.52; 13.9 12.36; \n",
            "15.0 15.74; 19.5 19.68; 11.3 11.75; \n",
            "14.0 15.6; 18.3 20.07; 10.4 10.89; \n",
            "15.5 14.78; 20.9 19.06; 11.9 10.13; \n",
            "16.5 15.91; 20.7 20.54; 14.5 11.22; \n",
            "14.1 16.32; 17.7 20.78; 12.5 12.22; \n",
            "14.7 14.34; 20.5 18.15; 11.8 10.36; \n",
            "13.4 15.3; 17.0 20.02; 11.1 10.72; \n",
            "11.7 14.01; 17.7 17.95; 6.8 10.0; \n",
            "13.6 12.71; 20.4 17.08; 9.6 7.8; \n",
            "14.5 14.47; 20.2 19.52; 9.9 9.62; \n",
            "16.3 14.88; 22.2 19.85; 12.4 10.05; \n",
            "13.8 16.19; 16.8 21.49; 12.2 11.51; \n",
            "10.8 13.88; 14.0 17.99; 7.9 9.92; \n",
            "9.3 11.22; 11.5 14.54; 8.3 7.19; \n",
            "5.4 9.91; 9.1 12.71; 3.5 6.48; \n",
            "3.4 6.22; 4.4 8.77; 2.5 2.28; \n",
            "3.9 4.45; 5.5 5.79; 2.7 1.58; \n",
            "6.5 4.88; 8.7 6.57; 4.7 1.84; \n",
            "8.0 7.17; 10.2 9.24; 6.4 3.89; \n",
            "10.7 8.27; 15.9 10.58; 7.1 5.14; \n",
            "12.4 10.64; 16.4 14.5; 7.5 6.68; \n",
            "9.9 11.99; 12.5 15.77; 6.8 8.2; \n",
            "12.7 9.31; 16.3 12.07; 9.7 5.88; \n",
            "12.0 11.87; 13.2 15.21; 11.1 8.51; \n",
            "8.7 10.6; 12.3 12.63; 5.2 8.16; \n",
            "5.6 7.91; 9.7 10.05; 3.1 4.69; \n",
            "8.1 5.42; 10.5 7.52; 6.2 2.19; \n",
            "5.6 8.27; 8.6 10.4; 4.3 5.28; \n",
            "5.0 5.85; 6.4 7.7; 3.9 2.5; \n",
            "3.0 5.49; 5.0 7.06; 2.4 2.67; \n",
            "2.1 3.29; 3.5 4.43; 0.7 0.62; \n",
            "3.3 2.86; 5.7 4.07; 1.2 0.13; \n",
            "3.4 3.94; 4.8 5.7; 1.5 0.86; \n",
            "6.4 3.66; 7.0 4.84; 4.3 1.05; \n",
            "6.4 6.13; 8.1 7.41; 4.2 3.9; \n",
            "5.1 5.78; 6.4 7.22; 3.9 3.24; \n",
            "5.8 4.57; 6.6 5.47; 4.5 2.32; \n",
            "2.9 5.19; 5.0 6.07; 0.4 3.21; \n",
            "5.4 2.4; 6.6 3.21; 4.3 -0.2; \n",
            "7.7 4.99; 9.3 5.87; 6.6 2.99; \n",
            "2.4 6.71; 8.6 7.84; 2.3 4.71; \n",
            "1.7 1.39; 4.1 2.99; 0.5 -1.45; \n",
            "0.8 1.88; 4.2 3.15; -1.8 -0.41; \n",
            "-1.1 0.94; 1.6 2.78; -3.0 -2.06; \n",
            "-3.3 -0.75; -0.7 0.78; -4.3 -3.68; \n",
            "-0.6 -3.05; 2.1 -1.64; -2.2 -5.83; \n",
            "0.7 -0.09; 5.1 1.62; -4.1 -2.6; \n",
            "6.0 1.0; 10.2 3.69; 1.7 -2.63; \n",
            "7.9 5.99; 9.7 9.36; 5.9 2.39; \n",
            "4.2 6.89; 6.6 9.29; 2.7 4.32; \n",
            "1.6 3.09; 4.8 4.99; -0.1 0.4; \n",
            "2.3 1.06; 4.3 2.97; 0.8 -1.81; \n",
            "3.5 1.7; 4.8 3.43; 2.7 -0.8; \n",
            "4.0 2.62; 5.9 3.79; 2.4 0.7; \n",
            "1.8 3.13; 3.2 4.46; 1.3 0.96; \n",
            "2.9 1.23; 5.6 1.97; 1.2 -0.68; \n",
            "2.6 2.79; 5.0 4.63; 0.7 0.24; \n",
            "2.8 2.47; 4.9 4.12; -0.3 -0.25; \n",
            "4.9 2.78; 6.7 4.37; 3.5 -0.0; \n",
            "4.8 4.29; 6.8 5.66; 3.8 2.13; \n",
            "2.7 3.92; 4.5 5.06; 2.0 1.86; \n",
            "1.5 2.03; 3.5 2.89; 0.4 -0.07; \n",
            "0.5 1.24; 2.9 2.25; -2.0 -0.92; \n",
            "3.0 0.41; 3.8 1.68; 1.5 -2.24; \n",
            "5.9 2.98; 7.0 4.0; 2.8 0.91; \n",
            "4.3 5.34; 6.0 6.73; 2.9 2.98; \n",
            "2.8 3.41; 8.1 4.27; 1.0 1.3; \n",
            "-0.6 2.32; 1.8 4.36; -2.7 -0.77; \n",
            "-1.8 -0.62; 1.7 0.64; -3.9 -3.51; \n",
            "-1.6 -1.45; 1.2 0.44; -4.5 -4.63; \n",
            "0.4 -1.22; 3.0 0.52; -1.5 -4.46; \n",
            "1.4 0.57; 2.6 2.26; 0.5 -2.16; \n",
            "0.5 1.21; 1.8 2.45; -0.7 -0.89; \n",
            "-1.3 0.52; 0.2 1.57; -2.4 -1.77; \n",
            "1.2 -1.14; 4.1 -0.14; -0.5 -3.66; \n",
            "-0.6 1.35; 1.1 3.36; -2.1 -1.42; \n",
            "1.7 -1.03; 5.4 0.27; 0.0 -3.28; \n",
            "0.7 1.35; 2.0 3.43; -0.6 -1.23; \n",
            "2.6 0.07; 4.8 1.0; 1.4 -1.84; \n",
            "1.7 2.1; 2.6 3.69; 0.9 -0.1; \n",
            "1.2 0.99; 2.8 1.76; 0.0 -0.74; \n",
            "0.3 0.7; 1.9 1.7; -1.1 -1.29; \n",
            "-1.6 -0.18; 0.4 0.59; -3.0 -2.07; \n",
            "-0.9 -1.81; 0.0 -0.81; -2.1 -4.17; \n",
            "-2.1 -0.81; -0.7 -0.12; -2.8 -2.74; \n",
            "-3.9 -2.15; -2.1 -1.56; -4.9 -4.36; \n",
            "-7.9 -3.72; -3.9 -3.02; -9.3 -6.12; \n",
            "-9.9 -7.72; -7.6 -6.4; -12.2 -11.18; \n",
            "-1.3 -8.96; 1.9 -7.76; -8.4 -12.52; \n",
            "-0.2 0.58; 3.1 3.68; -2.7 -3.35; \n",
            "4.1 -0.34; 6.3 1.64; 1.6 -3.38; \n",
            "2.0 3.76; 3.7 5.89; 0.5 1.28; \n",
            "-2.4 0.98; 1.7 2.27; -3.8 -1.24; \n",
            "-6.5 -2.85; -3.1 -0.85; -9.0 -6.2; \n",
            "-3.7 -6.81; -1.0 -4.82; -6.0 -10.31; \n",
            "-6.8 -3.3; -2.6 -0.95; -8.4 -6.2; \n",
            "-5.5 -7.4; -2.5 -5.62; -7.9 -10.46; \n",
            "-4.5 -4.84; -2.6 -2.43; -6.9 -8.12; \n",
            "-2.3 -3.85; 0.7 -1.71; -4.3 -6.89; \n",
            "0.8 -1.5; 3.8 1.12; -1.6 -4.86; \n",
            "0.5 0.95; 2.8 3.43; -0.9 -1.9; \n",
            "1.1 -0.05; 3.0 1.98; -0.6 -2.5; \n",
            "1.2 0.49; 2.6 2.41; -0.6 -1.59; \n",
            "4.0 0.41; 7.1 1.95; 0.4 -1.75; \n",
            "-1.0 3.1; 2.4 5.4; -2.8 0.34; \n",
            "-1.1 -2.39; 0.7 -0.78; -2.5 -4.99; \n",
            "0.8 -1.34; 5.3 0.05; -2.5 -3.54; \n",
            "-1.1 0.53; 0.7 2.81; -2.7 -2.72; \n",
            "-2.9 -1.27; -1.0 0.1; -4.0 -4.04; \n",
            "1.2 -2.89; 4.4 -1.52; -1.6 -5.45; \n",
            "6.8 1.51; 9.7 3.69; 3.5 -1.36; \n",
            "9.7 6.26; 13.8 8.83; 6.1 3.46; \n",
            "5.3 8.4; 9.1 11.93; 3.8 5.27; \n",
            "4.5 3.72; 7.9 5.86; 2.3 1.12; \n",
            "3.3 3.63; 9.5 5.86; 0.0 0.88; \n",
            "1.5 2.65; 5.5 5.83; -0.5 -1.28; \n",
            "-0.4 0.81; 2.5 3.35; -2.1 -2.38; \n",
            "-1.1 -0.98; 2.2 0.83; -3.7 -3.56; \n",
            "-1.6 -0.97; 2.0 1.21; -4.8 -4.02; \n",
            "-1.0 -0.93; 1.3 1.73; -3.9 -4.69; \n",
            "-3.3 -0.13; 0.3 2.39; -6.1 -3.73; \n",
            "-1.8 -2.69; 2.1 -0.15; -5.4 -6.56; \n",
            "-2.4 -0.77; 2.1 2.13; -6.0 -4.83; \n",
            "-1.5 -1.77; 2.6 1.33; -4.1 -6.11; \n",
            "-1.5 -1.04; 2.5 2.2; -5.2 -4.9; \n",
            "-0.1 -1.17; 2.5 1.82; -2.4 -4.99; \n",
            "1.5 0.14; 3.2 2.66; 0.5 -3.09; \n",
            "1.7 1.25; 2.8 3.24; 0.9 -1.2; \n",
            "4.2 1.08; 11.2 2.65; 0.7 -1.09; \n",
            "6.3 3.43; 9.0 7.03; 4.0 -0.2; \n",
            "6.1 5.09; 11.3 7.77; 1.8 2.59; \n",
            "6.4 4.86; 9.8 8.24; 3.9 1.37; \n",
            "5.3 5.2; 10.6 7.96; 0.4 2.26; \n",
            "5.3 4.45; 11.0 7.67; 0.7 0.52; \n",
            "6.8 4.54; 14.0 8.16; 1.4 0.44; \n",
            "9.4 6.5; 12.4 10.85; 6.0 1.91; \n",
            "8.5 8.6; 11.2 11.84; 7.5 5.09; \n",
            "7.1 7.6; 10.5 10.32; 5.2 4.67; \n",
            "6.9 6.51; 9.9 9.43; 3.8 3.04; \n",
            "8.4 6.77; 10.6 9.57; 6.4 3.36; \n",
            "8.3 7.92; 12.6 10.75; 4.0 4.76; \n",
            "7.6 7.96; 10.4 11.08; 4.5 4.13; \n",
            "6.9 7.19; 9.5 9.71; 5.0 3.74; \n",
            "7.4 6.57; 10.7 8.84; 4.1 3.45; \n",
            "10.9 7.25; 14.3 9.92; 7.8 3.65; \n",
            "12.6 10.66; 19.0 13.87; 7.8 7.09; \n",
            "11.4 12.19; 15.5 16.66; 7.4 7.8; \n",
            "9.0 10.82; 13.7 14.39; 6.6 7.03; \n",
            "4.1 8.77; 6.6 12.11; 1.5 4.94; \n",
            "5.7 4.3; 9.5 6.28; 3.9 0.71; \n",
            "5.8 6.03; 10.9 8.73; 2.8 2.48; \n",
            "7.1 5.98; 11.5 9.0; 4.8 1.96; \n",
            "4.1 7.11; 8.3 10.15; 1.4 3.69; \n",
            "4.0 4.37; 6.7 7.14; 1.6 0.63; \n",
            "4.6 4.75; 9.2 7.41; 2.0 1.15; \n",
            "5.1 5.15; 9.9 8.4; 2.3 1.07; \n",
            "5.4 5.28; 9.9 8.73; 1.7 1.23; \n",
            "9.9 5.29; 14.3 8.38; 6.5 1.66; \n",
            "8.8 9.35; 14.5 13.21; 5.1 5.76; \n",
            "4.3 8.25; 8.5 12.18; 3.4 4.2; \n",
            "6.9 3.82; 10.8 6.71; 3.5 0.34; \n",
            "8.5 6.81; 16.2 10.14; 1.8 3.3; \n",
            "9.8 8.4; 14.8 13.23; 4.3 3.23; \n",
            "10.9 9.58; 16.3 13.92; 5.8 5.05; \n",
            "9.3 10.31; 14.0 14.91; 5.9 5.76; \n",
            "8.8 8.82; 12.7 12.59; 5.4 4.73; \n",
            "7.5 8.79; 12.9 12.54; 2.6 4.48; \n",
            "9.3 7.7; 15.2 11.85; 4.5 2.73; \n",
            "7.7 9.47; 12.4 13.87; 5.3 4.6; \n",
            "6.4 7.65; 11.4 11.25; 1.2 3.44; \n",
            "8.2 6.87; 13.7 10.74; 5.4 2.05; \n",
            "7.8 8.51; 12.4 12.82; 5.3 3.93; \n",
            "7.0 8.01; 9.3 11.88; 5.7 3.71; \n",
            "9.3 6.96; 11.5 9.77; 7.4 3.58; \n",
            "8.4 9.09; 10.8 12.07; 5.0 5.91; \n",
            "14.2 8.03; 22.4 10.7; 9.6 4.59; \n",
            "17.1 13.75; 24.4 19.31; 10.0 9.1; \n",
            "16.8 16.21; 22.3 22.14; 11.8 11.08; \n",
            "17.0 15.4; 22.5 20.51; 11.6 10.97; \n",
            "16.0 15.86; 20.2 21.07; 13.1 11.17; \n",
            "16.6 15.05; 21.2 19.66; 12.0 10.85; \n",
            "13.6 15.87; 18.3 20.52; 12.3 11.38; \n",
            "15.8 13.22; 20.4 17.39; 11.9 9.3; \n",
            "14.9 15.34; 21.8 19.58; 7.8 11.28; \n",
            "16.1 15.27; 20.9 20.7; 12.9 9.69; \n",
            "7.5 16.27; 13.5 21.37; 2.8 11.44; \n",
            "10.2 8.7; 15.8 12.67; 3.0 3.02; \n",
            "13.3 11.82; 19.8 16.61; 5.8 6.07; \n",
            "8.7 14.68; 18.1 20.39; 7.1 8.3; \n",
            "6.1 9.85; 9.9 15.32; 3.2 4.05; \n",
            "7.3 7.42; 14.0 10.78; 2.0 2.77; \n",
            "6.5 8.73; 12.8 13.93; 1.3 2.84; \n",
            "7.1 8.07; 9.8 13.0; 5.1 2.2; \n",
            "9.2 7.74; 14.7 11.87; 3.9 3.23; \n",
            "12.0 9.63; 16.7 14.18; 7.7 4.64; \n",
            "13.6 11.76; 20.3 16.62; 7.5 7.2; \n",
            "15.4 13.32; 21.0 19.04; 10.5 8.0; \n",
            "15.3 14.68; 22.8 20.3; 7.8 9.65; \n",
            "15.1 14.89; 20.2 20.66; 14.0 9.08; \n",
            "15.5 14.22; 21.6 19.21; 10.7 10.0; \n",
            "10.0 14.82; 16.1 19.94; 6.5 9.99; \n",
            "10.0 9.89; 13.7 14.24; 7.0 4.97; \n",
            "13.4 10.44; 19.9 14.14; 7.5 6.41; \n",
            "16.4 13.73; 23.5 19.08; 8.5 8.3; \n",
            "19.4 16.66; 25.2 22.64; 13.3 10.83; \n",
            "17.9 18.57; 24.7 24.62; 12.6 13.12; \n",
            "19.1 17.33; 24.1 23.21; 14.6 12.07; \n",
            "18.9 18.43; 24.2 24.04; 11.8 13.24; \n",
            "19.2 18.57; 25.2 24.26; 11.9 12.92; \n",
            "20.3 18.59; 26.3 24.19; 13.3 12.87; \n",
            "20.9 19.39; 26.8 24.97; 14.5 13.81; \n",
            "21.3 19.86; 28.0 25.54; 16.4 14.4; \n",
            "20.2 20.36; 24.8 26.12; 18.8 14.98; \n",
            "18.3 19.52; 23.5 24.84; 16.5 14.78; \n",
            "19.1 18.31; 24.3 23.3; 12.6 13.59; \n",
            "15.5 19.27; 21.8 24.63; 13.7 13.74; \n",
            "15.9 16.53; 20.3 21.7; 11.6 11.45; \n",
            "17.9 16.63; 22.9 21.37; 12.1 11.65; \n",
            "16.9 18.2; 20.7 23.48; 14.8 12.89; \n",
            "15.5 17.15; 18.0 21.9; 13.0 12.61; \n",
            "11.7 15.72; 17.0 19.68; 9.0 11.56; \n",
            "15.6 12.95; 22.0 16.99; 11.6 8.15; \n",
            "15.2 16.64; 19.1 21.86; 12.1 11.51; \n",
            "16.6 15.61; 22.3 20.12; 10.9 11.15; \n",
            "18.9 16.76; 24.9 21.83; 11.5 11.63; \n",
            "18.6 18.63; 24.1 24.2; 12.1 13.26; \n",
            "18.9 18.35; 23.6 23.94; 14.8 13.06; \n",
            "15.2 18.52; 21.1 23.8; 11.2 13.58; \n",
            "14.6 15.72; 18.9 20.67; 11.6 10.56; \n",
            "17.3 14.95; 22.9 19.14; 10.4 10.42; \n",
            "16.7 17.47; 23.2 22.83; 11.9 11.98; \n",
            "17.9 17.09; 24.8 22.57; 11.5 11.58; \n",
            "19.8 18.22; 25.5 23.95; 12.4 12.55; \n",
            "19.0 19.44; 23.7 25.33; 13.0 13.72; \n",
            "20.7 18.8; 26.1 24.32; 13.4 13.31; \n",
            "22.6 20.12; 28.0 25.82; 17.1 14.39; \n",
            "18.2 21.26; 25.0 26.83; 17.3 16.06; \n",
            "14.9 18.12; 17.3 23.51; 13.7 13.18; \n",
            "11.1 15.18; 14.7 18.93; 9.2 11.16; \n",
            "14.3 12.17; 20.0 15.6; 8.0 7.71; \n",
            "12.2 15.6; 17.1 20.53; 10.0 9.97; \n",
            "13.6 13.43; 19.2 17.88; 9.6 8.54; \n",
            "15.2 14.53; 19.3 19.29; 8.7 9.55; \n",
            "16.5 15.76; 20.5 20.64; 12.5 10.66; \n",
            "19.0 16.63; 24.5 21.71; 13.6 11.79; \n",
            "17.3 18.66; 23.7 24.17; 14.3 13.51; \n",
            "19.6 17.25; 25.9 22.59; 12.9 12.34; \n",
            "21.0 18.98; 26.9 24.44; 14.0 13.8; \n",
            "20.4 19.8; 25.1 25.51; 16.6 14.62; \n",
            "18.9 19.31; 23.0 24.52; 14.7 14.51; \n",
            "21.4 18.24; 28.0 23.13; 13.4 13.5; \n",
            "24.0 20.48; 30.5 26.08; 15.9 15.0; \n",
            "25.4 22.32; 32.5 28.06; 17.1 16.8; \n",
            "27.0 23.22; 33.5 28.93; 18.6 17.66; \n",
            "27.4 24.12; 33.5 29.63; 19.7 18.58; \n",
            "24.1 24.35; 30.5 29.82; 19.3 18.94; \n",
            "24.5 22.7; 29.5 28.25; 17.7 17.25; \n",
            "25.5 23.05; 30.5 28.37; 19.8 17.49; \n",
            "25.5 23.57; 30.3 28.83; 19.6 18.26; \n",
            "26.1 23.5; 32.5 28.7; 17.9 18.32; \n",
            "26.7 24.06; 33.2 29.43; 21.0 18.38; \n",
            "24.0 24.49; 28.9 29.87; 20.0 19.12; \n",
            "20.2 22.96; 25.7 28.22; 18.5 17.68; \n",
            "19.7 20.68; 24.5 25.8; 15.7 15.47; \n",
            "20.8 20.42; 25.4 25.43; 14.8 15.03; \n",
            "22.2 21.0; 28.3 26.15; 15.4 15.55; \n",
            "18.2 22.02; 26.1 27.53; 15.2 16.37; \n",
            "20.2 19.43; 26.7 25.17; 14.4 13.73; \n",
            "21.5 20.67; 28.0 26.29; 17.9 15.05; \n",
            "22.3 21.4; 28.0 27.25; 16.8 15.98; \n",
            "24.2 21.75; 30.6 27.31; 17.0 16.38; \n",
            "25.4 22.83; 32.0 28.45; 18.5 17.36; \n",
            "26.3 23.46; 32.7 29.12; 19.5 18.12; \n",
            "23.9 23.85; 31.0 29.41; 21.0 18.59; \n",
            "20.6 22.59; 26.7 28.23; 16.4 17.53; \n",
            "20.7 20.5; 25.9 25.84; 15.6 15.1; \n",
            "22.6 20.51; 27.7 25.77; 16.5 15.17; \n",
            "24.3 21.95; 30.5 27.36; 17.4 16.46; \n",
            "24.4 23.0; 30.3 28.51; 19.9 17.48; \n",
            "25.8 22.97; 31.7 28.47; 19.9 17.85; \n",
            "26.2 23.71; 33.5 29.18; 20.7 18.54; \n",
            "25.4 24.11; 29.1 29.64; 21.5 18.87; \n",
            "22.2 23.49; 27.5 28.62; 16.6 18.61; \n",
            "22.1 21.62; 27.7 26.76; 16.5 16.24; \n",
            "23.4 21.68; 29.8 26.93; 16.5 16.32; \n",
            "23.9 22.66; 30.5 28.11; 17.9 17.04; \n",
            "24.4 22.88; 31.1 28.39; 19.3 17.42; \n",
            "25.5 23.22; 31.4 28.71; 19.5 17.83; \n",
            "25.9 23.74; 32.2 29.16; 19.4 18.48; \n",
            "26.1 24.11; 32.2 29.56; 19.9 18.7; \n",
            "27.1 24.23; 33.6 29.65; 20.3 18.77; \n",
            "25.9 24.65; 31.9 29.95; 21.0 19.36; \n",
            "25.4 23.91; 31.6 29.25; 18.8 18.73; \n",
            "24.7 23.71; 34.0 29.05; 19.7 18.28; \n",
            "19.3 23.68; 23.3 29.38; 15.0 18.01; \n",
            "19.1 20.11; 23.0 25.17; 16.1 14.56; \n",
            "19.6 19.73; 25.5 24.66; 14.8 14.51; \n",
            "21.9 20.45; 29.3 25.87; 15.4 14.82; \n",
            "24.0 21.99; 30.8 27.76; 17.7 16.1; \n",
            "22.2 23.04; 26.5 28.8; 18.1 17.49; \n",
            "20.3 21.52; 26.7 26.96; 15.3 16.32; \n",
            "18.8 20.53; 25.8 26.03; 14.7 14.94; \n",
            "17.2 19.73; 22.5 25.58; 13.1 13.89; \n",
            "20.4 18.1; 26.8 23.25; 14.7 12.62; \n",
            "23.3 20.34; 30.9 25.93; 15.9 14.88; \n",
            "23.8 22.31; 31.8 28.18; 17.9 16.7; \n",
            "22.5 22.55; 28.1 28.54; 18.5 17.01; \n",
            "21.3 21.64; 26.6 27.37; 15.5 16.41; \n",
            "20.4 20.93; 28.0 26.52; 14.5 15.37; \n",
            "19.5 20.67; 24.3 26.52; 15.0 14.77; \n",
            "18.0 19.65; 24.0 25.03; 12.4 14.22; \n",
            "19.5 18.46; 26.5 23.77; 12.8 12.77; \n",
            "20.1 19.86; 27.7 25.67; 13.6 13.94; \n",
            "20.8 20.44; 27.4 26.52; 16.9 14.32; \n",
            "21.9 20.7; 26.5 26.63; 17.4 15.11; \n",
            "20.4 21.23; 24.1 26.78; 17.2 15.93; \n",
            "19.9 19.93; 24.4 25.11; 15.5 15.07; \n",
            "19.4 19.67; 25.0 24.87; 13.8 14.65; \n",
            "20.1 19.46; 25.9 24.87; 14.3 13.98; \n",
            "20.6 19.97; 28.1 25.36; 14.5 14.58; \n",
            "21.1 20.37; 27.8 26.13; 15.9 14.68; \n",
            "21.5 20.64; 27.4 26.3; 17.2 15.21; \n",
            "22.7 20.92; 29.9 26.51; 16.5 15.65; \n",
            "23.6 21.95; 30.2 27.75; 17.8 16.41; \n",
            "23.1 22.54; 30.0 28.25; 16.3 17.13; \n",
            "22.4 22.23; 30.5 28.0; 15.8 16.6; \n",
            "22.5 21.88; 30.4 27.82; 17.7 16.02; \n",
            "22.7 21.96; 28.5 27.89; 17.5 16.29; \n",
            "22.5 21.85; 26.8 27.49; 17.6 16.4; \n",
            "17.5 21.55; 23.0 26.92; 14.9 16.32; \n",
            "15.5 18.27; 17.8 23.48; 14.7 12.96; \n",
            "14.9 16.45; 18.3 20.54; 12.4 12.13; \n",
            "14.1 16.13; 15.7 20.44; 12.7 11.3; \n",
            "17.0 15.1; 21.0 18.58; 12.6 10.95; \n",
            "17.0 17.37; 21.1 21.84; 14.5 12.67; \n",
            "16.3 17.18; 18.0 21.82; 15.3 12.74; \n",
            "16.7 16.34; 19.4 20.0; 15.2 12.65; \n",
            "17.4 16.55; 22.4 20.4; 15.1 12.81; \n",
            "18.0 17.3; 23.9 21.69; 14.1 13.29; \n",
            "16.0 17.83; 21.2 22.62; 12.6 13.41; \n",
            "17.1 16.12; 22.0 20.55; 12.7 11.97; \n",
            "18.3 17.02; 24.2 21.59; 15.4 12.66; \n",
            "15.3 18.08; 20.5 23.18; 11.5 13.77; \n",
            "15.1 15.79; 22.1 20.41; 9.6 11.16; \n",
            "16.5 15.92; 24.7 21.13; 10.9 10.7; \n",
            "18.8 17.41; 27.3 23.31; 13.0 11.89; \n",
            "19.7 19.18; 27.1 25.4; 14.3 13.46; \n",
            "20.2 19.63; 27.0 25.76; 16.8 14.03; \n",
            "15.9 19.63; 21.5 25.59; 11.7 14.51; \n",
            "14.6 16.33; 23.0 21.72; 9.1 11.16; \n",
            "15.4 15.95; 22.0 22.16; 11.4 9.75; \n",
            "15.5 16.43; 22.6 22.23; 10.5 10.79; \n",
            "16.8 16.17; 24.0 21.94; 11.8 10.47; \n",
            "16.8 17.18; 20.8 23.15; 13.7 11.51; \n",
            "13.6 16.82; 18.5 22.17; 11.1 11.92; \n",
            "11.5 14.24; 15.5 19.12; 9.0 9.31; \n",
            "11.5 12.66; 18.0 17.11; 6.3 7.82; \n",
            "16.1 12.84; 21.0 17.85; 12.3 7.19; \n",
            "17.1 16.19; 20.5 21.36; 14.5 11.44; \n",
            "16.8 16.44; 20.2 21.21; 12.5 12.16; \n",
            "17.2 16.15; 22.5 20.63; 14.8 11.82; \n",
            "14.6 16.79; 17.9 21.85; 13.2 12.45; \n",
            "15.1 14.56; 22.1 18.63; 10.5 10.6; \n",
            "13.2 15.53; 16.7 20.5; 10.6 10.59; \n",
            "14.2 13.44; 20.3 17.16; 10.4 9.34; \n",
            "14.2 14.29; 20.0 18.76; 10.0 9.86; \n",
            "17.6 14.62; 24.3 19.5; 12.1 9.84; \n",
            "13.3 17.8; 19.8 23.52; 10.3 12.58; \n",
            "7.4 14.0; 13.0 19.0; 3.5 9.11; \n",
            "6.1 8.67; 13.3 12.69; 1.5 3.69; \n",
            "7.0 7.86; 14.8 12.48; 1.4 2.1; \n",
            "8.4 8.88; 16.9 14.23; 3.2 2.74; \n",
            "9.6 9.77; 17.4 15.52; 5.0 3.55; \n",
            "10.3 10.65; 18.0 16.52; 5.4 4.94; \n",
            "11.4 11.17; 19.3 17.24; 6.5 5.31; \n",
            "12.4 12.35; 17.7 19.0; 9.3 6.28; \n",
            "11.0 12.69; 17.5 18.59; 6.7 7.45; \n",
            "10.8 11.02; 17.0 16.44; 6.5 5.77; \n",
            "11.9 10.71; 15.7 15.93; 8.3 5.73; \n",
            "10.1 11.46; 13.8 16.03; 7.1 7.1; \n",
            "9.2 9.71; 12.1 13.68; 7.7 5.49; \n",
            "7.4 9.07; 11.0 12.37; 5.4 5.4; \n",
            "6.4 7.55; 10.4 10.62; 2.7 3.69; \n",
            "8.6 6.98; 11.5 10.26; 6.4 2.76; \n",
            "10.4 8.95; 12.4 12.14; 8.4 5.2; \n",
            "9.8 10.21; 13.1 13.01; 6.7 6.89; \n",
            "10.2 9.58; 11.7 12.56; 9.5 5.93; \n",
            "7.6 9.76; 10.5 12.17; 5.0 6.99; \n",
            "8.1 7.42; 10.3 9.55; 5.8 4.19; \n",
            "10.9 8.05; 12.9 10.17; 9.3 5.01; \n",
            "11.2 10.4; 13.6 12.73; 9.9 7.58; \n",
            "6.4 10.14; 9.9 12.3; 5.0 7.57; \n",
            "6.5 5.95; 9.3 7.61; 4.0 3.15; \n",
            "8.7 6.72; 11.2 8.74; 6.9 3.69; \n",
            "6.3 8.7; 11.5 10.87; 2.2 5.86; \n",
            "4.6 6.5; 7.5 9.33; 2.4 2.35; \n",
            "6.9 4.81; 12.4 6.61; 3.5 1.77; \n",
            "8.5 7.09; 12.4 10.28; 6.8 3.37; \n",
            "4.4 8.45; 8.5 11.51; 0.5 5.08; \n",
            "4.7 4.69; 8.5 7.38; 1.0 0.61; \n",
            "2.6 4.97; 6.5 7.86; 0.0 1.23; \n",
            "0.3 2.85; 4.5 5.26; -3.0 -0.7; \n",
            "2.7 0.84; 6.5 3.65; -0.5 -3.47; \n",
            "4.7 3.39; 8.6 6.26; 2.4 -0.33; \n",
            "4.0 4.55; 6.6 7.36; 1.8 1.02; \n",
            "-0.5 3.95; 3.5 6.23; -2.8 0.75; \n",
            "-1.8 -0.38; 2.5 2.36; -4.9 -4.31; \n",
            "-0.9 -1.01; 1.1 1.96; -2.6 -5.0; \n",
            "1.3 -0.3; 2.3 1.93; 0.3 -3.45; \n",
            "-0.5 1.42; 1.6 3.12; -1.6 -1.09; \n",
            "1.3 -0.77; 4.3 0.57; -1.1 -3.3; \n",
            "-0.1 1.4; 3.0 3.62; -1.1 -1.47; \n",
            "-0.6 -0.29; 2.5 1.69; -4.0 -3.07; \n",
            "3.7 -0.27; 6.7 2.19; 0.2 -3.59; \n",
            "5.0 3.59; 6.8 6.06; 2.6 0.58; \n",
            "5.2 4.03; 6.9 5.84; 3.5 1.57; \n",
            "5.9 3.97; 7.4 5.57; 5.0 1.79; \n",
            "4.3 4.74; 6.5 6.05; 3.0 2.87; \n",
            "1.1 3.24; 3.1 4.39; -0.3 1.03; \n",
            "-1.0 0.5; 0.5 1.58; -1.6 -1.84; \n",
            "-2.4 -1.27; 0.0 -0.38; -4.0 -3.41; \n",
            "-2.8 -2.22; -1.6 -1.19; -3.4 -4.82; \n",
            "-2.0 -2.42; 0.2 -1.63; -3.4 -4.74; \n",
            "-4.0 -1.53; -1.5 -0.25; -5.3 -4.12; \n",
            "-2.8 -3.58; 0.2 -2.51; -5.1 -6.41; \n",
            "-3.5 -1.89; -1.4 -0.0; -5.5 -5.01; \n",
            "-6.8 -2.94; -3.0 -1.41; -8.5 -5.87; \n",
            "0.3 -6.43; 3.8 -4.53; -4.8 -9.98; \n",
            "1.4 1.26; 3.2 4.23; 0.3 -2.12; \n",
            "0.1 0.76; 2.5 2.2; -0.9 -1.36; \n",
            "-2.0 -0.54; 1.0 1.06; -4.9 -2.84; \n",
            "-4.7 -2.23; -2.2 -0.4; -7.2 -5.16; \n",
            "-0.8 -4.54; 2.8 -2.67; -3.2 -7.79; \n",
            "5.8 -0.54; 7.0 2.08; 2.8 -3.63; \n",
            "9.0 5.04; 10.5 7.01; 6.5 2.83; \n",
            "7.2 6.92; 9.5 8.87; 5.5 4.9; \n",
            "5.3 5.23; 6.5 7.1; 4.8 3.23; \n",
            "3.1 3.95; 6.2 5.13; 1.5 2.08; \n",
            "1.5 2.18; 4.0 3.77; 0.3 -0.41; \n",
            "0.1 0.74; 2.1 2.06; -2.0 -1.63; \n",
            "0.6 -0.52; 1.4 0.44; 0.2 -2.8; \n",
            "-0.1 0.24; 2.4 0.83; -1.1 -1.49; \n",
            "-1.3 -0.09; 0.6 1.03; -2.2 -2.48; \n",
            "-1.1 -0.87; 0.8 0.11; -2.8 -3.52; \n",
            "-3.8 -0.47; -1.1 0.81; -5.8 -3.05; \n",
            "-6.2 -3.44; -3.0 -2.04; -8.8 -6.54; \n",
            "-1.6 -5.37; 0.8 -3.69; -3.2 -8.96; \n",
            "0.6 -0.8; 6.0 1.19; -2.9 -3.51; \n",
            "-3.1 0.51; 5.7 3.25; -5.2 -2.91; \n",
            "-5.6 -3.83; -4.0 -0.12; -6.8 -8.2; \n",
            "-7.4 -5.11; -5.3 -3.19; -9.4 -7.75; \n",
            "-10.7 -6.78; -8.0 -4.43; -13.5 -10.29; \n",
            "-10.7 -10.14; -7.6 -8.19; -15.0 -14.34; \n",
            "-9.0 -9.82; -7.0 -7.12; -11.0 -14.14; \n",
            "-8.9 -8.13; -6.5 -6.23; -10.5 -11.04; \n",
            "-8.0 -7.86; -5.1 -5.91; -10.4 -11.56; \n",
            "1.6 -6.43; 9.0 -4.05; -5.3 -10.86; \n",
            "8.2 2.76; 9.5 8.05; 7.1 -2.22; \n",
            "5.8 6.54; 10.0 9.78; 3.1 4.68; \n",
            "2.6 3.73; 4.8 6.64; 1.0 1.0; \n",
            "4.5 0.85; 6.2 2.86; 2.7 -1.34; \n",
            "4.5 2.93; 7.4 4.84; 3.2 0.79; \n",
            "-0.4 2.21; 4.2 4.14; -3.0 -0.08; \n",
            "-0.6 -2.11; 0.8 -0.18; -1.7 -4.8; \n",
            "0.8 -1.24; 2.8 -0.19; -0.8 -3.15; \n",
            "0.8 0.72; 2.5 2.38; -0.5 -1.62; \n",
            "0.5 0.78; 3.0 2.49; -0.8 -2.12; \n",
            "0.2 0.69; 3.2 2.19; -1.9 -1.98; \n",
            "-1.1 0.16; 0.7 2.02; -2.1 -2.56; \n",
            "0.9 -0.9; 5.1 0.28; -3.5 -3.29; \n",
            "3.9 1.29; 5.8 4.0; 2.5 -2.46; \n",
            "3.5 3.44; 5.4 5.19; 2.3 1.15; \n",
            "4.4 2.48; 6.7 3.94; 2.6 0.39; \n",
            "3.3 3.55; 6.0 5.15; 1.8 1.31; \n",
            "2.8 2.49; 5.5 3.97; 1.4 0.17; \n",
            "2.6 2.08; 6.2 3.74; 0.5 -0.38; \n",
            "3.1 2.02; 5.5 3.98; 0.0 -0.59; \n",
            "4.6 2.61; 7.3 4.39; 2.0 -0.13; \n",
            "3.1 4.01; 5.8 5.9; 1.5 1.43; \n",
            "3.8 2.4; 6.4 4.09; 2.4 -0.25; \n",
            "5.6 3.48; 8.1 5.11; 3.4 0.98; \n",
            "7.1 5.13; 10.4 7.06; 5.4 2.52; \n",
            "5.6 6.28; 9.0 8.54; 4.3 3.61; \n",
            "4.0 4.69; 5.5 6.64; 3.0 2.12; \n",
            "0.9 3.38; 3.7 4.73; -0.5 1.24; \n",
            "1.3 0.57; 2.1 2.05; 0.4 -2.0; \n",
            "2.8 1.37; 4.6 2.38; 1.6 -0.79; \n",
            "2.8 2.56; 4.0 3.74; 2.1 0.37; \n",
            "4.3 2.38; 6.5 3.2; 2.8 0.49; \n",
            "0.9 3.98; 5.0 5.32; -0.6 1.83; \n",
            "-0.4 0.57; 3.5 2.22; -4.0 -2.42; \n",
            "1.1 0.08; 5.4 2.4; -2.3 -3.42; \n",
            "1.8 1.3; 5.2 3.91; -1.8 -2.17; \n",
            "4.4 1.78; 7.2 3.93; 3.0 -1.5; \n",
            "7.1 3.81; 12.5 5.8; 3.0 1.29; \n",
            "11.1 6.45; 16.2 9.78; 7.0 2.96; \n",
            "9.8 10.08; 13.7 14.26; 6.6 6.5; \n",
            "8.5 8.68; 12.3 12.21; 2.4 5.32; \n",
            "-0.6 7.69; 2.4 11.13; -1.5 3.6; \n",
            "0.8 -1.49; 6.0 0.12; -2.4 -4.65; \n",
            "1.1 1.07; 5.9 4.3; -2.6 -3.08; \n",
            "2.4 1.16; 4.9 3.98; -0.6 -2.85; \n",
            "3.3 2.64; 7.5 5.1; 1.4 -0.78; \n",
            "0.3 3.4; 3.5 6.14; -2.0 -0.07; \n",
            "-1.4 0.95; 1.9 3.47; -2.5 -2.96; \n",
            "-0.6 -0.57; 1.9 2.15; -2.0 -4.42; \n",
            "-0.5 -0.01; 1.8 2.49; -3.0 -3.06; \n",
            "3.8 -0.41; 6.0 1.63; 1.8 -3.44; \n",
            "4.6 3.61; 8.0 5.85; 2.0 1.07; \n",
            "2.5 3.74; 5.8 6.21; -0.8 0.93; \n",
            "3.5 1.95; 7.9 4.27; 0.5 -1.14; \n",
            "4.8 3.22; 8.0 6.09; 3.4 -0.17; \n",
            "1.1 4.02; 6.0 6.28; -0.7 1.29; \n",
            "-1.8 0.17; 1.8 2.46; -4.5 -3.09; \n",
            "0.8 -2.05; 4.5 0.31; -2.5 -5.25; \n",
            "5.9 1.03; 11.2 3.64; 1.1 -2.13; \n",
            "6.4 5.79; 10.8 9.55; 1.9 1.81; \n",
            "8.1 5.97; 14.0 9.48; 5.3 2.06; \n",
            "7.3 7.27; 12.8 11.22; 2.4 3.58; \n",
            "8.9 6.67; 14.5 10.61; 4.5 2.5; \n",
            "8.7 8.47; 11.5 13.02; 7.2 3.96; \n",
            "8.4 7.71; 16.1 10.85; 1.5 4.49; \n",
            "11.3 7.68; 16.7 12.23; 6.9 2.61; \n",
            "11.2 10.5; 17.1 15.02; 7.5 6.32; \n",
            "8.9 10.49; 13.5 15.28; 5.0 6.06; \n",
            "12.1 8.49; 16.2 12.28; 8.6 4.21; \n",
            "11.5 11.88; 18.8 16.29; 5.6 7.63; \n",
            "10.4 11.42; 15.5 16.61; 4.4 6.03; \n",
            "11.1 10.54; 19.0 15.15; 4.5 5.55; \n",
            "12.0 11.61; 20.1 17.24; 5.3 5.59; \n",
            "13.2 12.51; 21.9 18.27; 6.5 6.59; \n",
            "14.9 13.75; 23.5 20.16; 7.3 7.3; \n",
            "16.3 15.38; 24.5 22.09; 8.9 8.78; \n",
            "15.3 16.38; 20.1 22.94; 8.6 10.05; \n",
            "14.7 15.36; 20.0 21.27; 11.0 9.43; \n",
            "14.2 14.77; 19.9 20.42; 10.1 9.36; \n",
            "9.3 14.3; 16.4 19.69; 6.1 8.87; \n",
            "12.9 9.97; 19.8 14.96; 6.4 4.39; \n",
            "19.9 13.67; 25.9 19.39; 14.9 7.67; \n",
            "16.0 18.89; 23.6 25.04; 10.5 13.55; \n",
            "11.8 16.04; 19.0 22.14; 5.8 10.11; \n",
            "2.1 12.71; 6.4 18.45; 0.9 6.54; \n",
            "4.7 3.06; 10.0 6.39; -0.5 -1.56; \n",
            "5.1 6.59; 10.2 11.02; 1.4 0.97; \n",
            "5.7 6.55; 11.0 10.65; 0.5 1.06; \n",
            "7.5 6.6; 13.1 10.81; 2.5 1.29; \n",
            "8.9 8.13; 14.4 12.72; 2.5 3.25; \n",
            "10.6 9.96; 17.4 15.46; 3.5 4.05; \n",
            "11.3 11.51; 14.5 17.49; 8.5 5.01; \n",
            "11.0 11.08; 14.5 15.73; 7.0 6.55; \n",
            "13.4 10.23; 20.8 13.98; 5.5 5.84; \n",
            "15.0 12.98; 22.3 18.46; 7.1 7.44; \n",
            "16.6 14.63; 24.5 20.58; 8.5 8.7; \n",
            "17.5 15.95; 25.0 22.11; 10.0 9.9; \n",
            "18.0 16.9; 26.0 23.11; 9.5 10.86; \n",
            "19.1 17.6; 27.5 23.97; 10.4 11.14; \n",
            "20.0 18.64; 28.9 25.2; 11.0 12.12; \n",
            "19.5 19.68; 26.3 26.38; 12.6 12.82; \n",
            "19.1 19.19; 25.8 25.44; 12.9 12.91; \n",
            "17.7 18.85; 22.7 25.03; 13.9 12.72; \n",
            "15.3 17.62; 19.2 23.31; 10.6 11.95; \n",
            "16.2 15.81; 21.0 20.87; 12.0 10.17; \n",
            "15.6 16.66; 20.8 21.98; 11.9 11.07; \n",
            "14.7 16.26; 20.7 21.46; 9.9 10.81; \n",
            "17.2 15.56; 22.4 20.84; 10.9 9.8; \n",
            "16.9 17.57; 22.0 23.09; 13.0 11.88; \n",
            "18.4 17.1; 25.8 22.48; 12.0 11.76; \n",
            "21.4 18.6; 26.1 24.47; 16.0 12.8; \n",
            "22.1 20.44; 29.0 26.08; 16.5 15.27; \n",
            "19.6 20.85; 24.0 26.63; 16.0 15.62; \n",
            "13.0 18.89; 20.2 24.07; 9.8 14.18; \n",
            "15.1 14.09; 23.0 19.03; 6.5 8.67; \n",
            "19.0 16.44; 26.0 22.24; 9.4 9.95; \n",
            "21.6 19.43; 29.7 25.55; 12.3 12.88; \n",
            "25.0 21.05; 34.0 27.33; 17.4 14.55; \n",
            "17.5 23.04; 28.7 29.26; 13.6 17.22; \n",
            "13.8 18.61; 18.5 25.62; 10.5 11.87; \n",
            "17.0 15.3; 22.3 20.8; 10.4 9.5; \n",
            "16.8 17.88; 23.3 23.91; 9.1 11.55; \n",
            "16.7 17.73; 22.3 23.67; 12.1 11.08; \n",
            "11.8 17.01; 15.0 22.64; 9.1 11.34; \n",
            "11.2 12.46; 14.7 16.76; 6.4 7.58; \n",
            "13.3 12.57; 19.6 16.73; 6.7 7.3; \n",
            "14.9 14.89; 17.0 20.6; 13.0 8.3; \n",
            "14.9 15.15; 19.4 19.6; 13.2 10.48; \n",
            "14.9 14.75; 22.3 19.05; 8.5 10.32; \n",
            "17.0 15.46; 23.3 20.96; 12.2 9.9; \n",
            "14.1 17.11; 20.0 22.77; 11.9 11.89; \n",
            "18.1 14.44; 24.5 19.62; 12.0 9.52; \n",
            "20.5 17.87; 26.7 23.36; 15.6 12.63; \n",
            "22.2 19.42; 27.3 25.13; 17.3 14.54; \n",
            "21.8 20.19; 26.5 25.76; 18.4 15.73; \n",
            "20.1 20.07; 25.3 25.42; 15.0 15.69; \n",
            "15.9 19.41; 21.8 24.73; 13.3 14.53; \n",
            "15.7 16.23; 18.9 21.08; 12.3 11.45; \n",
            "18.4 15.98; 24.7 20.28; 12.2 11.41; \n",
            "21.7 18.46; 27.0 23.69; 15.0 13.01; \n",
            "22.3 20.7; 29.3 26.16; 16.3 15.59; \n",
            "22.0 21.23; 28.1 27.06; 15.8 15.88; \n",
            "22.8 21.2; 27.9 26.91; 17.3 15.83; \n",
            "22.9 21.79; 28.5 27.35; 15.0 16.49; \n",
            "23.3 21.88; 29.5 27.43; 15.1 16.24; \n",
            "19.0 22.12; 27.2 27.68; 16.5 16.33; \n",
            "13.0 19.32; 16.8 25.02; 11.4 13.79; \n",
            "12.9 14.23; 15.9 18.16; 10.5 9.55; \n",
            "15.0 14.34; 21.3 18.25; 8.7 9.54; \n",
            "19.5 16.67; 26.3 22.07; 11.8 10.56; \n",
            "22.5 19.87; 29.0 25.81; 16.5 13.85; \n",
            "24.4 21.56; 30.5 27.62; 17.0 16.05; \n",
            "25.7 22.48; 31.5 28.38; 17.0 17.05; \n",
            "25.9 23.24; 32.5 28.97; 20.9 17.74; \n",
            "27.4 23.44; 34.4 29.14; 18.9 18.17; \n",
            "25.7 24.19; 33.3 29.6; 20.4 18.73; \n",
            "21.9 23.35; 28.2 28.93; 17.4 18.05; \n",
            "19.2 21.06; 24.3 26.47; 14.5 15.78; \n",
            "17.4 19.32; 22.5 24.47; 12.8 13.87; \n",
            "19.9 18.61; 26.2 23.79; 14.2 12.77; \n",
            "20.3 20.54; 26.5 26.19; 16.6 14.57; \n",
            "20.2 20.6; 25.6 26.24; 15.8 15.18; \n",
            "22.8 20.4; 29.8 25.98; 14.9 14.91; \n",
            "25.0 22.2; 31.4 28.09; 18.1 16.36; \n",
            "26.4 23.42; 33.0 29.22; 19.0 17.8; \n",
            "25.0 24.04; 29.8 29.62; 21.8 18.5; \n",
            "21.2 22.89; 26.1 28.22; 17.1 18.08; \n",
            "22.6 20.51; 27.9 25.57; 16.0 15.53; \n",
            "22.7 21.64; 28.8 26.94; 16.8 16.33; \n",
            "24.2 22.05; 30.5 27.52; 16.5 16.5; \n",
            "25.4 22.9; 31.1 28.34; 19.4 17.22; \n",
            "26.5 23.47; 32.5 28.88; 19.8 18.25; \n",
            "27.1 24.13; 33.4 29.56; 19.1 18.79; \n",
            "27.1 24.61; 33.6 29.98; 20.5 19.16; \n",
            "28.2 24.77; 36.0 30.13; 20.8 19.27; \n",
            "29.2 25.29; 34.5 30.59; 22.3 19.83; \n",
            "25.9 25.52; 31.4 30.6; 20.5 20.44; \n",
            "26.2 23.97; 37.4 29.2; 20.6 18.61; \n",
            "19.4 24.65; 25.6 30.3; 16.5 18.89; \n",
            "20.0 20.63; 27.0 26.13; 12.0 14.85; \n",
            "24.3 21.1; 30.2 26.81; 15.7 14.51; \n",
            "21.2 23.58; 30.5 29.22; 16.5 17.49; \n",
            "19.7 21.89; 25.5 28.08; 14.4 15.57; \n",
            "21.2 20.57; 28.1 26.31; 14.9 14.54; \n",
            "17.3 21.57; 22.9 27.67; 15.4 15.29; \n",
            "17.3 18.55; 22.3 24.11; 13.9 12.94; \n",
            "17.4 18.4; 21.8 23.83; 13.9 12.86; \n",
            "15.9 18.06; 18.8 23.24; 12.5 12.62; \n",
            "15.8 16.52; 22.0 20.98; 12.0 11.85; \n",
            "18.9 16.65; 24.5 21.92; 12.1 11.34; \n",
            "20.3 19.2; 26.7 24.81; 14.0 13.59; \n",
            "19.9 19.95; 25.1 25.7; 16.5 14.31; \n",
            "17.8 19.39; 21.4 24.83; 16.8 14.54; \n",
            "17.0 17.52; 22.0 22.06; 12.6 13.25; \n",
            "16.3 17.28; 20.8 22.1; 13.8 12.42; \n",
            "18.7 16.71; 23.6 21.46; 14.4 12.14; \n",
            "20.7 18.48; 26.7 23.41; 14.5 13.8; \n",
            "21.0 19.96; 25.6 25.41; 15.9 14.93; \n",
            "22.2 20.05; 27.9 25.34; 14.7 15.23; \n",
            "23.0 21.01; 28.8 26.55; 16.8 15.72; \n",
            "20.8 21.73; 25.5 27.29; 17.7 16.5; \n",
            "23.7 20.25; 29.5 25.41; 17.6 15.36; \n",
            "24.2 22.06; 28.9 27.36; 19.0 17.09; \n",
            "23.2 22.31; 29.4 27.55; 16.5 17.47; \n",
            "22.5 21.98; 26.5 27.4; 19.0 16.63; \n",
            "19.2 21.42; 22.9 26.53; 17.8 16.69; \n",
            "19.1 19.24; 23.1 23.89; 16.1 14.65; \n",
            "20.6 19.25; 25.3 23.86; 16.5 14.59; \n",
            "20.3 20.43; 24.0 25.44; 17.0 15.57; \n",
            "20.3 19.97; 26.0 24.7; 15.8 15.37; \n",
            "19.8 20.21; 24.4 25.37; 15.8 15.33; \n",
            "18.9 19.91; 24.7 24.99; 13.5 14.96; \n",
            "18.0 19.36; 23.4 24.56; 14.1 14.09; \n",
            "18.7 18.59; 24.2 23.7; 13.2 13.45; \n",
            "22.3 19.15; 29.4 24.3; 14.6 13.89; \n",
            "17.8 21.61; 25.7 27.31; 15.2 16.08; \n",
            "16.0 18.58; 19.9 24.39; 13.8 13.22; \n",
            "16.6 16.71; 22.4 21.33; 11.5 12.03; \n",
            "17.1 17.52; 24.1 22.87; 11.0 12.11; \n",
            "17.3 18.14; 23.1 23.96; 11.5 12.16; \n",
            "18.7 17.94; 24.7 23.49; 14.2 12.32; \n",
            "18.2 18.69; 24.3 24.38; 13.2 13.38; \n",
            "18.7 18.39; 23.8 24.04; 16.5 12.99; \n",
            "18.1 18.56; 22.3 24.04; 16.2 13.75; \n",
            "18.2 17.93; 22.5 22.95; 15.9 13.35; \n",
            "21.2 17.88; 26.5 22.71; 16.0 13.46; \n",
            "20.8 20.25; 25.4 25.59; 16.2 15.51; \n",
            "22.0 19.77; 28.0 25.02; 17.7 15.09; \n",
            "19.6 20.67; 25.4 26.03; 16.5 15.96; \n",
            "17.5 19.22; 21.0 24.47; 14.6 14.49; \n",
            "18.8 17.5; 25.0 21.84; 13.7 13.17; \n",
            "19.9 18.92; 25.7 24.15; 14.4 13.78; \n",
            "21.3 19.84; 28.3 25.17; 14.3 14.71; \n",
            "16.9 20.9; 25.4 26.54; 15.0 15.4; \n",
            "19.2 17.85; 25.2 23.72; 15.1 12.54; \n",
            "20.8 19.44; 27.5 24.94; 16.6 14.31; \n",
            "20.9 20.62; 27.0 26.5; 15.5 15.32; \n",
            "19.9 20.63; 26.2 26.35; 15.6 15.25; \n",
            "19.4 19.71; 23.7 25.32; 15.5 14.5; \n",
            "16.5 19.19; 20.9 24.48; 14.5 14.43; \n",
            "14.8 16.95; 18.3 21.8; 11.3 12.22; \n",
            "16.3 15.6; 21.1 19.87; 13.4 10.9; \n",
            "16.0 16.74; 23.2 21.45; 10.5 11.98; \n",
            "19.7 16.88; 26.2 22.27; 15.4 11.36; \n",
            "21.7 19.59; 26.5 25.31; 18.0 14.44; \n",
            "20.5 20.61; 24.5 26.11; 17.4 15.93; \n",
            "16.6 19.55; 20.5 24.67; 15.1 15.07; \n",
            "16.0 16.75; 20.0 21.19; 14.3 12.52; \n",
            "15.2 16.24; 20.6 20.6; 10.7 12.12; \n",
            "16.4 15.82; 21.0 20.3; 11.5 11.13; \n",
            "15.1 16.73; 19.1 21.43; 13.9 11.92; \n",
            "15.1 15.22; 20.7 19.23; 10.7 11.31; \n",
            "14.6 15.63; 17.2 20.37; 12.9 10.81; \n",
            "13.4 15.21; 17.5 19.25; 11.2 11.07; \n",
            "12.5 14.18; 17.2 18.24; 9.6 9.89; \n",
            "10.4 13.31; 18.5 17.22; 5.4 8.99; \n",
            "10.7 11.97; 18.3 16.88; 5.2 6.45; \n",
            "10.6 12.13; 16.4 17.31; 6.4 6.51; \n",
            "11.3 11.67; 12.2 16.42; 10.9 6.6; \n",
            "12.0 11.53; 15.7 14.62; 10.0 8.04; \n",
            "11.0 12.2; 15.4 15.98; 7.5 8.38; \n",
            "11.4 11.35; 15.5 15.39; 9.4 7.02; \n",
            "12.0 11.66; 18.3 15.58; 6.5 7.89; \n",
            "14.7 12.36; 19.5 17.14; 12.5 7.41; \n",
            "12.3 14.34; 18.2 18.92; 7.4 10.24; \n",
            "14.3 12.2; 19.9 16.76; 9.8 7.31; \n",
            "15.4 13.95; 21.2 18.83; 12.4 9.41; \n",
            "16.0 15.19; 21.5 20.29; 11.8 10.76; \n",
            "14.5 15.72; 19.0 20.82; 12.0 11.17; \n",
            "15.3 14.29; 20.0 18.7; 12.5 10.23; \n",
            "14.4 14.93; 16.4 19.61; 13.0 10.7; \n",
            "15.6 13.9; 22.0 17.38; 10.5 10.61; \n",
            "18.7 15.67; 25.0 20.85; 15.5 10.66; \n",
            "15.9 18.03; 21.5 23.37; 12.8 13.61; \n",
            "14.3 15.63; 19.3 20.49; 12.0 11.24; \n",
            "12.0 14.46; 16.4 18.91; 9.4 10.16; \n",
            "11.1 12.72; 16.9 16.71; 6.2 8.44; \n",
            "10.5 12.11; 14.4 16.51; 8.0 7.01; \n",
            "7.9 11.4; 12.4 15.2; 5.4 7.21; \n",
            "5.2 8.75; 10.1 12.05; 1.0 4.52; \n",
            "5.0 6.64; 12.3 9.78; 0.0 2.04; \n",
            "5.8 6.72; 13.5 11.47; 0.4 0.87; \n",
            "6.5 7.45; 14.1 12.54; 1.2 1.37; \n",
            "6.4 7.84; 12.7 13.12; 2.0 1.88; \n",
            "7.7 7.34; 13.1 12.18; 4.4 1.85; \n",
            "7.9 8.22; 14.1 12.9; 4.0 3.43; \n",
            "7.9 8.25; 12.4 13.32; 4.8 3.11; \n",
            "7.9 7.99; 14.2 12.39; 3.4 3.57; \n",
            "10.8 7.85; 18.3 12.58; 7.0 3.04; \n",
            "9.6 10.53; 14.5 16.02; 6.3 5.67; \n",
            "11.8 9.12; 18.5 13.61; 7.2 4.73; \n",
            "14.1 11.31; 20.0 16.66; 10.0 6.43; \n",
            "10.6 13.38; 14.8 18.74; 7.2 8.81; \n",
            "12.7 10.05; 17.1 14.23; 10.3 5.75; \n",
            "14.4 12.19; 18.3 16.59; 11.5 8.29; \n",
            "13.4 13.6; 16.3 18.02; 11.4 9.66; \n",
            "12.5 12.49; 14.5 16.03; 11.0 9.05; \n",
            "11.4 11.8; 13.1 14.98; 10.0 8.63; \n",
            "10.9 10.87; 13.2 13.34; 8.6 7.88; \n",
            "9.8 10.84; 11.3 13.38; 9.2 7.56; \n",
            "8.6 9.76; 10.6 11.89; 7.3 6.82; \n",
            "6.2 8.63; 10.0 10.21; 3.0 5.88; \n",
            "7.1 6.73; 8.7 8.76; 6.1 3.14; \n",
            "2.9 7.69; 7.4 9.34; 1.9 4.85; \n",
            "1.1 3.42; 1.9 5.1; 0.2 -0.06; \n",
            "3.8 2.11; 7.3 2.84; 0.7 -0.48; \n",
            "9.2 4.68; 10.0 6.79; 7.3 1.28; \n",
            "10.2 9.02; 11.4 11.05; 9.0 6.51; \n",
            "5.8 9.31; 11.0 11.22; 2.5 7.01; \n",
            "6.7 5.32; 9.1 7.75; 5.8 1.77; \n",
            "6.6 6.41; 9.3 8.21; 4.4 4.08; \n",
            "6.0 6.05; 10.0 8.11; 3.9 3.09; \n",
            "2.9 5.49; 5.5 7.66; 0.0 2.42; \n",
            "4.4 2.45; 6.1 3.9; 3.5 -0.36; \n",
            "7.2 4.09; 9.2 5.45; 4.8 1.97; \n",
            "4.3 7.0; 8.0 8.99; 1.5 4.36; \n",
            "2.5 4.2; 7.0 6.21; 0.1 0.65; \n",
            "0.1 2.72; 4.6 4.92; -1.9 -0.6; \n",
            "0.7 0.22; 1.4 2.64; -1.1 -3.31; \n",
            "0.9 1.51; 1.4 2.84; 0.0 -1.23; \n",
            "1.5 1.15; 2.5 2.24; 0.7 -1.38; \n",
            "1.9 1.45; 2.7 2.38; 1.1 -0.67; \n",
            "2.5 1.73; 3.0 2.54; 1.9 -0.18; \n",
            "1.9 2.42; 2.7 3.21; 0.7 0.58; \n",
            "0.2 1.74; 1.6 2.4; -0.5 -0.27; \n",
            "-1.9 -0.06; -0.5 0.65; -2.6 -2.23; \n",
            "-2.7 -2.03; -1.8 -1.4; -3.7 -4.14; \n",
            "-1.8 -2.62; -0.9 -2.18; -2.5 -4.55; \n",
            "-1.7 -1.64; -0.9 -1.48; -2.9 -3.44; \n",
            "-1.8 -1.59; 0.7 -1.43; -3.5 -3.51; \n",
            "-5.3 -1.69; -1.5 -0.77; -8.5 -4.07; \n",
            "-5.2 -5.03; -1.6 -3.5; -8.4 -8.46; \n",
            "-5.1 -4.25; -0.5 -2.17; -9.0 -7.83; \n",
            "-3.4 -4.36; -1.0 -1.8; -6.9 -8.35; \n",
            "-0.8 -2.55; 0.7 -0.45; -2.1 -5.94; \n",
            "0.8 -0.57; 2.0 0.86; -0.6 -2.9; \n",
            "0.5 0.62; 1.6 1.88; -0.4 -1.63; \n",
            "1.8 0.11; 2.9 1.17; 0.4 -1.91; \n",
            "3.4 1.33; 5.3 2.73; 1.6 -0.68; \n",
            "4.3 2.42; 7.9 3.99; 2.9 0.39; \n",
            "2.2 2.89; 5.3 4.86; 0.4 0.58; \n",
            "2.0 0.9; 5.5 2.55; -2.0 -1.45; \n",
            "1.6 1.29; 3.0 3.52; 0.1 -1.62; \n",
            "1.7 0.95; 3.5 2.08; -0.5 -1.25; \n",
            "1.5 1.34; 4.0 2.55; -0.5 -1.15; \n",
            "0.3 1.08; 1.7 2.34; -0.2 -1.44; \n",
            "-2.2 0.05; 0.5 0.76; -4.5 -1.97; \n",
            "-6.1 -2.03; -1.5 -0.72; -8.5 -5.03; \n",
            "-6.3 -5.58; -3.2 -3.44; -9.0 -9.62; \n",
            "-7.1 -5.13; -5.4 -2.81; -9.1 -8.92; \n",
            "-6.0 -6.13; -4.0 -4.54; -7.2 -9.46; \n",
            "-5.9 -4.98; -2.4 -3.33; -8.1 -8.12; \n",
            "-7.7 -5.06; -5.5 -3.02; -10.0 -8.67; \n",
            "-4.1 -6.76; -2.1 -4.88; -6.5 -10.36; \n",
            "-3.3 -2.8; -0.8 -0.39; -5.4 -5.8; \n",
            "-4.9 -2.82; -2.3 -0.9; -6.5 -5.75; \n",
            "-3.6 -4.68; -3.3 -2.78; -4.5 -7.75; \n",
            "-3.5 -3.27; -2.1 -1.94; -4.5 -5.17; \n",
            "-6.6 -3.53; -4.2 -2.45; -9.5 -5.72; \n",
            "-7.0 -6.61; -2.8 -5.39; -10.3 -9.78; \n",
            "-6.7 -6.54; -3.0 -4.04; -9.5 -10.21; \n",
            "-8.0 -6.17; -5.6 -3.91; -9.7 -9.48; \n",
            "-10.6 -7.43; -7.8 -5.87; -11.1 -10.84; \n",
            "-8.6 -10.18; -5.7 -9.03; -12.7 -13.82; \n",
            "-1.5 -7.01; 1.4 -4.48; -5.7 -11.18; \n",
            "1.5 -0.3; 4.0 2.75; -0.9 -3.47; \n",
            "1.8 1.26; 3.5 3.57; 1.2 -1.19; \n",
            "4.4 0.94; 7.0 2.55; 2.6 -0.93; \n",
            "2.4 3.26; 3.9 5.45; 0.9 1.07; \n",
            "3.3 0.83; 4.7 2.47; 2.0 -1.28; \n",
            "3.4 1.84; 4.7 3.46; 2.8 0.08; \n",
            "0.1 1.55; 2.8 2.38; -1.9 0.11; \n",
            "-1.9 -1.21; 1.0 -0.21; -4.4 -3.38; \n",
            "-1.1 -2.4; -0.3 -0.84; -1.8 -5.06; \n",
            "3.3 -1.03; 4.6 -0.21; -0.3 -3.01; \n",
            "2.1 3.39; 4.7 4.79; 0.3 0.8; \n",
            "-0.9 1.61; 0.4 2.86; -2.5 -1.05; \n",
            "-3.5 -0.96; -0.5 -0.14; -5.2 -3.33; \n",
            "-3.2 -3.24; -1.3 -1.93; -4.5 -6.27; \n",
            "-2.8 -2.43; -2.0 -1.23; -3.5 -5.29; \n",
            "2.4 -2.44; 6.5 -1.76; -2.0 -4.77; \n",
            "6.0 2.44; 9.0 4.96; 3.9 -0.66; \n",
            "3.8 4.94; 7.7 7.12; 0.9 2.64; \n",
            "4.0 2.9; 8.4 5.16; 1.0 0.01; \n",
            "4.6 3.44; 7.7 6.21; 2.4 0.21; \n",
            "2.4 3.78; 3.3 6.01; 1.5 1.02; \n",
            "1.6 1.26; 2.7 2.32; 0.7 -0.87; \n",
            "-0.5 0.72; 0.9 1.72; -2.0 -1.05; \n",
            "0.9 -1.04; 1.8 -0.39; 0.0 -3.19; \n",
            "-2.0 1.03; 0.5 1.91; -4.0 -0.95; \n",
            "-1.2 -1.97; 1.0 -0.57; -3.0 -4.92; \n",
            "-3.2 -0.5; 0.3 0.95; -5.5 -3.32; \n",
            "-6.1 -2.78; -1.7 -1.02; -9.8 -6.2; \n",
            "-5.6 -5.35; -2.5 -2.7; -9.5 -9.79; \n",
            "-5.0 -4.39; -3.2 -1.98; -6.8 -8.18; \n",
            "-5.5 -4.09; -1.2 -2.52; -9.5 -7.3; \n",
            "2.3 -4.6; 4.7 -2.1; -1.2 -8.79; \n",
            "1.6 2.99; 3.7 5.64; 0.3 -0.06; \n",
            "-2.3 0.89; 3.1 2.49; -5.0 -1.5; \n",
            "-1.0 -2.66; 2.9 0.29; -2.4 -6.61; \n",
            "-1.9 -0.95; 1.8 1.75; -5.7 -3.91; \n",
            "2.3 -2.08; 3.2 0.88; 1.4 -5.77; \n",
            "2.6 1.82; 3.7 3.83; 1.8 -0.14; \n",
            "1.5 1.32; 3.2 2.46; 0.9 -0.42; \n",
            "2.0 0.49; 3.9 1.61; 0.8 -1.39; \n",
            "3.5 1.38; 5.0 3.05; 1.4 -0.54; \n",
            "3.2 2.82; 4.5 4.41; 2.0 0.56; \n",
            "2.8 2.38; 3.4 3.36; 2.0 0.53; \n",
            "3.2 1.88; 4.8 2.74; 2.1 0.09; \n",
            "2.7 2.37; 4.1 3.19; 1.5 0.62; \n",
            "2.6 1.9; 4.6 2.68; 1.5 -0.0; \n",
            "2.3 2.06; 3.8 2.86; 1.5 0.08; \n",
            "1.7 1.79; 2.2 2.35; 0.7 -0.01; \n",
            "1.5 1.4; 3.5 1.74; 0.3 -0.35; \n",
            "0.3 1.22; 4.6 2.06; -3.6 -0.91; \n",
            "1.0 0.24; 6.5 2.07; -4.0 -3.05; \n",
            "1.4 1.19; 6.5 3.91; -2.5 -2.67; \n",
            "2.7 1.5; 7.9 4.17; -1.6 -2.24; \n",
            "4.2 2.78; 9.5 5.77; 0.0 -1.24; \n",
            "5.0 4.11; 8.5 7.41; 3.0 0.01; \n",
            "4.8 4.48; 11.7 7.29; -0.5 1.23; \n",
            "9.0 4.47; 14.8 8.54; 3.7 -0.09; \n",
            "11.4 8.72; 15.3 13.38; 7.0 4.26; \n",
            "12.9 10.29; 17.8 14.55; 8.0 6.35; \n",
            "11.7 11.37; 15.2 15.98; 9.6 7.18; \n",
            "5.7 10.21; 11.1 13.88; 4.9 6.77; \n",
            "5.3 4.65; 7.4 7.67; 3.6 1.0; \n",
            "4.8 5.13; 6.4 7.55; 2.9 2.18; \n",
            "2.0 4.68; 3.8 6.68; 0.6 1.6; \n",
            "3.3 2.22; 4.9 3.73; 1.0 -0.72; \n",
            "3.6 3.82; 6.5 5.79; 0.5 0.93; \n",
            "1.7 4.11; 5.2 6.34; -0.5 0.6; \n",
            "2.6 2.39; 6.4 4.43; -1.5 -1.27; \n",
            "3.6 3.33; 6.9 5.97; 0.8 -0.75; \n",
            "5.3 3.86; 8.5 6.15; 2.5 0.28; \n",
            "5.4 5.2; 6.7 7.68; 4.5 1.88; \n",
            "4.4 4.77; 5.3 6.24; 3.3 2.39; \n",
            "3.1 3.78; 4.0 4.8; 1.5 1.68; \n",
            "4.4 2.67; 7.5 3.64; 2.5 0.43; \n",
            "3.5 4.06; 7.5 5.87; 0.5 1.38; \n",
            "5.4 3.04; 8.0 5.11; 1.9 -0.16; \n",
            "9.3 5.08; 16.5 7.2; 5.3 2.2; \n",
            "8.0 8.64; 10.3 12.71; 6.4 4.64; \n",
            "5.8 7.06; 9.3 9.28; 2.1 4.31; \n",
            "8.1 5.31; 11.7 7.85; 4.7 1.9; \n",
            "9.2 7.71; 14.3 10.64; 4.3 4.37; \n",
            "10.8 8.79; 18.0 12.27; 4.7 4.77; \n",
            "11.4 10.46; 18.5 15.24; 4.9 5.59; \n",
            "11.1 11.11; 20.0 16.09; 5.2 6.07; \n",
            "8.4 10.94; 14.5 16.52; 3.0 5.38; \n",
            "10.7 8.83; 18.2 13.66; 3.0 3.38; \n",
            "12.7 11.37; 20.5 17.28; 5.0 4.96; \n",
            "16.3 13.17; 21.2 19.21; 11.6 6.95; \n",
            "10.1 15.63; 17.8 21.4; 7.7 10.55; \n",
            "7.6 10.1; 9.3 15.36; 6.0 4.81; \n",
            "8.7 7.98; 14.3 11.2; 3.7 4.15; \n",
            "9.1 9.43; 12.4 14.15; 6.8 4.0; \n",
            "6.6 9.44; 10.5 13.47; 3.4 4.99; \n",
            "5.5 6.93; 11.5 10.26; 1.4 2.56; \n",
            "5.4 6.07; 10.3 10.07; 0.0 1.29; \n",
            "5.6 6.5; 10.5 10.42; 1.5 1.5; \n",
            "7.7 6.41; 15.1 10.57; 1.0 1.17; \n",
            "12.0 8.69; 19.8 13.77; 3.4 2.81; \n",
            "12.2 12.43; 17.4 18.39; 9.0 6.17; \n",
            "11.3 11.87; 14.1 16.95; 9.1 7.32; \n",
            "12.5 10.68; 19.2 14.63; 7.9 6.7; \n",
            "17.9 12.29; 24.1 17.39; 11.7 7.31; \n",
            "19.8 16.89; 26.0 22.78; 12.1 11.79; \n",
            "21.3 17.99; 28.7 23.93; 12.9 12.7; \n",
            "21.0 19.29; 25.9 25.4; 14.7 13.72; \n",
            "20.9 19.06; 28.3 24.69; 12.8 13.99; \n",
            "20.7 19.53; 27.8 25.55; 14.0 13.66; \n",
            "22.1 19.9; 27.8 25.85; 16.4 13.99; \n",
            "20.8 20.77; 25.5 26.35; 15.4 15.37; \n",
            "22.6 19.73; 28.8 25.04; 16.1 14.6; \n",
            "24.4 21.44; 31.4 27.15; 17.5 15.84; \n",
            "23.6 22.82; 28.2 28.64; 18.0 17.15; \n",
            "20.1 22.17; 25.3 27.68; 16.9 16.84; \n",
            "13.8 19.96; 19.5 25.25; 12.5 14.6; \n",
            "15.3 15.25; 19.3 19.79; 11.4 10.14; \n",
            "15.0 16.54; 20.0 21.07; 12.5 11.32; \n",
            "17.7 16.27; 23.4 21.16; 11.8 11.09; \n",
            "20.7 18.33; 26.0 23.58; 14.5 12.93; \n",
            "23.1 20.26; 30.0 25.9; 14.9 15.04; \n",
            "24.1 21.97; 32.0 28.0; 15.9 16.31; \n",
            "24.8 22.71; 31.0 28.73; 18.4 16.85; \n",
            "24.9 22.96; 31.4 28.66; 18.0 17.55; \n",
            "18.3 22.82; 27.2 28.38; 14.9 17.37; \n",
            "18.3 18.74; 23.5 24.59; 12.9 13.02; \n",
            "14.9 18.73; 22.1 23.98; 11.2 13.16; \n",
            "11.4 16.28; 16.0 21.8; 7.9 10.42; \n",
            "13.0 13.36; 18.2 17.86; 8.7 7.81; \n",
            "15.3 14.79; 21.0 19.87; 10.4 9.09; \n",
            "16.5 16.6; 22.8 22.29; 9.5 10.83; \n",
            "16.8 17.5; 22.5 23.52; 12.3 11.26; \n",
            "16.7 17.4; 22.5 23.27; 11.9 11.77; \n",
            "19.0 17.12; 26.5 22.76; 13.8 11.5; \n",
            "18.5 18.89; 22.5 24.96; 15.1 13.21; \n",
            "20.4 18.09; 27.5 23.37; 12.1 13.25; \n",
            "22.6 19.49; 30.6 25.24; 15.0 13.76; \n",
            "22.8 21.26; 29.2 27.35; 15.9 15.65; \n",
            "20.9 21.41; 25.8 27.32; 15.1 15.82; \n",
            "18.5 19.97; 23.5 25.45; 13.0 14.61; \n",
            "15.8 18.51; 20.5 23.82; 14.1 12.95; \n",
            "16.2 16.37; 21.0 21.07; 11.5 11.43; \n",
            "15.8 17.01; 21.5 21.94; 9.6 11.67; \n",
            "17.3 16.88; 22.5 22.13; 11.9 10.89; \n",
            "17.0 17.91; 22.2 23.22; 13.6 12.47; \n",
            "16.4 17.47; 18.0 22.85; 15.9 12.17; \n",
            "17.4 16.59; 20.6 20.77; 15.0 12.43; \n",
            "19.3 17.35; 24.5 21.84; 14.4 12.97; \n",
            "18.4 18.85; 21.7 23.96; 15.0 14.16; \n",
            "18.6 17.96; 23.1 22.51; 15.2 13.62; \n",
            "19.0 18.04; 25.0 22.73; 13.0 13.69; \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "def activation_sigmoid(x):  return 1.0/(1.0 + np.exp(-x))   # (0..1)\n",
        "def dactivation_sigmoid(x): return x*(1.0-x)\n",
        "\n",
        "def f(x):\n",
        "    for _x in x:\n",
        "      y=activation_sigmoid(_x)\n",
        "\n",
        "x=[random.random()*10-5 for _ in range(100)]\n",
        "g=np.arange(-16,17)\n",
        "gg=1.0/(1.0 + np.exp(-g)).astype(np.float64)\n",
        "gd=gg[1:]-gg[:-1]\n",
        "\n",
        "def activation_sigmoid_pcw(x):\n",
        "  b=np.floor(x).astype(np.int32)\n",
        "  d=x-b\n",
        "  return gg[b+17]*d+gg[b+16]*(1-d)\n",
        "\n",
        "def activation_sigmoid_pcw2(x):\n",
        "  b=np.floor(x).astype(np.int32)\n",
        "  d=x-b\n",
        "  return gg[b+16]+gd[b+17]*(1.0-d)\n",
        "\n",
        "def f2(x):\n",
        "    for _x in x:\n",
        "      y=activation_sigmoid_pcw(_x)"
      ],
      "metadata": {
        "id": "7ZnQ2YVE0Jj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.linspace(-5,5,1000)\n"
      ],
      "metadata": {
        "id": "5V5NzG3_00EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeit activation_sigmoid(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJOlLEL91MOB",
        "outputId": "837ae9cf-38ce-4146-f83a-debf92112b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 42.79 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 5: 24.5 µs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timeit activation_sigmoid_pcw(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DulSRDWkywz2",
        "outputId": "48ca99e8-3fd0-44a7-c126-d9323973e6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 6.22 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 5: 22.7 µs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IJm3yHKp1fpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g=np.arange(-16,17)\n",
        "gg=1.0/(1.0 + np.exp(-g))\n",
        "x=2.5\n",
        "b=np.floor(x).astype(np.int32)\n",
        "print(b)\n",
        "d=x-b\n",
        "r=gg[b+17]*d+gg[b+16]*(1-d)\n",
        "print(r, 1.0/(1.0 + np.exp(-int(x))), 1.0/(1.0 + np.exp(-x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhHLve_CwZff",
        "outputId": "0b112e7f-3557-4c9a-cd98-dbd8dc65dc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "0.9166856024001578 0.8807970779778823 0.9241418199787566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [16, 8]"
      ],
      "metadata": {
        "id": "GhvVHMmzuA8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.linspace(-5,5,100)\n",
        "y=1.0/(1.0 + np.exp(-x))\n",
        "y2=activation_sigmoid_pcw(x)\n",
        "plt.plot(x,y,\".\")\n",
        "plt.plot(x,y2,\".\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "G1wpnM1xuxjI",
        "outputId": "93f230c5-f53e-4c16-d8dc-4444fdc89c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
